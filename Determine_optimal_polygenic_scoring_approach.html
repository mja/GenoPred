<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Determining Optimal Polygenic Scoring Method</title>

<script src="site_libs/jquery-1.12.4/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<link href="site_libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="site_libs/datatables-binding-0.7/datatables.js"></script>
<link href="site_libs/dt-core-1.10.16/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="site_libs/dt-core-1.10.16/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="site_libs/dt-core-1.10.16/js/jquery.dataTables.min.js"></script>
<link href="site_libs/nouislider-7.0.10/jquery.nouislider.min.css" rel="stylesheet" />
<script src="site_libs/nouislider-7.0.10/jquery.nouislider.min.js"></script>
<link href="site_libs/selectize-0.12.0/selectize.bootstrap3.css" rel="stylesheet" />
<script src="site_libs/selectize-0.12.0/selectize.min.js"></script>
<link href="site_libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="site_libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">GenoPred</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/opain/GenoPred">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Determining Optimal Polygenic Scoring Method</h1>

</div>


<style>
p.caption {
  font-size: 1.5em;
}
</style>
<style type="text/css">
pre code, pre, code {
  white-space: pre !important;
  overflow-x: scroll !important;
  word-break: keep-all !important;
  word-wrap: initial !important;
}
</style>
<hr />
<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>There are two main approaches for calculating polygenic scores (PRSs):</p>
<ul>
<li><em>p</em>-value thresholding and clumping</li>
<li>Shrinkage of GWAS summary statistics</li>
<li>Best-Linear Unbiased Predictor (BLUP)</li>
</ul>
<p>We often don’t know what the optimal parameters are when deriving a polygenic score, i.e. best p-value threshold or best shrinkage parameters. Methods to identify the best parameter are:</p>
<ul>
<li>Cross-validation (e.g. 10-fold cross validation).
<ul>
<li>Will find optimal parameters, however is time consuming.</li>
</ul></li>
<li>Pseudo-validation - optimal parameters are predicted based on distribution of GWAS summary statistics.
<ul>
<li>Fast but may not find optimal threshold.</li>
</ul></li>
</ul>
<p>Rather than using a single PRS, it may also be advantageous to predict outcome using multiple PRSs based on different parameters. A limitation to this approach is that modelling many predictors is computationally intensive and may increase the risk of overfitting.</p>
<p>Another approach for improving prediction using polygenic scores is to model polygenic scores for multiple outcomes in an elastic net model (<a href="https://www.nature.com/articles/mp2017163">ref</a>,<a href="https://www.nature.com/articles/s41380-019-0394-4">ref</a>). Here we will aim to replicate these findings with the polygenic score method that this study determines as optimal.</p>
<p><br/></p>
<hr />
</div>
<div id="aims" class="section level1">
<h1><span class="header-section-number">2</span> Aims</h1>
<ol style="list-style-type: decimal">
<li>Compare PRS derived from p-value and clumping method, and shrinkage methods (including lassosum and PRScs), using 10-fold cross validation to identify the optimal parameters.</li>
<li>Compare the predictive utility of the best PRS identified using 10-fold cross-validated PRS with the PRS selected using pseudo-validation.</li>
<li>Compare predictive utility of models including multiple PRSs based on difference parameters, to those using a single PRS selected using 10-fold cross-validation or pseudo-validation.</li>
<li>Test whether models containing polygenic scores for multiple outcomes improve prediction over the use of a polygenic score for a single outcome.</li>
</ol>
<p><br/></p>
<hr />
</div>
<div id="methods" class="section level1">
<h1><span class="header-section-number">3</span> Methods</h1>
<div id="sample" class="section level2">
<h2><span class="header-section-number">3.1</span> Sample</h2>
<ul>
<li>UK Biobank</li>
</ul>
</div>
<div id="outcomes" class="section level2">
<h2><span class="header-section-number">3.2</span> Outcomes</h2>
<ul>
<li>Depression (binary)</li>
<li>Intelligence (continuous)</li>
<li>Body mass index (BMI - continuous)</li>
<li>Height (continuous)</li>
</ul>
</div>
<div id="genotypic-data" class="section level2">
<h2><span class="header-section-number">3.3</span> Genotypic data</h2>
<p>HapMap3 variants were extracted from the HRC imputed genetic data, and converted to hard-call PLINK format with no hard-call threshold to maximise overlap with the HapMap3 SNP list. Individuals were excluded if they had extensive missing data, had non-European ancestry, or were closely-related to other individuals in the sample. This was done prior to this project.</p>
</div>
<div id="polygenic-scoring" class="section level2">
<h2><span class="header-section-number">3.4</span> Polygenic scoring</h2>
<p>Polygenic scores were derived using three methods: 1. p-value thresholding and clumping (pT + clump). No pseudo-validation approach for selecting the optimal pT is available). 2. lassosum - Lasso-based shrinkage method. 3. PRScs - Bayesian shrinkage method.</p>
<p>Polygenic scores were derived using a reference standardised pipeline, previously described in detail <a href="https://opain.github.io/GenoPred/Pipeline_prep.html#4_polygenic_scoring">here</a>. In brief, all scores were derived using HapMap3 SNPs only, modelling LD based on European individuals within the 1000 Genomes reference. Any HapMap3 missing in the target sample are imputed using the allele frequency measured in the European subset of the 1000 Genomes reference.</p>
</div>
<div id="estimating-predictive-ability" class="section level2">
<h2><span class="header-section-number">3.5</span> Estimating predictive ability</h2>
<p>All models were derived using elastic-net regularisation to reduce the likelihood of overfitting and account for multicollinearity when modelling highly correlated predictors. 10-fold cross validation was performed using 80% of individuals to identify optimal parameters, with subsequent test-set validation in the remaining 20% of individuals to estimate the predictive utility among individuals not included in the parameter selection process.</p>
<p>Model building and evaluation was performed using an Rscript called Model_builder.R (more information <a href="https://github.com/opain/GenoPred/tree/master/Scripts/Model_builder">here</a>).</p>
</div>
<div id="code" class="section level2">
<h2><span class="header-section-number">3.6</span> Code</h2>
<details>
<p><summary>pT + clump PRSs</summary></p>
<pre class="bash"><code>##############################
# Evaluating predictive utility of pT + clump PRSs across multiple pTs individually and in combination
##############################

# Make required directories
for pheno_i in $(echo Depression Intelligence BMI Height);do
mkdir -p /users/k1806347/brc_scratch/Analyses/UKBB_outcomes_for_prediction/${pheno_i}/Association_withPRSs
done</code></pre>
<pre class="bash"><code>######
# Split the different PRS p-value thresholds into separate files
######
module add general/R/3.5.0
R
library(data.table)
gwas&lt;-c(&#39;DEPR06&#39;,&#39;COLL01&#39;,&#39;BODY03&#39;,&#39;HEIG03&#39;)
for(gwas_i in gwas){
  PRS&lt;-data.frame(fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/PolygenicScores/EUR/&#39;,gwas_i,&#39;/UKBB.w_hm3.&#39;,gwas_i,&#39;.EUR.profiles&#39;)))
  for(i in 3:dim(PRS)[2]){
    tmp&lt;-gsub(paste0(gwas_i,&#39;_&#39;),&#39;pT_&#39;,names(PRS)[i])
    fwrite(PRS[,c(1,2,i)], paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/PolygenicScores/EUR/&#39;,gwas_i,&#39;/UKBB.w_hm3.&#39;,gwas_i,&#39;.EUR.&#39;,tmp,&#39;.profile&#39;), sep=&#39; &#39;)
  }
}
q()
n</code></pre>
<pre class="bash"><code>######
# Create a file to group the predictors
######
module add general/R/3.5.0
R
library(data.table)
gwas&lt;-c(&#39;DEPR06&#39;,&#39;COLL01&#39;,&#39;BODY03&#39;,&#39;HEIG03&#39;)
pheno&lt;-c(&#39;Depression&#39;,&#39;Intelligence&#39;,&#39;BMI&#39;,&#39;Height&#39;)

for(i in 1:4){
  predictors_list&lt;-list.files(path=paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/PolygenicScores/EUR/&#39;,gwas[i]) ,pattern=&#39;.pT&#39;,full.names=T)
  groups&lt;-data.frame( predictor=predictors_list,
                      group=gsub(&#39;.*UKBB.w_hm3.&#39;, &#39;&#39;, predictors_list))

  write.table(groups, paste0(&#39;/users/k1806347/brc_scratch/Analyses/UKBB_outcomes_for_prediction/&#39;,pheno[i],&#39;/Association_withPRSs/UKBB.w_hm3.&#39;,gwas[i],&#39;.EUR-PRSs.predictor_groups&#39;), col.names=T, row.names=F, quote=F)
}
q()
n</code></pre>
<pre class="bash"><code>######
# Derive and evaluate models
######

pheno=$(echo Depression Intelligence BMI Height)
pheno_file=$(echo ever_depressed_pheno_final.UpdateIDs.txt UKBB_Fluid.intelligence.score.UpdateIDs.pheno UKBB_BMI.score.UpdateIDs.pheno UKBB_Height.score.UpdateIDs.pheno)
gwas=$(echo DEPR06 COLL01 BODY03 HEIG03)
prev=$(echo 0.15 NA NA NA)

for i in $(seq 1 4);do
  pheno_i=$(echo ${pheno} | cut -f ${i} -d &#39; &#39;)
  pheno_file_i=$(echo ${pheno_file} | cut -f ${i} -d &#39; &#39;)
  gwas_i=$(echo ${gwas} | cut -f ${i} -d &#39; &#39;)
  prev_i=$(echo ${prev} | cut -f ${i} -d &#39; &#39;)

  qsub -l h_vmem=3G -pe smp 5 /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/MyGit/GenoPred/Scripts/Model_builder/Model_builder.R \
    --pheno /users/k1806347/brc_scratch/Data/UKBB/Phenotype/${pheno_i}/${pheno_file_i} \
    --keep /users/k1806347/brc_scratch/Analyses/UKBB_outcomes_for_prediction/ukb18177_glanville_post_qc_id_list.UpdateIDs.fam \
    --out /users/k1806347/brc_scratch/Analyses/UKBB_outcomes_for_prediction/${pheno_i}/Association_withPRSs/UKBB.w_hm3.${gwas_i}.EUR-PRSs \
    --n_core 5 \
    --assoc T \
    --outcome_pop_prev ${prev_i} \
    --predictors /users/k1806347/brc_scratch/Analyses/UKBB_outcomes_for_prediction/${pheno_i}/Association_withPRSs/UKBB.w_hm3.${gwas_i}.EUR-PRSs.predictor_groups
done</code></pre>
</details>
<details>
<p><summary>lassosum PRSs</summary></p>
<pre class="bash"><code>################################
# Evaluate use of lassosum PRSs when using multiple shrinkage parameters individually and in combination
################################

######
# Split lassosum PRSs into individual files
######
module add general/R/3.5.0
R
library(data.table)
gwas&lt;-c(&#39;DEPR06&#39;,&#39;COLL01&#39;,&#39;BODY03&#39;,&#39;HEIG03&#39;)
for(gwas_i in gwas){
  PRS&lt;-data.frame(fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/PolygenicScores_lassosum/EUR/&#39;,gwas_i,&#39;/UKBB.w_hm3.&#39;,gwas_i,&#39;.EUR.lassosum_profiles&#39;)))
  for(i in 3:dim(PRS)[2]){
    if(sum(is.na(PRS[,i])) &lt; length(PRS[,i])){
      tmp&lt;-gsub(paste0(gwas_i,&#39;_&#39;),&#39;param_&#39;,names(PRS)[i])
      fwrite(PRS[,c(1,2,i)], paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/PolygenicScores_lassosum/EUR/&#39;,gwas_i,&#39;/UKBB.w_hm3.&#39;,gwas_i,&#39;.EUR.&#39;,tmp,&#39;.lassosum_profiles&#39;), sep=&#39; &#39;)
    }
    print(i)
  }
}
q()
n</code></pre>
<pre class="bash"><code>######
# Create predictor groups files
######
module add general/R/3.5.0
R
library(data.table)
gwas&lt;-c(&#39;DEPR06&#39;,&#39;COLL01&#39;,&#39;BODY03&#39;,&#39;HEIG03&#39;)
pheno&lt;-c(&#39;Depression&#39;,&#39;Intelligence&#39;,&#39;BMI&#39;,&#39;Height&#39;)

for(i in 1:4){
  predictors_list&lt;-list.files(path=paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/PolygenicScores_lassosum/EUR/&#39;,gwas[i]) ,pattern=&#39;.param&#39;,full.names=T)
  groups&lt;-data.frame( predictor=predictors_list,
                      group=gsub(&#39;.*UKBB.w_hm3.&#39;, &#39;&#39;, predictors_list))

  write.table(groups, paste0(&#39;/users/k1806347/brc_scratch/Analyses/UKBB_outcomes_for_prediction/&#39;,pheno[i],&#39;/Association_withPRSs/UKBB.w_hm3.&#39;,gwas[i],&#39;.EUR-PRSs_lassosum.predictor_groups&#39;), col.names=T, row.names=F, quote=F)
}
q()
n</code></pre>
<pre class="bash"><code>######
# Derive and evaluate
######
pheno=$(echo Depression Intelligence BMI Height)
pheno_file=$(echo ever_depressed_pheno_final.UpdateIDs.txt UKBB_Fluid.intelligence.score.UpdateIDs.pheno UKBB_BMI.score.UpdateIDs.pheno UKBB_Height.score.UpdateIDs.pheno)
gwas=$(echo DEPR06 COLL01 BODY03 HEIG03)
prev=$(echo 0.15 NA NA NA)

for i in $(seq 1 4);do
    pheno_i=$(echo ${pheno} | cut -f ${i} -d &#39; &#39;)
    pheno_file_i=$(echo ${pheno_file} | cut -f ${i} -d &#39; &#39;)
    gwas_i=$(echo ${gwas} | cut -f ${i} -d &#39; &#39;)
    prev_i=$(echo ${prev} | cut -f ${i} -d &#39; &#39;)

    qsub -l h_vmem=10G -pe smp 5 /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/MyGit/GenoPred/Scripts/Model_builder/Model_builder.R \
        --pheno /users/k1806347/brc_scratch/Data/UKBB/Phenotype/${pheno_i}/${pheno_file_i} \
        --keep /users/k1806347/brc_scratch/Analyses/UKBB_outcomes_for_prediction/ukb18177_glanville_post_qc_id_list.UpdateIDs.fam \
        --out /users/k1806347/brc_scratch/Analyses/UKBB_outcomes_for_prediction/${pheno_i}/Association_withPRSs/UKBB.w_hm3.${gwas_i}.EUR-PRSs_lassosum \
        --n_core 5 \
        --assoc T \
        --outcome_pop_prev ${prev_i} \
        --predictors /users/k1806347/brc_scratch/Analyses/UKBB_outcomes_for_prediction/${pheno_i}/Association_withPRSs/UKBB.w_hm3.${gwas_i}.EUR-PRSs_lassosum.predictor_groups
done</code></pre>
</details>
<details>
<p><summary>PRScs PRSs</summary></p>
<pre class="bash"><code>################################
# Evaluate use of multiple PRSs based on different shrinkage parameters, and use of pseudo-validated PRS (PRScs)
################################

#####
# Split PRScs PRSs into individual files
#####
module add general/R/3.5.0
R
library(data.table)
gwas&lt;-c(&#39;DEPR06&#39;,&#39;COLL01&#39;,&#39;BODY03&#39;,&#39;HEIG03&#39;)
for(gwas_i in gwas){
  PRS&lt;-data.frame(fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/PolygenicScores_PRScs/EUR/&#39;,gwas_i,&#39;/UKBB.w_hm3.&#39;,gwas_i,&#39;.EUR.PRScs_profiles&#39;)))
  for(i in 3:dim(PRS)[2]){
    if(sum(is.na(PRS[,i])) &lt; length(PRS[,i])){
      tmp&lt;-gsub(paste0(gwas_i,&#39;_&#39;),&#39;param_&#39;,names(PRS)[i])
      fwrite(PRS[,c(1,2,i)], paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/PolygenicScores_PRScs/EUR/&#39;,gwas_i,&#39;/UKBB.w_hm3.&#39;,gwas_i,&#39;.EUR.&#39;,tmp,&#39;.PRScs_profiles&#39;), sep=&#39; &#39;)
    }
    print(i)
  }
}
q()
n</code></pre>
<pre class="bash"><code>#####
# Create predictor groups files
#####
module add general/R/3.5.0
R
library(data.table)
gwas&lt;-c(&#39;DEPR06&#39;,&#39;COLL01&#39;,&#39;BODY03&#39;,&#39;HEIG03&#39;)
pheno&lt;-c(&#39;Depression&#39;,&#39;Intelligence&#39;,&#39;BMI&#39;,&#39;Height&#39;)

for(i in 1:4){
  predictors_list&lt;-list.files(path=paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/PolygenicScores_PRScs/EUR/&#39;,gwas[i]) ,pattern=&#39;.param&#39;,full.names=T)
  groups&lt;-data.frame( predictor=predictors_list,
                      group=gsub(&#39;.*UKBB.w_hm3.&#39;, &#39;&#39;, predictors_list))

  write.table(groups, paste0(&#39;/users/k1806347/brc_scratch/Analyses/UKBB_outcomes_for_prediction/&#39;,pheno[i],&#39;/Association_withPRSs/UKBB.w_hm3.&#39;,gwas[i],&#39;.EUR-PRSs_PRScs.predictor_groups&#39;), col.names=T, row.names=F, quote=F)
}
q()
n</code></pre>
<pre class="bash"><code>#####
# Derive and evaluate
#####
pheno=$(echo Depression Intelligence BMI Height)
pheno_file=$(echo ever_depressed_pheno_final.UpdateIDs.txt UKBB_Fluid.intelligence.score.UpdateIDs.pheno UKBB_BMI.score.UpdateIDs.pheno UKBB_Height.score.UpdateIDs.pheno)
gwas=$(echo DEPR06 COLL01 BODY03 HEIG03)
prev=$(echo 0.15 NA NA NA)

for i in $(seq 1 4);do
pheno_i=$(echo ${pheno} | cut -f ${i} -d &#39; &#39;)
pheno_file_i=$(echo ${pheno_file} | cut -f ${i} -d &#39; &#39;)
gwas_i=$(echo ${gwas} | cut -f ${i} -d &#39; &#39;)
prev_i=$(echo ${prev} | cut -f ${i} -d &#39; &#39;)

qsub -l h_vmem=10G -pe smp 5 /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/MyGit/GenoPred/Scripts/Model_builder/Model_builder.R \
--pheno /users/k1806347/brc_scratch/Data/UKBB/Phenotype/${pheno_i}/${pheno_file_i} \
--keep /users/k1806347/brc_scratch/Analyses/UKBB_outcomes_for_prediction/ukb18177_glanville_post_qc_id_list.UpdateIDs.fam \
--out /users/k1806347/brc_scratch/Analyses/UKBB_outcomes_for_prediction/${pheno_i}/Association_withPRSs/UKBB.w_hm3.${gwas_i}.EUR-PRSs_PRScs \
--n_core 5 \
--assoc T \
--outcome_pop_prev ${prev_i} \
--predictors /users/k1806347/brc_scratch/Analyses/UKBB_outcomes_for_prediction/${pheno_i}/Association_withPRSs/UKBB.w_hm3.${gwas_i}.EUR-PRSs_PRScs.predictor_groups
done</code></pre>

<p><br/></p>
<hr />
</div>
</div>
<div id="results" class="section level1">
<h1><span class="header-section-number">4</span> Results</h1>
<p>The pattern of results are consistent between 10-fold cross-validation and test set validation.</p>
<p>Modelling multiple PRSs based on a range of parameters consistenly provides a small improvement over the best single PRS idenitfied by cross-validation.</p>
<p>As previous studies have shown, performing a grid search of shrinkage parameters with both lassosum- and PRScs-based PRSs consistently out performs PRS derived using the traditional pT + clump method.</p>
<p>The pseudovalidation approach within lassosum performs worse than any other approach tested here. In contrast the PRScs pseduovalidated PRS performs well, providing nearly the best prediction for all outcomes.</p>
<hr />
<details>
<p><summary>Code for plotting results</summary></p>
<pre class="bash"><code>#####
# Compare results from each approach
#####
module add general/R/3.5.0
R

pheno&lt;-c(&#39;Depression&#39;,&#39;Intelligence&#39;,&#39;BMI&#39;,&#39;Height&#39;)
gwas&lt;-c(&#39;DEPR06&#39;,&#39;COLL01&#39;,&#39;BODY03&#39;,&#39;HEIG03&#39;)

# Read in the results, labelling which parameters where pseudovalidated and validated using 10-fold cross validation
All_res&lt;-NULL
for(i in 1:4){
  pT_clump&lt;-read.table(paste0(&#39;/users/k1806347/brc_scratch/Analyses/UKBB_outcomes_for_prediction/&#39;,pheno[i],&#39;/Association_withPRSs/UKBB.w_hm3.&#39;,gwas[i],&#39;.EUR-PRSs.pred_eval.txt&#39;), header=T, stringsAsFactors=F)
  pT_clump$Method&lt;-&#39;pT + clump&#39;
  Param_tmp&lt;-sort(as.numeric(gsub(&#39;e.&#39;,&#39;e-&#39;,gsub(&#39;.profile_group&#39;,&#39;&#39;,gsub(paste0(gwas[i],&#39;.EUR.pT_&#39;),&#39;&#39;,pT_clump$Model)))))
  pT_clump$Param&lt;-as.character(as.numeric(gsub(&#39;e.&#39;,&#39;e-&#39;,gsub(&#39;.profile_group&#39;,&#39;&#39;,gsub(paste0(gwas[i],&#39;.EUR.pT_&#39;),&#39;&#39;,pT_clump$Model)))))
  pT_clump$Param[dim(pT_clump)[1]]&lt;-&#39;Multi-PRS&#39;
  pT_clump&lt;-pT_clump[match(c(Param_tmp,&#39;Multi-PRS&#39;), pT_clump$Param),]
  pT_clump$Model&lt;-NULL
  pT_clump$Group&lt;-NA
  pT_clump$Group[pT_clump$CrossVal_R == max(abs(pT_clump$CrossVal_R[pT_clump$Param != &#39;Multi-PRS&#39;]))]&lt;-&#39;10FCVal&#39;
  pT_clump$Group[pT_clump$Param == &#39;Multi-PRS&#39;]&lt;-&#39;Multi-PRS&#39;
  pT_clump&lt;-pT_clump[!is.na(pT_clump$Group),]
  
  lassosum_res&lt;-read.table(paste0(&#39;/users/k1806347/brc_scratch/Analyses/UKBB_outcomes_for_prediction/&#39;,pheno[i],&#39;/Association_withPRSs/UKBB.w_hm3.&#39;,gwas[i],&#39;.EUR-PRSs_lassosum.pred_eval.txt&#39;), header=T, stringsAsFactors=F)
  lassosum_res$Method&lt;-&#39;lassosum&#39;
  lassosum_res$Param&lt;-gsub(&#39;.lassosum.*&#39;,&#39;&#39;,gsub(&#39;.*param_&#39;,&#39;&#39;,lassosum_res$Model))
  lassosum_res$Param[dim(lassosum_res)[1]]&lt;-&#39;Multi-PRS&#39;
  lassosum_res$Model&lt;-NULL
  lassosum_val&lt;-read.table(paste0(&#39;/users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic_lassosum/&#39;,gwas[i],&#39;/1KGPhase3.w_hm3.&#39;,gwas[i],&#39;.log&#39;), sep=&#39;&amp;&#39;)
  lassosum_val_s&lt;-as.numeric(gsub(&#39;s = &#39;,&#39;&#39;,lassosum_val$V1[grepl(&#39;s = &#39;,lassosum_val$V1)]))
  lassosum_val_lambda&lt;-as.numeric(gsub(&#39;lambda =&#39;,&#39;&#39;,lassosum_val$V1[grepl(&#39;lambda =&#39;,lassosum_val$V1)]))
  lassosum_val_param&lt;-paste0(&#39;s&#39;,lassosum_val_s,&#39;_lambda&#39;,lassosum_val_lambda)
  lassosum_val_param&lt;-substr(lassosum_val_param, 1, nchar(lassosum_val_param)-1) 
  lassosum_res$Group&lt;-NA
  lassosum_res$Group[which(lassosum_res$CrossVal_R == max(abs(lassosum_res$CrossVal_R[lassosum_res$Param != &#39;Multi-PRS&#39;])))[1]]&lt;-&#39;10FCVal&#39;
  lassosum_res$Group[grepl(lassosum_val_param,lassosum_res$Param)]&lt;-&#39;PseudoVal&#39;
  lassosum_res$Group[lassosum_res$Param == &#39;Multi-PRS&#39;]&lt;-&#39;Multi-PRS&#39;
  lassosum_res&lt;-lassosum_res[!is.na(lassosum_res$Group),]
  
  PRScs_res&lt;-read.table(paste0(&#39;/users/k1806347/brc_scratch/Analyses/UKBB_outcomes_for_prediction/&#39;,pheno[i],&#39;/Association_withPRSs/UKBB.w_hm3.&#39;,gwas[i],&#39;.EUR-PRSs_PRScs.pred_eval.txt&#39;), header=T, stringsAsFactors=F)
  PRScs_res$Method&lt;-&#39;PRScs&#39;
  PRScs_res$Param&lt;-gsub(&#39;.PRScs.*&#39;,&#39;&#39;,gsub(&#39;.*param_&#39;,&#39;&#39;,PRScs_res$Model))
  PRScs_res$Param[dim(PRScs_res)[1]]&lt;-&#39;Multi-PRS&#39;
  PRScs_res$Model&lt;-NULL
  PRScs_res$Group&lt;-NA
  PRScs_res$Group[which(PRScs_res$CrossVal_R == max(abs(PRScs_res$CrossVal_R[PRScs_res$Param != &#39;Multi-PRS&#39; &amp; PRScs_res$Param != &#39;phiauto&#39;])))[1]]&lt;-&#39;10FCVal&#39;
  PRScs_res$Group[PRScs_res$Param == &#39;phiauto&#39;]&lt;-&#39;PseudoVal&#39;
  PRScs_res$Group[PRScs_res$Param == &#39;Multi-PRS&#39;]&lt;-&#39;Multi-PRS&#39;
  PRScs_res&lt;-PRScs_res[!is.na(PRScs_res$Group),]

  res&lt;-do.call(rbind, list(pT_clump, lassosum_res, PRScs_res))
  res$Phenotype&lt;-pheno[i]
  res$Cross_LiabR2&lt;-NULL
  res$Indep_LiabR2&lt;-NULL
  res$CrossVal_pval&lt;-NULL
  res$IndepVal_pval&lt;-NULL

  All_res&lt;-rbind(All_res, res)
}

# Reformat to be a table
All_res&lt;-All_res[c(&#39;Phenotype&#39;,&#39;Method&#39;,&#39;Group&#39;,&#39;CrossVal_R&#39;,&#39;CrossVal_R_SE&#39;,&#39;IndepVal_R&#39;,&#39;IndepVal_R_SE&#39;)]

write.csv(All_res, &#39;/mnt/lustre/users/k1806347/Analyses/UKBB_outcomes_for_prediction/PRS_method_comp.csv&#39;, row.names=F)

###
# Plot comparison between validated PRS vs multi-PRS when using pT + clump method
###

library(ggplot2)
library(cowplot)

All_res$Method&lt;-factor(All_res$Method, levels=unique(All_res$Method))

plots&lt;-list()
for(i in 1:4){
plots[[pheno[i]]] &lt;- ggplot( All_res[All_res$Phenotype==pheno[i],], aes(x=Method, y=CrossVal_R, fill=Group)) +
                      geom_bar(stat=&quot;identity&quot;, position=position_dodge(preserve = &quot;single&quot;), colour=&#39;black&#39;) +
                      geom_errorbar(aes(ymin=CrossVal_R-CrossVal_R_SE, ymax=CrossVal_R+CrossVal_R_SE), width=.2, position=position_dodge(width = 0.9, preserve = &quot;single&quot;)) +
                      labs(y=&quot;Correlation (SE)&quot;, x=&#39;&#39;, title=pheno[i]) +
                      coord_cartesian(ylim=c(min(All_res$CrossVal_R[All_res$Phenotype==pheno[i]])-0.02, max(All_res$CrossVal_R[All_res$Phenotype==pheno[i]])+0.025), clip=&quot;on&quot;) +
                              theme(axis.text.x = element_text(angle = 45, hjust = 1))
}

png(&#39;/mnt/lustre/users/k1806347/Analyses/UKBB_outcomes_for_prediction/PRS_method_comp_CrossVal.png&#39;, units=&#39;px&#39;, res=300, width=3000, height=2500)
plot_grid(plotlist=plots)
dev.off()

plots&lt;-list()
for(i in 1:4){
plots[[pheno[i]]] &lt;- ggplot( All_res[All_res$Phenotype==pheno[i],], aes(x=Method, y=IndepVal_R, fill=Group)) +
                      geom_bar(stat=&quot;identity&quot;, position=position_dodge(preserve = &quot;single&quot;), colour=&#39;black&#39;) +
                      geom_errorbar(aes(ymin=IndepVal_R-IndepVal_R_SE, ymax=IndepVal_R+IndepVal_R_SE), width=.2, position=position_dodge(width = 0.9, preserve = &quot;single&quot;)) +
                      labs(y=&quot;Correlation (SE)&quot;, x=&#39;&#39;, title=pheno[i]) +
                      coord_cartesian(ylim=c(min(All_res$IndepVal_R[All_res$Phenotype==pheno[i]])-0.02, max(All_res$IndepVal_R[All_res$Phenotype==pheno[i]])+0.025), clip=&quot;on&quot;) +
                              theme(axis.text.x = element_text(angle = 45, hjust = 1))
}

png(&#39;/mnt/lustre/users/k1806347/Analyses/UKBB_outcomes_for_prediction/PRS_method_comp_IndepVal.png&#39;, units=&#39;px&#39;, res=300, width=3000, height=2500)
plot_grid(plotlist=plots)
dev.off()

q()
n</code></pre>
</details>
<center>
<div class="figure">
<img src="Images/Determine_optimal_polygenic_scoring_approach/PRS_method_comp_CrossVal.png" alt="Figure 1: Predictive utility estimated using 10-fold cross-validation" />
<p class="caption">Figure 1: Predictive utility estimated using 10-fold cross-validation</p>
</div>
<p><br/></p>
<hr />
<div class="figure">
<img src="Images/Determine_optimal_polygenic_scoring_approach/PRS_method_comp_IndepVal.png" alt="Figure 2: Predictive utility estimated using test set validation" />
<p class="caption">Figure 2: Predictive utility estimated using test set validation</p>
</div>

<p><br/></p>
<hr />
<div id="htmlwidget-f81eebe49a5c82fb61a7" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-f81eebe49a5c82fb61a7">{"x":{"filter":"top","filterHTML":"<tr>\n  <td data-type=\"factor\" style=\"vertical-align: top;\">\n    <div class=\"form-group has-feedback\" style=\"margin-bottom: auto;\">\n      <input type=\"search\" placeholder=\"All\" class=\"form-control\" style=\"width: 100%;\"/>\n      <span class=\"glyphicon glyphicon-remove-circle form-control-feedback\"><\/span>\n    <\/div>\n    <div style=\"width: 100%; display: none;\">\n      <select multiple=\"multiple\" style=\"width: 100%;\" data-options=\"[&quot;BMI&quot;,&quot;Depression&quot;,&quot;Height&quot;,&quot;Intelligence&quot;]\"><\/select>\n    <\/div>\n  <\/td>\n  <td data-type=\"factor\" style=\"vertical-align: top;\">\n    <div class=\"form-group has-feedback\" style=\"margin-bottom: auto;\">\n      <input type=\"search\" placeholder=\"All\" class=\"form-control\" style=\"width: 100%;\"/>\n      <span class=\"glyphicon glyphicon-remove-circle form-control-feedback\"><\/span>\n    <\/div>\n    <div style=\"width: 100%; display: none;\">\n      <select multiple=\"multiple\" style=\"width: 100%;\" data-options=\"[&quot;lassosum&quot;,&quot;PRScs&quot;,&quot;pT + clump&quot;]\"><\/select>\n    <\/div>\n  <\/td>\n  <td data-type=\"factor\" style=\"vertical-align: top;\">\n    <div class=\"form-group has-feedback\" style=\"margin-bottom: auto;\">\n      <input type=\"search\" placeholder=\"All\" class=\"form-control\" style=\"width: 100%;\"/>\n      <span class=\"glyphicon glyphicon-remove-circle form-control-feedback\"><\/span>\n    <\/div>\n    <div style=\"width: 100%; display: none;\">\n      <select multiple=\"multiple\" style=\"width: 100%;\" data-options=\"[&quot;10FCVal&quot;,&quot;Multi-PRS&quot;,&quot;PseudoVal&quot;]\"><\/select>\n    <\/div>\n  <\/td>\n  <td data-type=\"character\" style=\"vertical-align: top;\">\n    <div class=\"form-group has-feedback\" style=\"margin-bottom: auto;\">\n      <input type=\"search\" placeholder=\"All\" class=\"form-control\" style=\"width: 100%;\"/>\n      <span class=\"glyphicon glyphicon-remove-circle form-control-feedback\"><\/span>\n    <\/div>\n  <\/td>\n  <td data-type=\"character\" style=\"vertical-align: top;\">\n    <div class=\"form-group has-feedback\" style=\"margin-bottom: auto;\">\n      <input type=\"search\" placeholder=\"All\" class=\"form-control\" style=\"width: 100%;\"/>\n      <span class=\"glyphicon glyphicon-remove-circle form-control-feedback\"><\/span>\n    <\/div>\n  <\/td>\n<\/tr>","caption":"<caption>Table 1: Correlation between PRS model predictions and observed values<\/caption>","data":[["Depression","Depression","Depression","Depression","Depression","Depression","Depression","Depression","Intelligence","Intelligence","Intelligence","Intelligence","Intelligence","Intelligence","Intelligence","Intelligence","BMI","BMI","BMI","BMI","BMI","BMI","BMI","BMI","Height","Height","Height","Height","Height","Height","Height","Height"],["pT + clump","pT + clump","lassosum","lassosum","lassosum","PRScs","PRScs","PRScs","pT + clump","pT + clump","lassosum","lassosum","lassosum","PRScs","PRScs","PRScs","pT + clump","pT + clump","lassosum","lassosum","lassosum","PRScs","PRScs","PRScs","pT + clump","pT + clump","lassosum","lassosum","lassosum","PRScs","PRScs","PRScs"],["10FCVal","Multi-PRS","10FCVal","PseudoVal","Multi-PRS","10FCVal","PseudoVal","Multi-PRS","10FCVal","Multi-PRS","10FCVal","PseudoVal","Multi-PRS","10FCVal","PseudoVal","Multi-PRS","10FCVal","Multi-PRS","10FCVal","PseudoVal","Multi-PRS","10FCVal","PseudoVal","Multi-PRS","10FCVal","Multi-PRS","10FCVal","PseudoVal","Multi-PRS","10FCVal","PseudoVal","Multi-PRS"],["0.119 (0.004)","0.126 (0.004)","0.123 (0.004)","0.077 (0.004)","0.127 (0.004)","0.137 (0.004)","0.138 (0.004)","0.14 (0.004)","0.09 (0.004)","0.094 (0.004)","0.093 (0.004)","0.065 (0.004)","0.094 (0.004)","0.102 (0.004)","0.1 (0.004)","0.104 (0.004)","0.255 (0.002)","0.271 (0.002)","0.276 (0.002)","0.215 (0.002)","0.28 (0.002)","0.281 (0.002)","0.272 (0.002)","0.29 (0.002)","0.299 (0.002)","0.315 (0.002)","0.342 (0.002)","0.289 (0.002)","0.345 (0.002)","0.342 (0.002)","0.342 (0.002)","0.344 (0.002)"],["0.108 (0.007)","0.12 (0.007)","0.118 (0.007)","0.081 (0.007)","0.12 (0.007)","0.122 (0.007)","0.124 (0.007)","0.125 (0.007)","0.085 (0.007)","0.094 (0.007)","0.086 (0.007)","0.067 (0.007)","0.089 (0.007)","0.096 (0.007)","0.099 (0.007)","0.1 (0.007)","0.261 (0.004)","0.276 (0.004)","0.282 (0.004)","0.216 (0.004)","0.286 (0.004)","0.287 (0.004)","0.275 (0.004)","0.295 (0.003)","0.303 (0.003)","0.318 (0.003)","0.346 (0.003)","0.295 (0.003)","0.349 (0.003)","0.346 (0.003)","0.345 (0.003)","0.347 (0.003)"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>Phenotype<\/th>\n      <th>Method<\/th>\n      <th>Group<\/th>\n      <th>CrossVal R (SE)<\/th>\n      <th>IndepVal R (SE)<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":10,"scrollX":true,"order":[],"autoWidth":false,"orderClasses":false,"orderCellsTop":true}},"evals":[],"jsHooks":[]}</script>
<p><br/></p>
<hr />
</div>
<div id="discussion" class="section level1">
<h1><span class="header-section-number">5</span> Discussion</h1>
<p>This study has replicated previous findings that shrinkage of GWAS summary statistics using lassosum or PRScs can increase the variance explained by subsequent PRSs. Interestingly predicting the optimal shrinkage paramter via pseudovalidation is suboptimal for lassosum, with selection of the shrinkage parameter by formal cross validation providing substantial improvements the variance explained by the PRS. In contrast psudovalidation, or fully bayesian mode, implemented by PRScs performs well, providing PRSs with a predictive utility close to those derived using a shrinkage parameter identified via cross validation.</p>
<p>This study also reports that use of an elastic net to model model PRSs, based on a range of shrinkage paramters provides the optimal variance explained for all methods and outcomes. However, the improvement in prediction is small, and computational burden of generating multiple PRSs, and modelling them in an elastic net is substantial. Furthermore, as more predictors are included in the model, the likelihood of overfitting increases, particularly in smaller samples.</p>
<p><br/></p>
<hr />
</div>
<div id="conclusion" class="section level1">
<h1><span class="header-section-number">6</span> Conclusion</h1>
<p>Based on our results we think suggest the use of PRScs using only the pseudovalidated, or fully bayesian, global shrinkage parameter, as this provides near optimal prediction whilst reducing computional burden and risk of overfitting.</p>
<hr />
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
