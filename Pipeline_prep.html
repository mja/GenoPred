<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Preparing reference files for genotype-based scoring</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">GenoPred</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="Pipeline_prep.html">Preparing reference files for genotype-based scoring</a>
</li>
<li>
  <a href="Determine_optimal_polygenic_scoring_approach.html">Determine optimal polygenic scoring approach</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/opain/GenoPred">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Preparing reference files for genotype-based scoring</h1>

</div>


<style>
p.caption {
  font-size: 1.5em;
}
</style>
<style type="text/css">
pre code, pre, code {
  white-space: pre !important;
  overflow-x: auto !important;
  word-break: keep-all !important;
  word-wrap: initial !important;
}
</style>
<hr />
<p><br/></p>
<p>Genotype-based scores are typically based on several target sample specific features of the data including:</p>
<ul>
<li><p>Linkage disequilibrium (LD) structure</p></li>
<li><p>Available genetic variation</p></li>
<li><p>Minor allele frequecy (MAF)</p></li>
</ul>
<p>Basing these features on the target sample lead to differences in genotype-based scores across samples seperately processed, meaning they cannot be directly compared. This is not a limitation when performing inference within a single dataset, however in framework of prediction it is important that the predictors are derived in a way that can be replicated in any future dataset to optimise external validity of the prediction model.</p>
<p>To ensure consistency in genotye-based scoring we can base each of these features on a reference dataset, such as the 1000 Genomes reference, an approach herein refered to as ‘reference-standardised’. Another advantage of reference-standardised scoring is that a single sample can be realiably processed, enabling reliable prediction for n individual.</p>
<p>This page provides instructions for preparing the reference data required for reference-standardised genotype-based scoring. Here I provide code used when preparing on the KCL Rosalind cluster, with the intention of deriving scores in the UK Biobank sample and Twins Early Development Study (TEDS) sample.</p>
<p><br/></p>
<hr />
<p><br/></p>
<div id="pre-requisites" class="section level1">
<h1><span class="header-section-number">1</span> Pre-requisites</h1>
<p>The following software is required for the prediction pipeline:</p>
<ul>
<li><p>PLINK v1.9 (<a href="https://www.cog-genomics.org/plink2/" class="uri">https://www.cog-genomics.org/plink2/</a>)</p></li>
<li><p>PLINK v2 (<a href="https://www.cog-genomics.org/plink/2.0/" class="uri">https://www.cog-genomics.org/plink/2.0/</a>)</p></li>
<li><p>SHAPEIT (<a href="https://mathgen.stats.ox.ac.uk/genetics_softwae*hapeit/shapeit.html#download" class="uri">https://mathgen.stats.ox.ac.uk/genetics_softwae*hapeit/shapeit.html#download</a>)</p></li>
<li><p>IMPUTE2 (<a href="https://mathgen.stats.ox.ac.uk/impute/impute_v" class="uri">https://mathgen.stats.ox.ac.uk/impute/impute_v</a>.*ml#download)</p></li>
<li><p>QCTOOL v2 (<a href="https://www.well.ox.ac.uk/~gav/qctool/documet*ion/download.html" class="uri">https://www.well.ox.ac.uk/~gav/qctool/documet*ion/download.html</a>)</p></li>
<li><p>R (<a href="https://www.r-project.org/" class="uri">https://www.r-project.org/</a>)</p></li>
<li><p>R packages:</p></li>
</ul>
<pre class="r"><code>install.packages(c(&#39;data.table&#39;,&#39;doMC&#39;,&#39;optparse&#39;,&#39;foreach&#39;,&#39;caret&#39;,&#39;ggplot2&#39;,&#39;cowplot&#39;))</code></pre>
<p>NOTE: Setting environmental variables Throughout this script I use environmental variables to indicate where files are to be stored. These enable other people to use the code more easily. I set the environmental variables using a file called ‘Pipeline_prep.var’. You will need to create your own version of this file. These variables need to be set on the command line and in R.</p>
<p><br/></p>
<hr />
<p><br/></p>
</div>
<div id="genotypic-data" class="section level1">
<h1><span class="header-section-number">2</span> Genotypic data</h1>
<p>In this section we will download the required reference genotype data, and format it for use.</p>
<details>
<p><summary>Set required variables for command line</summary></p>
<pre class="bash"><code># Set variables
Impute2_1KG_dir=$(sed -n &#39;/Impute2_1KG_dir/p&#39; /users/k1806347/brc_scratch/Software/MyGit/GenoPred/Variables_used/Pipeline_prep.var | cut -d &#39; &#39; -f 2)
HapMap3_snplist_dir=$(sed -n &#39;/HapMap3_snplist_dir/p&#39; /users/k1806347/brc_scratch/Software/MyGit/GenoPred/Variables_used/Pipeline_prep.var | cut -d &#39; &#39; -f 2)
Geno_1KG_dir=$(sed -n &#39;/Geno_1KG_dir/p&#39; /users/k1806347/brc_scratch/Software/MyGit/GenoPred/Variables_used/Pipeline_prep.var | cut -d &#39; &#39; -f 2)
</code></pre>
</details>
<p><br/></p>
<hr />
<p><br/></p>
<div id="impute2-1000-genomes-phase-3" class="section level2">
<h2><span class="header-section-number">2.1</span> IMPUTE2 1000 Genomes Phase 3</h2>
<p>This dataset is the 1000 Genomes Phase 3 reference data in the format requird for imputation via the IMPUTE2 software. This is only required if you want to calculate genetic scores within target samples that have not undergone genotype imputation. Imputation is important as it will ensure a sufficient overlap with the HapMap3 SNP-list which all genotype-based scores are restricted to in subsequent stages of the genotype-based prediction pipeline.</p>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code># Create directory for the data
mkdir -p ${Impute2_1KG_dir}

# Download data using wget
cd ${Impute2_1KG_dir}
wget https://mathgen.stats.ox.ac.uk/impute/1000GP_Phase3.tgz
wget https://mathgen.stats.ox.ac.uk/impute/1000GP_Phase3_chrX.tgz

# Decompress data
tar -zxvf 1000GP_Phase3.tgz
tar -zxvf 1000GP_Phase3_chrX.tgz</code></pre>
</details>
<p><br/></p>
<hr />
<p><br/></p>
</div>
<div id="hapmap3-snp-list" class="section level2">
<h2><span class="header-section-number">2.2</span> HapMap3 SNP-list</h2>
<p>Here we download a list of SNPs within the HapMap3 reference created for use in LD-score regression. We use the HapMap3 SNP-list as this is a collection of genetic variants as they are well captured by standard genotype imputation reference panels (incl. 1000 Genomes), meaning that these SNPs are typically available and accurately imputed in most GWAS and target samples. Using this common set of SNPs means that scores for individuals from different sources will be directly comparable, assuming a high proportion of these variants are available in the target sample. This relatively sparse subset of the genome provides decent coverage of genome-wide common genetic variation, however scores may explain less variation than those based on dense coverge of the genome or sequence data. Having said this, in my analyses HapMap3 restricted genotype-based scores perform similarly to those based on dense imputation.</p>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code># Dowload snplist using wget and decompress
cd ${HapMap3_snplist_dir}
wget https://data.broadinstitute.org/alkesgroup/LDSCORE/w_hm3.snplist.bz2
bunzip2 w_hm3.snplist.bz2</code></pre>
</details>
<p><br/></p>
<hr />
<p><br/></p>
</div>
<div id="genomes-populations" class="section level2">
<h2><span class="header-section-number">2.3</span> 1000 Genomes populations</h2>
<p>Here we download information on which population each individual in the 1000 Genomes reference is from. Individuals are grouped into ‘populations’ which are typically country specific, and ‘super populations’ which include a collection of ancetrally similar countries. Individuals are grouped into these populations if the last few generations of their family are all from one region. We need this population data so we can select individuals in the 1000 Genomes data to match those in our target samples. This is important for providing accurate information on LD structure and minor allele frequencies.</p>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code># Download the populations file
cd ${Geno_1KG_dir}
wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/integrated_call_samples_v3.20130502.ALL.panel

# Create a version of population file that only contains sample ID, pop and super_pop
cut -f 1-3 ${Geno_1KG_dir}/integrated_call_samples_v3.20130502.ALL.panel &gt; ${Geno_1KG_dir}/integrated_call_samples_v3.20130502.ALL.panel_small

# Create a keep file listing each population super population from the reference.
mkdir -p ${Geno_1KG_dir}/keep_files

module add general/R/3.5.0
R

Pipeline_prep.var&lt;-read.table(&#39;/users/k1806347/brc_scratch/Software/MyGit/GenoPred/Variables_used/Pipeline_prep.var&#39;)

Geno_1KG_dir&lt;-Pipeline_prep.var$V2[Pipeline_prep.var$V1 == &#39;Geno_1KG_dir&#39;]

pop_data&lt;-read.table(paste0(Geno_1KG_dir, &#39;/integrated_call_samples_v3.20130502.ALL.panel&#39;), header=T, stringsAsFactors=F)

for(i in unique(pop_data$pop)){
  write.table(cbind(pop_data$sample[pop_data$pop == i],pop_data$sample[pop_data$pop == i]), paste0(Geno_1KG_dir,&#39;/keep_files/&#39;,i,&#39;_samples.keep&#39;), col.names=F, row.names=F, quote=F)
}

for(i in unique(pop_data$super_pop)){
  write.table(cbind(pop_data$sample[pop_data$super_pop == i],pop_data$sample[pop_data$super_pop == i]), paste0(Geno_1KG_dir,&#39;/keep_files/&#39;,i,&#39;_samples.keep&#39;), col.names=F, row.names=F, quote=F)
}

# Create a file listing all ancestry groups
write.table(unique(pop_data$super_pop), paste0(Geno_1KG_dir,&#39;/super_pop.list&#39;), col.names=F, row.names=F, quote=F)
write.table(unique(pop_data$pop), paste0(Geno_1KG_dir,&#39;/pop.list&#39;), col.names=F, row.names=F, quote=F)

# Create a file listing the code of each population and the location of the keep file
pop_keep_loc&lt;-data.frame(pop=unique(pop_data$pop))
pop_keep_loc$keep&lt;-paste0(Geno_1KG_dir,&#39;/keep_files/&#39;,pop_keep_loc$pop,&#39;_samples.keep&#39;)

super_pop_keep_loc&lt;-data.frame(pop=unique(pop_data$super_pop))
super_pop_keep_loc$keep&lt;-paste0(Geno_1KG_dir, &#39;/keep_files/&#39;,super_pop_keep_loc$pop,&#39;_samples.keep&#39;)

write.table(super_pop_keep_loc, paste0(Geno_1KG_dir,&#39;/super_pop_keep.list&#39;), col.names=F, row.names=F, quote=F)
write.table(pop_keep_loc, paste0(Geno_1KG_dir,&#39;/pop_keep.list&#39;), col.names=F, row.names=F, quote=F)
write.table(rbind(super_pop_keep_loc,pop_keep_loc), paste0(Geno_1KG_dir,&#39;/super_pop_and_pop_keep.list&#39;), col.names=F, row.names=F, quote=F)
q()
n</code></pre>
</details>
<p><br/></p>
<hr />
<p><br/></p>
</div>
<div id="genomes-plink-files" class="section level2">
<h2><span class="header-section-number">2.4</span> 1000 Genomes PLINK files</h2>
<p>Here we download the 1000 Genomes Phase 3 data in vcf format, convert into PLINK binary format, and extract variants in the HapMap3 SNP-list. This data is used to estimate LD-structure and minor allele frequencies. We also estimate genotype-based scores within the reference data to determine the mean and standard deviation of the genotype-based scores within specific ancestral groups. This can then be used to standardise genotype-based scores in the target sample which enables improved interpretation of the scores and ensure scores from diverse sources are on the same scale when performing prediction modelling.</p>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>cd ${Geno_1KG_dir}

# Download the vcf files, convert to plink, extract hapmap3 snps, and delete vcfs
for chr in $(seq 1 22); do
wget http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr${chr}.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz
done

for chr in $(seq 1 22); do
qsub /users/k1806347/brc_scratch/Software/plink1.9.sh \
  --vcf ${Geno_1KG_dir}/ALL.chr${chr}.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz \
  --make-bed \
  --out ${Geno_1KG_dir}/1KGPhase3.chr${chr}
done  

# Delete the vcf files after conversion to plink format is complete
rm ${Geno_1KG_dir}/ALL.chr*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

# Use R to identify a list of SNPs that matches with the hapmap3 snplist
qrsh
module add general/R/3.5.0
R

Pipeline_prep.var&lt;-read.table(&#39;/users/k1806347/brc_scratch/Software/MyGit/GenoPred/Variables_used/Pipeline_prep.var&#39;)
Geno_1KG_dir&lt;-Pipeline_prep.var$V2[Pipeline_prep.var$V1 == &#39;Geno_1KG_dir&#39;]
HapMap3_snplist_dir&lt;-Pipeline_prep.var$V2[Pipeline_prep.var$V1 == &#39;HapMap3_snplist_dir&#39;]

library(data.table)
hapmap3_snps&lt;-fread(paste0(HapMap3_snplist_dir,&#39;/w_hm3.snplist&#39;))

# Generate IUPAC codes
hapmap3_snps$IUPAC[hapmap3_snps$A1 == &#39;A&#39; &amp; hapmap3_snps$A2 ==&#39;T&#39; | hapmap3_snps$A1 == &#39;T&#39; &amp; hapmap3_snps$A2 ==&#39;A&#39;]&lt;-&#39;W&#39;
hapmap3_snps$IUPAC[hapmap3_snps$A1 == &#39;C&#39; &amp; hapmap3_snps$A2 ==&#39;G&#39; | hapmap3_snps$A1 == &#39;G&#39; &amp; hapmap3_snps$A2 ==&#39;C&#39;]&lt;-&#39;S&#39;
hapmap3_snps$IUPAC[hapmap3_snps$A1 == &#39;A&#39; &amp; hapmap3_snps$A2 ==&#39;G&#39; | hapmap3_snps$A1 == &#39;G&#39; &amp; hapmap3_snps$A2 ==&#39;A&#39;]&lt;-&#39;R&#39;
hapmap3_snps$IUPAC[hapmap3_snps$A1 == &#39;C&#39; &amp; hapmap3_snps$A2 ==&#39;T&#39; | hapmap3_snps$A1 == &#39;T&#39; &amp; hapmap3_snps$A2 ==&#39;C&#39;]&lt;-&#39;Y&#39;
hapmap3_snps$IUPAC[hapmap3_snps$A1 == &#39;G&#39; &amp; hapmap3_snps$A2 ==&#39;T&#39; | hapmap3_snps$A1 == &#39;T&#39; &amp; hapmap3_snps$A2 ==&#39;G&#39;]&lt;-&#39;K&#39;
hapmap3_snps$IUPAC[hapmap3_snps$A1 == &#39;A&#39; &amp; hapmap3_snps$A2 ==&#39;C&#39; | hapmap3_snps$A1 == &#39;C&#39; &amp; hapmap3_snps$A2 ==&#39;A&#39;]&lt;-&#39;M&#39;

hapmap3_snps$SNP_IUPAC&lt;-paste(hapmap3_snps$SNP,hapmap3_snps$IUPAC,sep=&#39;:&#39;)

# For each chr
for(chr in 1:22){
    bim&lt;-fread(paste0(Geno_1KG_dir,&#39;/1KGPhase3.chr&#39;,chr,&#39;.bim&#39;))

    bim$IUPAC[bim$V5 == &#39;A&#39; &amp; bim$V6 ==&#39;T&#39; | bim$V5 == &#39;T&#39; &amp; bim$V6 ==&#39;A&#39;]&lt;-&#39;W&#39;
    bim$IUPAC[bim$V5 == &#39;C&#39; &amp; bim$V6 ==&#39;G&#39; | bim$V5 == &#39;G&#39; &amp; bim$V6 ==&#39;C&#39;]&lt;-&#39;S&#39;
    bim$IUPAC[bim$V5 == &#39;A&#39; &amp; bim$V6 ==&#39;G&#39; | bim$V5 == &#39;G&#39; &amp; bim$V6 ==&#39;A&#39;]&lt;-&#39;R&#39;
    bim$IUPAC[bim$V5 == &#39;C&#39; &amp; bim$V6 ==&#39;T&#39; | bim$V5 == &#39;T&#39; &amp; bim$V6 ==&#39;C&#39;]&lt;-&#39;Y&#39;
    bim$IUPAC[bim$V5 == &#39;G&#39; &amp; bim$V6 ==&#39;T&#39; | bim$V5 == &#39;T&#39; &amp; bim$V6 ==&#39;G&#39;]&lt;-&#39;K&#39;
    bim$IUPAC[bim$V5 == &#39;A&#39; &amp; bim$V6 ==&#39;C&#39; | bim$V5 == &#39;C&#39; &amp; bim$V6 ==&#39;A&#39;]&lt;-&#39;M&#39;

    bim$SNP_IUPAC&lt;-paste(bim$V2,bim$IUPAC,sep=&#39;:&#39;)
    
    bim_hapmap3_snps&lt;-merge(hapmap3_snps,bim,by=&#39;SNP_IUPAC&#39;)
    sum(duplicated(bim_hapmap3_snps$V2))
    
    bim$V2[!(bim$SNP_IUPAC %in% bim_hapmap3_snps$SNP_IUPAC)] &lt;- paste0(bim$V2[!(bim$SNP_IUPAC %in% bim_hapmap3_snps$SNP_IUPAC)],&#39;_excl&#39;)
    bim[!(bim$SNP_IUPAC %in% bim_hapmap3_snps$SNP_IUPAC),]
    
    fwrite(bim[,1:6], paste0(Geno_1KG_dir,&#39;/1KGPhase3.chr&#39;,chr,&#39;.bim&#39;), sep=&#39;\t&#39;, col.names=F)
    fwrite(as.list(bim_hapmap3_snps$V2), paste0(Geno_1KG_dir,&#39;/1KGPhase3.chr&#39;,chr,&#39;.extract&#39;), sep=&#39;\n&#39;, col.names=F)   
}

q()
n

for chr in $(seq 1 22); do
qsub /users/k1806347/brc_scratch/Software/plink1.9.sh \
  --bfile ${Geno_1KG_dir}/1KGPhase3.chr${chr} \
  --make-bed \
  --extract ${Geno_1KG_dir}/1KGPhase3.chr$chr.extract \
  --out ${Geno_1KG_dir}/1KGPhase3.w_hm3.chr${chr}
done

rm ${Geno_1KG_dir}/1KGPhase3.chr*

# Create version that is all chromosomes merged
ls ${Geno_1KG_dir}/1KGPhase3.w_hm3.chr*.bed | sed -e &#39;s/\.bed//g&#39; &gt; ${Geno_1KG_dir}/merge_list.txt

/users/k1806347/brc_scratch/Software/plink1.9.sh \
  --merge-list ${Geno_1KG_dir}/merge_list.txt \
  --make-bed \
  --out ${Geno_1KG_dir}/1KGPhase3.w_hm3.GW</code></pre>
</details>
<p><br/></p>
<hr />
<p><br/></p>
</div>
<div id="genomes-allele-frequency-files" class="section level2">
<h2><span class="header-section-number">2.5</span> 1000 Genomes allele frequency files</h2>
<p>Here we create files containing ancestry specific minor allele frequency estimates for the HapMap3 SNPs based on the 1000 Genomes Phase 3 data. This information is mainly used for mean-imputation of missing SNPs during genotype-based scoring. This avoids target sample specific minor allele frequencies being used for mean imputation which may not be available, and will vary between target samples.</p>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code># The following script uses .sumstats.gz files produced by the LDSC munge_sumstats.py
for pop in $(cat ${Geno_1KG_dir}/super_pop.list); do
mkdir -p ${Geno_1KG_dir}/freq_files/${pop}
for chr in $(seq 1 22); do
qsub /users/k1806347/brc_scratch/Software/plink1.9.sh \
    --bfile ${Geno_1KG_dir}/1KGPhase3.w_hm3.chr${chr} \
    --freq \
    --keep ${Geno_1KG_dir}/keep_files/${pop}_samples.keep \
    --out ${Geno_1KG_dir}/freq_files/${pop}/1KGPhase3.w_hm3.${pop}.chr${chr}
done
done

for pop in $(cat ${Geno_1KG_dir}/pop.list); do
mkdir -p ${Geno_1KG_dir}/freq_files/${pop}
for chr in $(seq 1 22); do
qsub /users/k1806347/brc_scratch/Software/plink1.9.sh \
    --bfile ${Geno_1KG_dir}/1KGPhase3.w_hm3.chr${chr} \
    --freq \
    --keep ${Geno_1KG_dir}/keep_files/${pop}_samples.keep \
    --out ${Geno_1KG_dir}/freq_files/${pop}/1KGPhase3.w_hm3.${pop}.chr${chr}
done
done

# Calculate MAF across all populations
mkdir ${Geno_1KG_dir}/freq_files/AllAncestry
for chr in $(seq 1 22); do
qsub /users/k1806347/brc_scratch/Software/plink1.9.sh \
    --bfile ${Geno_1KG_dir}/1KGPhase3.w_hm3.chr${chr} \
    --freq \
    --out ${Geno_1KG_dir}/freq_files/AllAncestry/1KGPhase3.w_hm3.AllAncestry.chr${chr}
done

# Delete the log and nosex files
rm ${Geno_1KG_dir}/freq_files/*/1KGPhase3.w_hm3.*.chr*.log
rm ${Geno_1KG_dir}/freq_files/*/1KGPhase3.w_hm3.*.chr*.nosex</code></pre>
</details>
<p><br/></p>
<hr />
<p><br/></p>
</div>
</div>
<div id="ancestry-scoring" class="section level1">
<h1><span class="header-section-number">3</span> Ancestry scoring</h1>
<p>In this section we perform principal components analysis of genotypic data in the 1000 Genomes reference to identify the main axes of population structure, which typically correspond to ancestral differences. We calculate these principal components (PCs) of ancestry across the full reference, and within super populations to detect broad and ancestry-specific axes of variance. After PCA, we idenitfy which variants are associated with the PCs (SNP-weights) to calculate ancestry scores on the same axes of variance in future target samples. This can be used to infer the ancestry of an individual which is an important factor to consider when performing genotype-baed prediction.</p>
<p>This section uses an R script called ‘ancestry_score_file_creator.R’. Further information the usage of this script can be found <a href="https://github.com/opain/GenoPred/tree/master/Scripts/ancestry_score_file_creator">here</a>.</p>
<details>
<p><summary>Set required variables</summary></p>
<pre class="bash"><code># Set variables
Geno_1KG_dir=$(sed -n &#39;/Geno_1KG_dir/p&#39; /users/k1806347/brc_scratch/Software/MyGit/GenoPred/Variables_used/Pipeline_prep.var | cut -d &#39; &#39; -f 2)
plink1_9=$(sed -n &#39;/plink1_9/p&#39; /users/k1806347/brc_scratch/Software/MyGit/GenoPred/Variables_used/Pipeline_prep.var | cut -d &#39; &#39; -f 2)
plink2=$(sed -n &#39;/plink2/p&#39; /users/k1806347/brc_scratch/Software/MyGit/GenoPred/Variables_used/Pipeline_prep.var | cut -d &#39; &#39; -f 2)</code></pre>
<details>
<p><summary>Show code for ancestry scoring</summary></p>
<pre class="bash"><code># Create score files for European specific PCs, and scaling files for Europeans
qsub /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/MyGit/GenoPred/Scripts/ancestry_score_file_creator/ancestry_score_file_creator.R \
    --ref_plink_chr ${Geno_1KG_dir}/1KGPhase3.w_hm3.chr \
    --ref_keep ${Geno_1KG_dir}/keep_files/EUR_samples.keep \
    --plink ${plink1_9} \
    --plink2 ${plink2} \
    --n_pcs 100 \
    --output ${Geno_1KG_dir}/Score_files_for_ancestry/EUR/1KGPhase3.w_hm3.EUR

# Create score files for all ancestry PCs, and scaling files for each super population
qsub /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/MyGit/GenoPred/Scripts/Pipeline_prep/ancestry_score_file_creator.R \
    --ref_plink_chr ${Geno_1KG_dir}/1KGPhase3.w_hm3.chr \
    --plink ${plink1_9} \
    --plink2 ${plink2} \
    --n_pcs 100 \
    --ref_pop_scale ${Geno_1KG_dir}/super_pop_keep.list \
    --output ${Geno_1KG_dir}/Score_files_for_ancestry/AllAncestry/1KGPhase3.w_hm3.AllAncestry</code></pre>
</details>
<p><br/></p>
<hr />
<p><br/></p>
</div>
<div id="polygenic-scoring" class="section level1">
<h1><span class="header-section-number">4</span> Polygenic scoring</h1>
<div id="create-repository-of-ldsc-format-gwas-summary-statistics" class="section level2">
<h2><span class="header-section-number">4.1</span> Create repository of LDSC format GWAS summary statistics</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code># This has already been prepared by Helena Gaspar
###
# Select which GWAS we want to include which don&#39;t include UKBB
###
module add general/R/3.5.0
R
pheno&lt;-read.csv(&#39;/users/k1806347/brc_scratch/Data/GWAS_sumstats/QC_sumstats_list_031218.csv&#39;, stringsAsFactors=F)
pheno_brief&lt;-pheno[c(&#39;Code&#39;,&#39;phenotype_category&#39;,&#39;trait&#39;,&#39;sample_size_discovery&#39;,&#39;Ncases&#39;,&#39;Ncontrols&#39;,&#39;sex&#39;,&#39;consortium&#39;,&#39;year&#39;,&#39;UK.Biobank&#39;,&#39;h2.observed&#39;,&#39;ancestry&#39;,&#39;PRS.created&#39;)]

pheno_brief$sample_size_discovery&lt;-gsub(&#39;,&#39;,&#39;&#39;,pheno_brief$sample_size_discovery)

# Extract those that have LDSC sumstats (this removes those where sumstats are unavailable)
pheno_brief$sample_size_discovery&lt;-as.numeric(pheno_brief$sample_size_discovery)

# Exclude GWAS containing UKBB as this is our target sample
pheno_brief&lt;-pheno_brief[which(pheno_brief$UK.Biobank == &#39;no&#39;),]
pheno_brief&lt;-pheno_brief[!is.na(as.numeric(pheno_brief$h2.observed)),]

# BLOO GWAS are mislabelled as not containing UKBB. Remove them.
pheno_brief&lt;-pheno_brief[!(grepl(&#39;BLOO&#39;,pheno_brief$Code)),]

# INTE02, INTE03, all EDUC, GWAS are mislabelled as not containing UKBB. Remove them.
pheno_brief&lt;-pheno_brief[!(grepl(&#39;BLOO|INTE02|INTE03|EDUC&#39;,pheno_brief$Code)),]

# Extract the largest GWAS for each phenotype
pheno_brief_bigest&lt;-NULL
for(i in unique(pheno_brief$trait)){
  tmp&lt;-pheno_brief[pheno_brief$trait == i,]
  tmp&lt;-tmp[rev(order(tmp$sample_size_discovery)),]
  pheno_brief_bigest&lt;-rbind(pheno_brief_bigest,tmp[1,])
}

# Extract those with sample size &gt;15000
pheno_brief_bigest_big&lt;-pheno_brief_bigest[pheno_brief_bigest$sample_size_discovery &gt; 15000,]

# Remove GWAS from MAGNETIC as we are not looking at cardiometabolic traits and is excessive.
pheno_brief_bigest_big_nomag&lt;-pheno_brief_bigest_big[pheno_brief_bigest_big$consortium !=&#39;MAGNETIC&#39;,]

pheno_brief_bigest_big_nomag$gwas_list&lt;-paste0(&#39;/mnt/lustre/groups/ukbiobank/sumstats/munged/&#39;,pheno_brief_bigest_big_nomag$Code,&#39;.sumstats.gz&#39;)

write.table(pheno_brief_bigest_big_nomag[c(&#39;Code&#39;,&#39;gwas_list&#39;)], &#39;~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt&#39;, col.names=F, row.names=F, quote=F)

q()
n

# NOTE. The overlapping with UKBB variable is unreliable and should be checked using the LDSC covariance intercept with outcome variables.

###
# Select which GWAS we want to include which don&#39;t include TEDS
###
module add general/R/3.5.0
R
pheno&lt;-read.csv(&#39;/users/k1806347/brc_scratch/Data/GWAS_sumstats/QC_sumstats_list_031218.csv&#39;, stringsAsFactors=F)
pheno_brief&lt;-pheno[c(&#39;Code&#39;,&#39;phenotype_category&#39;,&#39;trait&#39;,&#39;sample_size_discovery&#39;,&#39;Ncases&#39;,&#39;Ncontrols&#39;,&#39;sex&#39;,&#39;consortium&#39;,&#39;year&#39;,&#39;UK.Biobank&#39;,&#39;h2.observed&#39;,&#39;ancestry&#39;,&#39;PRS.created&#39;)]

pheno_brief$sample_size_discovery&lt;-gsub(&#39;,&#39;,&#39;&#39;,pheno_brief$sample_size_discovery)

# Extract those that have LDSC sumstats (this removes those where sumstats are unavailable)
pheno_brief$sample_size_discovery&lt;-as.numeric(pheno_brief$sample_size_discovery)

# Remove GWAS containing TEDS individuals
pheno_brief&lt;-pheno_brief[!grepl(&#39;EDUC04|EDUC03&#39;, pheno_brief$Code),]

# Remove BLOO GWASs as there are lot of them and unnecessary for our purposes.
pheno_brief&lt;-pheno_brief[!grepl(&#39;BLOO&#39;, pheno_brief$Code),]

# Remove BLOP, CROH03 and DIAB01 GWASs
pheno_brief&lt;-pheno_brief[!grepl(&#39;BLOP|CROH03|DIAB01&#39;, pheno_brief$Code),]
 
# Remove entries with missing sample size information
pheno_brief&lt;-pheno_brief[!is.na(pheno_brief$sample_size_discovery),]

# Extract the most recent and largest GWAS for each phenotype
pheno_brief_bigest&lt;-NULL
for(i in unique(pheno_brief$trait)){
  tmp&lt;-pheno_brief[pheno_brief$trait == i,]
  tmp&lt;-tmp[rev(order(tmp$sample_size_discovery)),]
  pheno_brief_bigest&lt;-rbind(pheno_brief_bigest,tmp[1,])
}

# Extract those with sample size &gt;15000
pheno_brief_bigest_big&lt;-pheno_brief_bigest[pheno_brief_bigest$sample_size_discovery &gt; 15000,]

# Remove GWAS from MAGNETIC as we are not looking at cardiometabolic traits and is excessive.
pheno_brief_bigest_big_nomag&lt;-pheno_brief_bigest_big[pheno_brief_bigest_big$consortium !=&#39;MAGNETIC&#39;,]

pheno_brief_bigest_big_nomag$gwas_list&lt;-paste0(&#39;/mnt/lustre/groups/ukbiobank/sumstats/munged/&#39;,pheno_brief_bigest_big_nomag$Code,&#39;.sumstats.gz&#39;)

write.table(pheno_brief_bigest_big_nomag[c(&#39;Code&#39;,&#39;gwas_list&#39;)], &#39;~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutTEDS.txt&#39;, col.names=F, row.names=F, quote=F)

q()
n</code></pre>
</details>
<p><br/></p>
<hr />
<p><br/></p>
</div>
<div id="prepare-score-files-and-scaling-files-for-polygenic-scoring" class="section level2">
<h2><span class="header-section-number">4.2</span> Prepare score files and scaling files for polygenic scoring</h2>
<p>The score files should be based on the LD structure of the ancestry matching the GWAS (typically European). The following script uses .sumstats.gz files produced by the LDSC munge_sumstats.py.</p>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>###
# Run for all in ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt
###
# Create file listing GWAS that haven&#39;t been processed.
&gt; ${Geno_1KG_dir}/Score_files_for_poylygenic/todo.txt
for gwas in $(cut -f 1 -d &#39; &#39; ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt);do
if [ ! -f ${Geno_1KG_dir}/Score_files_for_poylygenic/${gwas}/1KGPhase3.w_hm3.${gwas}.EUR.scale ]; then
echo $gwas &gt;&gt; ${Geno_1KG_dir}/Score_files_for_poylygenic/todo.txt
fi
done

n=0
for gwas in $(cat ${Geno_1KG_dir}/Score_files_for_poylygenic/todo.txt);do
qsub -N $(echo job$(($n+20))) -hold_jid $(echo job$(($n+0))) -l h_vmem=6G /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/polygenic_score_file_creator.R \
--ref_plink_chr ${Geno_1KG_dir}/1KGPhase3.w_hm3.chr \
--ref_keep ${Geno_1KG_dir}/keep_files/EUR_samples.keep \
--sumstats /mnt/lustre/groups/ukbiobank/sumstats/munged/${gwas}.sumstats.gz \
--plink /users/k1806347/brc_scratch/Software/plink1.9.sh \
--memory 3000 \
--output ${Geno_1KG_dir}/Score_files_for_poylygenic/${gwas}/1KGPhase3.w_hm3.${gwas} \
--ref_pop_scale ${Geno_1KG_dir}/super_pop_keep.list
n=$(($n+1))
done

###
# Run for all in ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutTEDS.txt
###
&gt; ${Geno_1KG_dir}/Score_files_for_poylygenic/todo.txt
for gwas in $(cut -f 1 -d &#39; &#39; ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutTEDS.txt);do
if [ ! -f ${Geno_1KG_dir}/Score_files_for_poylygenic/${gwas}/1KGPhase3.w_hm3.${gwas}.EUR.scale ]; then
echo $gwas &gt;&gt; ${Geno_1KG_dir}/Score_files_for_poylygenic/todo.txt
fi
done

n=0
for gwas in $(cat ${Geno_1KG_dir}/Score_files_for_poylygenic/todo.txt);do
qsub -N $(echo job$(($n+5))) -hold_jid $(echo job$(($n+0))) -l h_vmem=6G /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/polygenic_score_file_creator.R \
    --ref_plink_chr ${Geno_1KG_dir}/1KGPhase3.w_hm3.chr \
    --ref_keep ${Geno_1KG_dir}/keep_files/EUR_samples.keep \
    --sumstats /mnt/lustre/groups/ukbiobank/sumstats/munged/${gwas}.sumstats.gz \
    --plink /users/k1806347/brc_scratch/Software/plink1.9.sh \
  --memory 3000 \
    --output ${Geno_1KG_dir}/Score_files_for_poylygenic/${gwas}/1KGPhase3.w_hm3.${gwas} \
    --ref_pop_scale ${Geno_1KG_dir}/super_pop_keep.list
n=$(($n+1))
done</code></pre>
</details>
<p><br/></p>
<hr />
<p><br/></p>
</div>
<div id="prepare-score-files-and-scaling-files-for-polygenic-scoring-using-lassosum" class="section level2">
<h2><span class="header-section-number">4.3</span> Prepare score files and scaling files for polygenic scoring using lassosum</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>###
# Run for all in ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt
###
mkdir ${Geno_1KG_dir}/Score_files_for_poylygenic_lassosum
&gt; ${Geno_1KG_dir}/Score_files_for_poylygenic_lassosum/todo.txt
# for gwas in $(cut -f 1 -d &#39; &#39; ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt);do
for gwas in $(echo DEPR06 COLL01 HEIG03 BODY03);do
if [ ! -f ${Geno_1KG_dir}/Score_files_for_poylygenic_lassosum/${gwas}/1KGPhase3.w_hm3.${gwas}.EUR.scale ]; then
echo $gwas &gt;&gt; ${Geno_1KG_dir}/Score_files_for_poylygenic_lassosum/todo.txt
fi
done

n=0
for gwas in $(cat ${Geno_1KG_dir}/Score_files_for_poylygenic_lassosum/todo.txt);do
qsub -N $(echo job$(($n+5))) -hold_jid $(echo job$(($n+0))) -l h_vmem=10G /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/polygenic_score_file_creator_lassosum.R \
    --ref_plink_gw ${Geno_1KG_dir}/1KGPhase3.w_hm3.GW \
    --ref_keep ${Geno_1KG_dir}/keep_files/EUR_samples.keep \
    --sumstats /mnt/lustre/groups/ukbiobank/sumstats/munged/${gwas}.sumstats.gz \
    --output ${Geno_1KG_dir}/Score_files_for_poylygenic_lassosum/${gwas}/1KGPhase3.w_hm3.${gwas} \
    --ref_pop_scale ${Geno_1KG_dir}/super_pop_keep.list
n=$(($n+1))
done

# Lassosum pseudovalidation does not seem to perform well.</code></pre>
</details>
<p><br/></p>
<hr />
<p><br/></p>
</div>
<div id="prepare-score-and-scale-files-for-polygenic-scoring-using-prscs" class="section level2">
<h2><span class="header-section-number">4.4</span> Prepare score and scale files for polygenic scoring using PRScs</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>cd /users/k1806347/brc_scratch/Software
# Download software
git clone ssh://git@github.com/getian107/PRScs.git
# Download required reference data
wget https://www.dropbox.com/s/p9aqanhxvxaqv8k/ldblk_1kg_eur.tar.gz?dl=0
tar xvzf ldblk_1kg_eur.tar.gz?dl=0

mkdir ${Geno_1KG_dir}/Score_files_for_poylygenic_PRScs

&gt; ${Geno_1KG_dir}/Score_files_for_poylygenic_PRScs/todo.txt
#for gwas in $(cut -f 1 -d &#39; &#39; ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt);do
for gwas in $(echo DEPR06 COLL01 HEIG03 BODY03);do
if [ ! -f ${Geno_1KG_dir}/Score_files_for_poylygenic_PRScs/${gwas}/1KGPhase3.w_hm3.${gwas}.EUR.scale ]; then
echo $gwas &gt;&gt; ${Geno_1KG_dir}/Score_files_for_poylygenic_PRScs/todo.txt
fi
done

n=0
for gwas in $(cat ${Geno_1KG_dir}/Score_files_for_poylygenic_PRScs/todo.txt);do
qsub -N $(echo job$(($n+15))) -hold_jid $(echo job$(($n+0))) -pe smp 6 -l h_vmem=6G /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/polygenic_score_file_creator_PRScs.R \
--ref_plink_chr ${Geno_1KG_dir}/1KGPhase3.w_hm3.chr \
--ref_keep ${Geno_1KG_dir}/keep_files/EUR_samples.keep \
--sumstats /mnt/lustre/groups/ukbiobank/sumstats/munged/${gwas}.sumstats.gz \
--plink /users/k1806347/brc_scratch/Software/plink1.9.sh \
--memory 5000 \
--output ${Geno_1KG_dir}/Score_files_for_poylygenic_PRScs/${gwas}/1KGPhase3.w_hm3.${gwas} \
--ref_pop_scale ${Geno_1KG_dir}/super_pop_keep.list \
--PRScs_path /users/k1806347/brc_scratch/Software/PRScs/PRScs.py \
--PRScs_ref_path /users/k1806347/brc_scratch/Software/PRScs/ldblk_1kg_eur \
--n_cores 6 \
--phi_param 1e-6,1e-4,1e-2,1,auto
n=$(($n+1))
done</code></pre>
</details>
<p><br/></p>
<hr />
<p><br/></p>
</div>
</div>
<div id="functionally-informed-polygenic-scoring" class="section level1">
<h1><span class="header-section-number">5</span> Functionally-informed polygenic scoring</h1>
<div id="perform-twas-using-all-tissue-data-and-gwas" class="section level2">
<h2><span class="header-section-number">5.1</span> Perform TWAS using all tissue data and GWAS</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>mkdir -p ~/brc_scratch/Data/TWAS_sumstats/FUSION

module add general/R/3.5.0
R

library(data.table)

# Read in full list of SNP-weights
weights&lt;-list.files(path=&#39;/mnt/lustre/groups/biomarkers-brc-mh/TWAS_resource/FUSION/SNP-weights/.&#39;, recursive=F)

# Write a file listing all SNP-weight sets.
write.table(weights, &#39;~/brc_scratch/Data/TWAS_sumstats/FUSION/snp_weight_list.txt&#39;, col.names=F, row.names=F, quote=F)

# Create a .pos file containing SNP-weights for all tissues.
pos&lt;-NULL
for(i in weights){
  pos_tmp&lt;-data.frame(fread(paste0(&#39;/mnt/lustre/groups/biomarkers-brc-mh/TWAS_resource/FUSION/SNP-weights/&#39;,i,&#39;/&#39;,i,&#39;.pos&#39;)))
  pos_tmp$PANEL&lt;-i
  pos_tmp$WGT&lt;-paste0(i,&#39;/&#39;,pos_tmp$WGT)
  pos&lt;-rbind(pos,pos_tmp[c(&#39;PANEL&#39;,&#39;WGT&#39;,&#39;ID&#39;,&#39;CHR&#39;,&#39;P0&#39;,&#39;P1&#39;)])
}

write.table(pos, &#39;~/brc_scratch/Data/TWAS_sumstats/FUSION/All_tissues.pos&#39;, col.names=T, row.names=F, quote=F)

q()
n

# Perform TWAS for all selected GWAS and all tissues
# Create file listing GWAS that haven&#39;t been converted to TWAS
###
# Run for all in ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt
###
&gt; ~/brc_scratch/Data/TWAS_sumstats/FUSION/todo.txt
for gwas in $(cut -f 1 -d &#39; &#39; ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt);do
if [ ! -f ~/brc_scratch/Data/TWAS_sumstats/FUSION/${gwas}/${gwas}_res_GW.txt ]; then
grep $gwas ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt &gt;&gt; ~/brc_scratch/Data/TWAS_sumstats/FUSION/todo.txt
fi
done

qsub -l h_vmem=6G -pe smp 8 -tc 3 -t 1-$(wc -l ~/brc_scratch/Data/TWAS_sumstats/FUSION/todo.txt | cut -d&#39; &#39; -f1) /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/Run_TWAS_new.sh \
  --gwas_list ~/brc_scratch/Data/TWAS_sumstats/FUSION/todo.txt \
  --pos ~/brc_scratch/Data/TWAS_sumstats/FUSION/All_tissues.pos \
  --outdir ~/brc_scratch/Data/TWAS_sumstats/FUSION \
  --ncores 8
  
# Create a list of TWAS that have less than 25% missing TWAS.Z
module add general/R/3.5.0
R
library(data.table)
gwas&lt;-fread(&#39;~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt&#39;, header=F)$V1
twas_comp&lt;-NULL
twas_incomp&lt;-NULL
for(gwas_name in gwas){
    twas&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/&#39;,gwas_name,&#39;/&#39;,gwas_name,&#39;_res_GW.txt&#39;))
    if((sum(is.na(twas$TWAS.Z)) / dim(twas)[1]) &lt; 0.25){
        twas_comp&lt;-c(twas_comp,gwas_name)
    } else {
        twas_incomp&lt;-c(twas_incomp,gwas_name)
    }
}

write.table(twas_comp, &#39;/users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/Largest_TWAS_over15K_withoutUKBB_75comp.txt&#39;, col.names=F, row.names=F, quote=F)
q()
n

###
# Run for all in ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutTEDS.txt
###
&gt; ~/brc_scratch/Data/TWAS_sumstats/FUSION/todo.txt
for gwas in $(cut -f 1 -d &#39; &#39; ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutTEDS.txt);do
if [ ! -f ~/brc_scratch/Data/TWAS_sumstats/FUSION/${gwas}/${gwas}_res_GW.txt ]; then
grep $gwas ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutTEDS.txt &gt;&gt; ~/brc_scratch/Data/TWAS_sumstats/FUSION/todo.txt
fi
done

qsub -l h_vmem=6G -pe smp 8 -tc 3 -t 1-$(wc -l ~/brc_scratch/Data/TWAS_sumstats/FUSION/todo.txt | cut -d&#39; &#39; -f1) /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/Run_TWAS_new.sh \
  --gwas_list ~/brc_scratch/Data/TWAS_sumstats/FUSION/todo.txt \
  --pos ~/brc_scratch/Data/TWAS_sumstats/FUSION/All_tissues.pos \
  --outdir ~/brc_scratch/Data/TWAS_sumstats/FUSION \
  --ncores 8
  
# Create a list of TWAS that have less than 25% missing TWAS.Z
module add general/R/3.5.0
R
library(data.table)
gwas&lt;-fread(&#39;~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutTEDS.txt&#39;, header=F)$V1
twas_comp&lt;-NULL
twas_incomp&lt;-NULL
for(gwas_name in gwas){
    twas&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/&#39;,gwas_name,&#39;/&#39;,gwas_name,&#39;_res_GW.txt&#39;))
    if((sum(is.na(twas$TWAS.Z)) / dim(twas)[1]) &lt; 0.25){
        twas_comp&lt;-c(twas_comp,gwas_name)
    } else {
        twas_incomp&lt;-c(twas_incomp,gwas_name)
    }
}

write.table(twas_comp, &#39;/users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/Largest_TWAS_over15K_withoutTEDS_75comp.txt&#39;, col.names=F, row.names=F, quote=F)
q()
n</code></pre>
</details>
<p><br/></p>
<hr />
<p><br/></p>
</div>
<div id="predict-functional-genomic-features" class="section level2">
<h2><span class="header-section-number">5.2</span> Predict functional genomic features</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>mkdir -p ~/brc_scratch/Data/FUSION/SCORE_FILES

# Create SCORE files and expression reference.
qsub -pe smp 15 -l h_vmem=2G /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/FUSION_score_file_creator.R \
  --weights ~/brc_scratch/Data/TWAS_sumstats/FUSION/All_tissues.pos \
  --weights_dir /mnt/lustre/groups/biomarkers-brc-mh/TWAS_resource/FUSION/SNP-weights \
  --output ~/brc_scratch/Data/FUSION/SCORE_FILES \
  --n_cores 15

# Calculate features based on each SNP-weight set. To not swamp the cluster, submit only three weights at a time.
# Create file listing weights that haven&#39;t been predicted in the reference.
&gt; ${Geno_1KG_dir}/Predicted_expression/FUSION/todo.txt
for weights in $(cat ~/brc_scratch/Data/TWAS_sumstats/FUSION/snp_weight_list.txt);do
if [ ! -f ${Geno_1KG_dir}/Predicted_expression/FUSION/${weights}/1KGPhase3.w_hm3.FUSION.${weights}.predictions.gz ]; then
echo $weights &gt;&gt; ${Geno_1KG_dir}/Predicted_expression/FUSION/todo.txt
fi
done

n=0
for weights in $(cat ${Geno_1KG_dir}/Predicted_expression/FUSION/todo.txt);do
qsub -N $(echo job$(($n+2))) -hold_jid $(echo job$(($n+0))) -pe smp 5 -l h_vmem=8G /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/FUSION_ref_scorer.R \
  --ref_plink_chr ${Geno_1KG_dir}/1KGPhase3.w_hm3.chr \
  --weights /mnt/lustre/groups/biomarkers-brc-mh/TWAS_resource/FUSION/SNP-weights/${weights}/${weights}.pos \
  --output ${Geno_1KG_dir}/Predicted_expression/FUSION/${weights}/1KGPhase3.w_hm3.FUSION.${weights} \
  --plink ~/brc_scratch/Software/plink1.9.sh \
  --n_cores 5 \
  --pigz /users/k1806347/brc_scratch/Software/pigz.sh \
  --score_files ~/brc_scratch/Data/FUSION/SCORE_FILES \
  --ref_pop_scale ${Geno_1KG_dir}/super_pop_keep.list
n=$(($n+1))
done</code></pre>
</details>
<p><br/></p>
<hr />
<p><br/></p>
</div>
<div id="prepare-score-files-and-scaling-files-for-functionally-informed-polygenic-scores" class="section level2">
<h2><span class="header-section-number">5.3</span> Prepare score files and scaling files for functionally informed polygenic scores</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>######
# Calculate for /users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/Largest_TWAS_over15K_withoutUKBB_75comp.txt
######
&gt; ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/todo.txt
for gwas in $(cat /users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/Largest_TWAS_over15K_withoutUKBB_75comp.txt);do
for weights in $(cat ~/brc_scratch/Data/TWAS_sumstats/FUSION/snp_weight_list.txt);do
if [ ! -f ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/${gwas}/1KGPhase3.w_hm3.EUR.FUSION.${gwas}.${weights}.scale ]; then
echo $gwas $weights &gt;&gt; ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/todo.txt
fi
done
done

for i in $(seq 1 $(wc -l ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/todo.txt | cut -d &#39; &#39; -f 1));do
gwas=$(awk -v var=&quot;$i&quot; &#39;NR == var {print $1}&#39; ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/todo.txt)
weights=$(awk -v var=&quot;$i&quot; &#39;NR == var {print $2}&#39; ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/todo.txt)

qsub /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/ref_funtionally_informed_risk_scorer.R \
  --twas_results /users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/${gwas}/${gwas}_res_GW.txt \
  --ref_feature_pred ${Geno_1KG_dir}/Predicted_expression/FUSION/${weights}/1KGPhase3.w_hm3.FUSION.${weights}.predictions.gz \
  --output ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/${gwas}/1KGPhase3.w_hm3.EUR.FUSION.${gwas}.${weights} \
  --ref_keep ${Geno_1KG_dir}/keep_files/EUR_samples.keep \
  --ref_scale ${Geno_1KG_dir}/Predicted_expression/FUSION/${weights}/1KGPhase3.w_hm3.FUSION.${weights}.EUR.scale \
  --panel ${weights}

sleep 1
done
</code></pre>
</details>
<p><br/></p>
<hr />
<p><br/></p>
</div>
</div>
<div id="redundant-code-for-research" class="section level1">
<h1><span class="header-section-number">6</span> Redundant code for research</h1>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>###
# Calculate GeRSs weighting genes by R2 and TWAS.Z
###
&gt; ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/todo_R2weighted.txt
for gwas in $(cat /users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/Largest_TWAS_over15K_withoutUKBB_75comp.txt);do
for weights in $(cat ~/brc_scratch/Data/TWAS_sumstats/FUSION/snp_weight_list.txt);do
if [ ! -f ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/${gwas}/1KGPhase3.w_hm3.EUR.FUSION.${gwas}.${weights}.R2weighted.scale ]; then
echo $gwas $weights &gt;&gt; ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/todo_R2weighted.txt
fi
done
done

for i in $(seq 1 $(wc -l ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/todo_R2weighted.txt | cut -d &#39; &#39; -f 1));do
gwas=$(awk -v var=&quot;$i&quot; &#39;NR == var {print $1}&#39; ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/todo_R2weighted.txt)
weights=$(awk -v var=&quot;$i&quot; &#39;NR == var {print $2}&#39; ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/todo_R2weighted.txt)

qsub /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/ref_funtionally_informed_risk_scorer.R \
  --twas_results /users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/${gwas}/${gwas}_res_GW.txt \
  --ref_feature_pred ${Geno_1KG_dir}/Predicted_expression/FUSION/${weights}/1KGPhase3.w_hm3.FUSION.${weights}.predictions.gz \
  --output ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/${gwas}/1KGPhase3.w_hm3.EUR.FUSION.${gwas}.${weights}.R2weighted \
  --ref_keep ${Geno_1KG_dir}/keep_files/EUR_samples.keep \
  --ref_scale ${Geno_1KG_dir}/Predicted_expression/FUSION/${weights}/1KGPhase3.w_hm3.FUSION.${weights}.EUR.scale \
  --panel ${weights} \
  --r2_weighted T

sleep 5
done

# Experiment finished. Don&#39;t calculate R2 weighted GeRSs.
# Delete R2 weighted reference files

######
# Calculate all tissue GeRSs
######

# Create a file containing a list of gene expression files, and a list of scale files
ls ${Geno_1KG_dir}/Predicted_expression/FUSION/*/1KGPhase3.w_hm3.FUSION.*.predictions.gz &gt; ${Geno_1KG_dir}/Predicted_expression/FUSION/1KGPhase3.w_hm3.FUSION.predictions_list
ls ${Geno_1KG_dir}/Predicted_expression/FUSION/*/1KGPhase3.w_hm3.FUSION.*.EUR.scale &gt; ${Geno_1KG_dir}/Predicted_expression/FUSION/1KGPhase3.w_hm3.FUSION.EUR.scales_list

qrsh -l h_vmem=25G
module add general/R/3.5.0
module add compilers/gcc/8.1.0
module add general/python/2.7.10
R

qsub -l h_vmem=30G /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/ref_funtionally_informed_risk_scorer.R \
  --twas_results /users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/DEPR07/DEPR07_res_GW.txt \
  --ref_feature_pred ${Geno_1KG_dir}/Predicted_expression/FUSION/1KGPhase3.w_hm3.FUSION.predictions_list \
  --output ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/DEPR07/1KGPhase3.w_hm3.EUR.FUSION.DEPR07.AllTissue \
  --ref_keep ${Geno_1KG_dir}/keep_files/EUR_samples.keep \
  --ref_scale ${Geno_1KG_dir}/Predicted_expression/FUSION/1KGPhase3.w_hm3.FUSION.EUR.scales_list

######
# Calculate for /users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/Largest_TWAS_over15K_withoutTEDS_75comp.txt
######

&gt; ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/todo.txt
# for gwas in $(cat /users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/Largest_TWAS_over15K_withoutTEDS_75comp.txt);do
for gwas in $(echo ADHD02 BODY11 HEIG03 INTE03);do
for weights in $(cat ~/brc_scratch/Data/TWAS_sumstats/FUSION/snp_weight_list.txt);do
if [ ! -f ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/${gwas}/1KGPhase3.w_hm3.EUR.FUSION.${gwas}.${weights}.scale ]; then
echo $gwas $weights &gt;&gt; ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/todo.txt
fi
done
done

for i in $(seq 1 $(wc -l ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/todo.txt | cut -d &#39; &#39; -f 1));do
gwas=$(awk -v var=&quot;$i&quot; &#39;NR == var {print $1}&#39; ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/todo.txt)
weights=$(awk -v var=&quot;$i&quot; &#39;NR == var {print $2}&#39; ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/todo.txt)

qsub /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/ref_funtionally_informed_risk_scorer.R \
  --twas_results /users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/${gwas}/${gwas}_res_GW.txt \
  --ref_feature_pred ${Geno_1KG_dir}/Predicted_expression/FUSION/${weights}/1KGPhase3.w_hm3.FUSION.${weights}.predictions.gz \
  --output ${Geno_1KG_dir}/Score_files_for_functionally_informed_risk_scores/${gwas}/1KGPhase3.w_hm3.EUR.FUSION.${gwas}.${weights} \
  --ref_keep ${Geno_1KG_dir}/keep_files/EUR_samples.keep \
  --ref_scale ${Geno_1KG_dir}/Predicted_expression/FUSION/${weights}/1KGPhase3.w_hm3.FUSION.${weights}.EUR.scale \
  --panel ${weights}

sleep 1
done
</code></pre>
</details>
<p><br/></p>
<hr />
<p><br/></p>
<details>
<p><summary>Session info</summary></p>
<p>Date knitted: 27 July, 2019</p>
<pre><code>## R version 3.5.0 (2018-04-23)
## Platform: x86_64-pc-linux-gnu (64-bit)
## Running under: Scientific Linux release 6.6 (Carbon)
## 
## Matrix products: default
## BLAS: /opt/apps/general/R/3.5.0/lib64/R/lib/libRblas.so
## LAPACK: /opt/apps/general/R/3.5.0/lib64/R/lib/libRlapack.so
## 
## locale:
##  [1] LC_CTYPE=en_GB       LC_NUMERIC=C         LC_TIME=en_GB       
##  [4] LC_COLLATE=en_GB     LC_MONETARY=en_GB    LC_MESSAGES=en_GB   
##  [7] LC_PAPER=en_GB       LC_NAME=C            LC_ADDRESS=C        
## [10] LC_TELEPHONE=C       LC_MEASUREMENT=en_GB LC_IDENTIFICATION=C 
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] DT_0.7
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.1      later_0.7.2     digest_0.6.18   mime_0.5       
##  [5] R6_2.4.0        jsonlite_1.5    xtable_1.8-2    magrittr_1.5   
##  [9] evaluate_0.13   stringi_1.2.4   promises_1.0.1  rmarkdown_1.13 
## [13] tools_3.5.0     stringr_1.3.1   htmlwidgets_1.3 crosstalk_1.0.0
## [17] shiny_1.0.5     httpuv_1.4.3    xfun_0.6.1      yaml_2.1.19    
## [21] compiler_3.5.0  htmltools_0.3.6 knitr_1.22</code></pre>
</details>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
