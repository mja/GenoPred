<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Preparing reference files for genotype-based scoring</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">GenoPred</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="Pipeline_prep.html">Preparing reference files for genotype-based scoring</a>
</li>
<li>
  <a href="Determine_optimal_polygenic_scoring_approach.html">Determine optimal polygenic scoring approach</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/opain/GenoPred">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Preparing reference files for genotype-based scoring</h1>

</div>


<style>
p.caption {
  font-size: 1.5em;
}
</style>
<style type="text/css">
pre code, pre, code {
  white-space: pre !important;
  overflow-x: auto !important;
  word-break: keep-all !important;
  word-wrap: initial !important;
}
</style>
<hr />
<p>Genotype-based scores are typically based on several target sample specific features of the data including:</p>
<ul>
<li><p>Linkage disequilibrium (LD) structure</p></li>
<li><p>Available genetic variation</p></li>
<li><p>Minor allele frequecy (MAF)</p></li>
</ul>
<p>Basing these features on the target sample lead to differences in genotype-based scores across samples seperately processed, meaning they cannot be directly compared. This is not a limitation when performing inference within a single dataset, however in framework of prediction it is important that the predictors are derived in a way that can be replicated in any future dataset to optimise external validity of the prediction model.</p>
<p>To ensure consistency in genotye-based scoring we can base each of these features on a reference dataset, such as the 1000 Genomes reference, an approach herein refered to as ‘reference-standardised’. Another advantage of reference-standardised scoring is that a single sample can be realiably processed, enabling reliable prediction for n individual.</p>
<p>This page provides instructions for preparing the reference data required for reference-standardised genotype-based scoring. Here I provide code used when preparing on the KCL Rosalind cluster, with the intention of deriving scores in the UK Biobank sample and Twins Early Development Study (TEDS) sample.</p>
<div id="pre-requisites" class="section level1">
<h1><span class="header-section-number">1</span> Pre-requisites</h1>
<ul>
<li><p>PLINK v1.9 (<a href="https://www.cog-genomics.org/plink2/" class="uri">https://www.cog-genomics.org/plink2/</a>)</p></li>
<li><p>SHAPEIT (<a href="https://mathgen.stats.ox.ac.uk/genetics_softwae*hapeit/shapeit.html#download" class="uri">https://mathgen.stats.ox.ac.uk/genetics_softwae*hapeit/shapeit.html#download</a>)</p></li>
<li><p>IMPUTE2 (<a href="https://mathgen.stats.ox.ac.uk/impute/impute_v" class="uri">https://mathgen.stats.ox.ac.uk/impute/impute_v</a>.*ml#download)</p></li>
<li><p>QCTOOL v2 (<a href="https://www.well.ox.ac.uk/~gav/qctool/documet*ion/download.html" class="uri">https://www.well.ox.ac.uk/~gav/qctool/documet*ion/download.html</a>)</p></li>
<li><p>R (<a href="https://www.r-project.org/" class="uri">https://www.r-project.org/</a>)</p></li>
<li><p>R packages:</p></li>
</ul>
<pre class="r"><code>install.packages(c(&#39;data.table&#39;,&#39;doMC&#39;,&#39;optparse&#39;,&#39;foreach&#39;,&#39;caret&#39;,&#39;ggplot2&#39;,&#39;cowplot&#39;))</code></pre>
<hr />
</div>
<div id="download-and-preprare-required-reference-genetic-data" class="section level1">
<h1><span class="header-section-number">2</span> Download and preprare required reference genetic data</h1>
<div id="download-the-impute2-1000-genomes-phase-3-data" class="section level2">
<h2><span class="header-section-number">2.1</span> Download the IMPUTE2 1000 Genomes Phase 3 data</h2>
<p>Download available <a href="https://mathgen.stats.ox.ac.uk/impute/1000GP_Phase3.html">here</a></p>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code># Create directory for the data
mkdir -p /mnt/lustre/users/k1806347/Data/1KG/Impute2/1000GP_Phase3

# Download data using wget
cd /mnt/lustre/users/k1806347/Data/1KG/Impute2/1000GP_Phase3
wget https://mathgen.stats.ox.ac.uk/impute/1000GP_Phase3.tgz
wget https://mathgen.stats.ox.ac.uk/impute/1000GP_Phase3_chrX.tgz

# Decompress data
tar -zxvf 1000GP_Phase3.tgz
tar -zxvf 1000GP_Phase3_chrX.tgz</code></pre>
</details>
</div>
<div id="download-the-ld-score-regression-list-of-hapmap3-snps" class="section level2">
<h2><span class="header-section-number">2.2</span> Download the LD-score regression list of HapMap3 SNPs</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code># Dowload snplist using wget and decompress
cd /users/k1806347/brc_scratch/Data/ldsc
wget https://data.broadinstitute.org/alkesgroup/LDSCORE/w_hm3.snplist.bz2
bunzip2 w_hm3.snplist.bz2</code></pre>
</details>
</div>
<div id="create-a-keep-file-listing-each-population-in-the-reference-and-file-listing-unique-populations" class="section level2">
<h2><span class="header-section-number">2.3</span> Create a keep file listing each population in the reference and file listing unique populations</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code># Download the populations file
cd /users/k1806347/brc_scratch/Data/1KG/Phase3
wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/integrated_call_samples_v3.20130502.ALL.panel

# Create a version of population file that only contains sample ID, pop and super_pop
cut -f 1-3 /users/k1806347/brc_scratch/Data/1KG/Phase3/integrated_call_samples_v3.20130502.ALL.panel &gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/integrated_call_samples_v3.20130502.ALL.panel_small

# Create a keep file listing each population super population from the reference.
mkdir -p /users/k1806347/brc_scratch/Data/1KG/Phase3/keep_files

module add general/R/3.5.0
R
pop_data&lt;-read.table(&#39;/users/k1806347/brc_scratch/Data/1KG/Phase3/integrated_call_samples_v3.20130502.ALL.panel&#39;, header=T, stringsAsFactors=F)

for(i in unique(pop_data$pop)){
  write.table(cbind(pop_data$sample[pop_data$pop == i],pop_data$sample[pop_data$pop == i]), paste0(&#39;/users/k1806347/brc_scratch/Data/1KG/Phase3/keep_files/&#39;,i,&#39;_samples.keep&#39;), col.names=F, row.names=F, quote=F)
}

for(i in unique(pop_data$super_pop)){
  write.table(cbind(pop_data$sample[pop_data$super_pop == i],pop_data$sample[pop_data$super_pop == i]), paste0(&#39;/users/k1806347/brc_scratch/Data/1KG/Phase3/keep_files/&#39;,i,&#39;_samples.keep&#39;), col.names=F, row.names=F, quote=F)
}

# Create a file listing all ancestry groups
write.table(unique(pop_data$super_pop), &#39;/users/k1806347/brc_scratch/Data/1KG/Phase3/super_pop.list&#39;, col.names=F, row.names=F, quote=F)
write.table(unique(pop_data$pop), &#39;/users/k1806347/brc_scratch/Data/1KG/Phase3/pop.list&#39;, col.names=F, row.names=F, quote=F)

# Create a file listing the code of each population and the location of the keep file
pop_keep_loc&lt;-data.frame(pop=unique(pop_data$pop))
pop_keep_loc$keep&lt;-paste0(&#39;/users/k1806347/brc_scratch/Data/1KG/Phase3/keep_files/&#39;,pop_keep_loc$pop,&#39;_samples.keep&#39;)

super_pop_keep_loc&lt;-data.frame(pop=unique(pop_data$super_pop))
super_pop_keep_loc$keep&lt;-paste0(&#39;/users/k1806347/brc_scratch/Data/1KG/Phase3/keep_files/&#39;,super_pop_keep_loc$pop,&#39;_samples.keep&#39;)

write.table(super_pop_keep_loc, &#39;/users/k1806347/brc_scratch/Data/1KG/Phase3/super_pop_keep.list&#39;, col.names=F, row.names=F, quote=F)
write.table(pop_keep_loc, &#39;/users/k1806347/brc_scratch/Data/1KG/Phase3/pop_keep.list&#39;, col.names=F, row.names=F, quote=F)
write.table(rbind(super_pop_keep_loc,pop_keep_loc), &#39;/users/k1806347/brc_scratch/Data/1KG/Phase3/super_pop_and_pop_keep.list&#39;, col.names=F, row.names=F, quote=F)
q()
n</code></pre>
</details>
</div>
<div id="prepare-1000-genomes-plink-files" class="section level2">
<h2><span class="header-section-number">2.4</span> Prepare 1000 Genomes PLINK files</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>cd /users/k1806347/brc_scratch/Data/1KG/Phase3

# Download the vcf files, convert to plink, extract hapmap3 snps, and delete vcfs
for chr in $(seq 1 22); do
wget http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr${chr}.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz
done

for chr in $(seq 1 22); do
qsub /users/k1806347/brc_scratch/Software/plink1.9.sh \
  --vcf /users/k1806347/brc_scratch/Data/1KG/Phase3/ALL.chr${chr}.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz \
  --make-bed \
  --out /users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.chr${chr}
done  

rm /users/k1806347/brc_scratch/Data/1KG/Phase3/ALL.chr*.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz

# Use R to identify a list of SNPs that matches with the hapmap3 snplist
qrsh
module add general/R/3.5.0
R
library(data.table)
hapmap3_snps&lt;-fread(&#39;/users/k1806347/brc_scratch/Data/ldsc/w_hm3.snplist&#39;)

# Generate IUPAC codes
hapmap3_snps$IUPAC[hapmap3_snps$A1 == &#39;A&#39; &amp; hapmap3_snps$A2 ==&#39;T&#39; | hapmap3_snps$A1 == &#39;T&#39; &amp; hapmap3_snps$A2 ==&#39;A&#39;]&lt;-&#39;W&#39;
hapmap3_snps$IUPAC[hapmap3_snps$A1 == &#39;C&#39; &amp; hapmap3_snps$A2 ==&#39;G&#39; | hapmap3_snps$A1 == &#39;G&#39; &amp; hapmap3_snps$A2 ==&#39;C&#39;]&lt;-&#39;S&#39;
hapmap3_snps$IUPAC[hapmap3_snps$A1 == &#39;A&#39; &amp; hapmap3_snps$A2 ==&#39;G&#39; | hapmap3_snps$A1 == &#39;G&#39; &amp; hapmap3_snps$A2 ==&#39;A&#39;]&lt;-&#39;R&#39;
hapmap3_snps$IUPAC[hapmap3_snps$A1 == &#39;C&#39; &amp; hapmap3_snps$A2 ==&#39;T&#39; | hapmap3_snps$A1 == &#39;T&#39; &amp; hapmap3_snps$A2 ==&#39;C&#39;]&lt;-&#39;Y&#39;
hapmap3_snps$IUPAC[hapmap3_snps$A1 == &#39;G&#39; &amp; hapmap3_snps$A2 ==&#39;T&#39; | hapmap3_snps$A1 == &#39;T&#39; &amp; hapmap3_snps$A2 ==&#39;G&#39;]&lt;-&#39;K&#39;
hapmap3_snps$IUPAC[hapmap3_snps$A1 == &#39;A&#39; &amp; hapmap3_snps$A2 ==&#39;C&#39; | hapmap3_snps$A1 == &#39;C&#39; &amp; hapmap3_snps$A2 ==&#39;A&#39;]&lt;-&#39;M&#39;

hapmap3_snps$SNP_IUPAC&lt;-paste(hapmap3_snps$SNP,hapmap3_snps$IUPAC,sep=&#39;:&#39;)

# For each chr
for(chr in 1:22){
    bim&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.chr&#39;,chr,&#39;.bim&#39;))

    bim$IUPAC[bim$V5 == &#39;A&#39; &amp; bim$V6 ==&#39;T&#39; | bim$V5 == &#39;T&#39; &amp; bim$V6 ==&#39;A&#39;]&lt;-&#39;W&#39;
    bim$IUPAC[bim$V5 == &#39;C&#39; &amp; bim$V6 ==&#39;G&#39; | bim$V5 == &#39;G&#39; &amp; bim$V6 ==&#39;C&#39;]&lt;-&#39;S&#39;
    bim$IUPAC[bim$V5 == &#39;A&#39; &amp; bim$V6 ==&#39;G&#39; | bim$V5 == &#39;G&#39; &amp; bim$V6 ==&#39;A&#39;]&lt;-&#39;R&#39;
    bim$IUPAC[bim$V5 == &#39;C&#39; &amp; bim$V6 ==&#39;T&#39; | bim$V5 == &#39;T&#39; &amp; bim$V6 ==&#39;C&#39;]&lt;-&#39;Y&#39;
    bim$IUPAC[bim$V5 == &#39;G&#39; &amp; bim$V6 ==&#39;T&#39; | bim$V5 == &#39;T&#39; &amp; bim$V6 ==&#39;G&#39;]&lt;-&#39;K&#39;
    bim$IUPAC[bim$V5 == &#39;A&#39; &amp; bim$V6 ==&#39;C&#39; | bim$V5 == &#39;C&#39; &amp; bim$V6 ==&#39;A&#39;]&lt;-&#39;M&#39;

    bim$SNP_IUPAC&lt;-paste(bim$V2,bim$IUPAC,sep=&#39;:&#39;)
    
    bim_hapmap3_snps&lt;-merge(hapmap3_snps,bim,by=&#39;SNP_IUPAC&#39;)
    sum(duplicated(bim_hapmap3_snps$V2))
    
    bim$V2[!(bim$SNP_IUPAC %in% bim_hapmap3_snps$SNP_IUPAC)] &lt;- paste0(bim$V2[!(bim$SNP_IUPAC %in% bim_hapmap3_snps$SNP_IUPAC)],&#39;_excl&#39;)
    bim[!(bim$SNP_IUPAC %in% bim_hapmap3_snps$SNP_IUPAC),]
    
    fwrite(bim[,1:6], paste0(&#39;/users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.chr&#39;,chr,&#39;.bim&#39;), sep=&#39;\t&#39;, col.names=F)
    fwrite(as.list(bim_hapmap3_snps$V2), paste0(&#39;/users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.chr&#39;,chr,&#39;.extract&#39;), sep=&#39;\n&#39;, col.names=F) 
}

q()
n

for chr in $(seq 1 22); do
qsub /users/k1806347/brc_scratch/Software/plink1.9.sh \
  --bfile /users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.chr${chr} \
  --make-bed \
  --extract /users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.chr$chr.extract \
  --out /users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.w_hm3.chr${chr}
done

rm /users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.chr*

# Create version that is all chromosomes merged
ls /users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.w_hm3.chr*.bed | sed -e &#39;s/\.bed//g&#39; &gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/merge_list.txt

/users/k1806347/brc_scratch/Software/plink1.9.sh \
  --merge-list /users/k1806347/brc_scratch/Data/1KG/Phase3/merge_list.txt \
  --make-bed \
  --out /users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.w_hm3.GW</code></pre>
</details>
</div>
<div id="calculate-allele-frequency-files-for-each-population-in-the-reference-and-across-individuals" class="section level2">
<h2><span class="header-section-number">2.5</span> Calculate allele frequency files for each population in the reference and across individuals</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code># The following script uses .sumstats.gz files produced by the LDSC munge_sumstats.py
for pop in $(cat /users/k1806347/brc_scratch/Data/1KG/Phase3/super_pop.list); do
mkdir -p /users/k1806347/brc_scratch/Data/1KG/Phase3/freq_files/${pop}
for chr in $(seq 1 22); do
qsub /users/k1806347/brc_scratch/Software/plink1.9.sh \
    --bfile /users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.w_hm3.chr${chr} \
    --freq \
    --keep /users/k1806347/brc_scratch/Data/1KG/Phase3/keep_files/${pop}_samples.keep \
    --out /users/k1806347/brc_scratch/Data/1KG/Phase3/freq_files/${pop}/1KGPhase3.w_hm3.${pop}.chr${chr}
done
done

for pop in $(cat /users/k1806347/brc_scratch/Data/1KG/Phase3/pop.list); do
mkdir -p /users/k1806347/brc_scratch/Data/1KG/Phase3/freq_files/${pop}
for chr in $(seq 1 22); do
qsub /users/k1806347/brc_scratch/Software/plink1.9.sh \
    --bfile /users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.w_hm3.chr${chr} \
    --freq \
    --keep /users/k1806347/brc_scratch/Data/1KG/Phase3/keep_files/${pop}_samples.keep \
    --out /users/k1806347/brc_scratch/Data/1KG/Phase3/freq_files/${pop}/1KGPhase3.w_hm3.${pop}.chr${chr}
done
done

# Calculate MAF across all populations
mkdir /users/k1806347/brc_scratch/Data/1KG/Phase3/freq_files/AllAncestry
for chr in $(seq 1 22); do
qsub /users/k1806347/brc_scratch/Software/plink1.9.sh \
    --bfile /users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.w_hm3.chr${chr} \
    --freq \
    --out /users/k1806347/brc_scratch/Data/1KG/Phase3/freq_files/AllAncestry/1KGPhase3.w_hm3.AllAncestry.chr${chr}
done

# Delete the log and nosex files
rm /users/k1806347/brc_scratch/Data/1KG/Phase3/freq_files/*/1KGPhase3.w_hm3.*.chr*.log
rm /users/k1806347/brc_scratch/Data/1KG/Phase3/freq_files/*/1KGPhase3.w_hm3.*.chr*.nosex</code></pre>
</details>
<hr />
</div>
</div>
<div id="prepare-reference-files-for-ancestry-scoring" class="section level1">
<h1><span class="header-section-number">3</span> Prepare reference files for ancestry scoring</h1>
<div id="prepare-score-files-and-scaling-files-for-genome-wide-principal-components" class="section level2">
<h2><span class="header-section-number">3.1</span> Prepare score files and scaling files for genome-wide principal components</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code># Create score files for European specific PCs, and scaling files for Europeans
qsub /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/ancestry_score_file_creator.R \
    --ref_plink_chr /users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.w_hm3.chr \
    --ref_keep /users/k1806347/brc_scratch/Data/1KG/Phase3/keep_files/EUR_samples.keep \
    --plink /users/k1806347/brc_scratch/Software/plink1.9.sh \
    --plink2 /users/k1806347/brc_scratch/Software/plink2 \
    --n_pcs 100 \
    --output /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_ancestry/EUR/1KGPhase3.w_hm3.EUR

# Create score files for all ancestry PCs, and scaling files for each super population
qsub /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/ancestry_score_file_creator.R \
    --ref_plink_chr /users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.w_hm3.chr \
    --plink /users/k1806347/brc_scratch/Software/plink1.9.sh \
    --plink2 /users/k1806347/brc_scratch/Software/plink2 \
    --n_pcs 100 \
    --ref_pop_scale /users/k1806347/brc_scratch/Data/1KG/Phase3/super_pop_keep.list \
    --output /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_ancestry/AllAncestry/1KGPhase3.w_hm3.AllAncestry</code></pre>
</details>
<hr />
</div>
</div>
<div id="prepare-reference-files-for-polygenic-scoring" class="section level1">
<h1><span class="header-section-number">4</span> Prepare reference files for polygenic scoring</h1>
<div id="create-repository-of-ldsc-format-gwas-summary-statistics" class="section level2">
<h2><span class="header-section-number">4.1</span> Create repository of LDSC format GWAS summary statistics</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code># This has already been prepared by Helena Gaspar
###
# Select which GWAS we want to include which don&#39;t include UKBB
###
module add general/R/3.5.0
R
pheno&lt;-read.csv(&#39;/users/k1806347/brc_scratch/Data/GWAS_sumstats/QC_sumstats_list_031218.csv&#39;, stringsAsFactors=F)
pheno_brief&lt;-pheno[c(&#39;Code&#39;,&#39;phenotype_category&#39;,&#39;trait&#39;,&#39;sample_size_discovery&#39;,&#39;Ncases&#39;,&#39;Ncontrols&#39;,&#39;sex&#39;,&#39;consortium&#39;,&#39;year&#39;,&#39;UK.Biobank&#39;,&#39;h2.observed&#39;,&#39;ancestry&#39;,&#39;PRS.created&#39;)]

pheno_brief$sample_size_discovery&lt;-gsub(&#39;,&#39;,&#39;&#39;,pheno_brief$sample_size_discovery)

# Extract those that have LDSC sumstats (this removes those where sumstats are unavailable)
pheno_brief$sample_size_discovery&lt;-as.numeric(pheno_brief$sample_size_discovery)

# Exclude GWAS containing UKBB as this is our target sample
pheno_brief&lt;-pheno_brief[which(pheno_brief$UK.Biobank == &#39;no&#39;),]
pheno_brief&lt;-pheno_brief[!is.na(as.numeric(pheno_brief$h2.observed)),]

# BLOO GWAS are mislabelled as not containing UKBB. Remove them.
pheno_brief&lt;-pheno_brief[!(grepl(&#39;BLOO&#39;,pheno_brief$Code)),]

# INTE02, INTE03, all EDUC, GWAS are mislabelled as not containing UKBB. Remove them.
pheno_brief&lt;-pheno_brief[!(grepl(&#39;BLOO|INTE02|INTE03|EDUC&#39;,pheno_brief$Code)),]

# Extract the largest GWAS for each phenotype
pheno_brief_bigest&lt;-NULL
for(i in unique(pheno_brief$trait)){
  tmp&lt;-pheno_brief[pheno_brief$trait == i,]
  tmp&lt;-tmp[rev(order(tmp$sample_size_discovery)),]
  pheno_brief_bigest&lt;-rbind(pheno_brief_bigest,tmp[1,])
}

# Extract those with sample size &gt;15000
pheno_brief_bigest_big&lt;-pheno_brief_bigest[pheno_brief_bigest$sample_size_discovery &gt; 15000,]

# Remove GWAS from MAGNETIC as we are not looking at cardiometabolic traits and is excessive.
pheno_brief_bigest_big_nomag&lt;-pheno_brief_bigest_big[pheno_brief_bigest_big$consortium !=&#39;MAGNETIC&#39;,]

pheno_brief_bigest_big_nomag$gwas_list&lt;-paste0(&#39;/mnt/lustre/groups/ukbiobank/sumstats/munged/&#39;,pheno_brief_bigest_big_nomag$Code,&#39;.sumstats.gz&#39;)

write.table(pheno_brief_bigest_big_nomag[c(&#39;Code&#39;,&#39;gwas_list&#39;)], &#39;~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt&#39;, col.names=F, row.names=F, quote=F)

q()
n

# NOTE. The overlapping with UKBB variable is unreliable and should be checked using the LDSC covariance intercept with outcome variables.

###
# Select which GWAS we want to include which don&#39;t include TEDS
###
module add general/R/3.5.0
R
pheno&lt;-read.csv(&#39;/users/k1806347/brc_scratch/Data/GWAS_sumstats/QC_sumstats_list_031218.csv&#39;, stringsAsFactors=F)
pheno_brief&lt;-pheno[c(&#39;Code&#39;,&#39;phenotype_category&#39;,&#39;trait&#39;,&#39;sample_size_discovery&#39;,&#39;Ncases&#39;,&#39;Ncontrols&#39;,&#39;sex&#39;,&#39;consortium&#39;,&#39;year&#39;,&#39;UK.Biobank&#39;,&#39;h2.observed&#39;,&#39;ancestry&#39;,&#39;PRS.created&#39;)]

pheno_brief$sample_size_discovery&lt;-gsub(&#39;,&#39;,&#39;&#39;,pheno_brief$sample_size_discovery)

# Extract those that have LDSC sumstats (this removes those where sumstats are unavailable)
pheno_brief$sample_size_discovery&lt;-as.numeric(pheno_brief$sample_size_discovery)

# Remove GWAS containing TEDS individuals
pheno_brief&lt;-pheno_brief[!grepl(&#39;EDUC04|EDUC03&#39;, pheno_brief$Code),]

# Remove BLOO GWASs as there are lot of them and unnecessary for our purposes.
pheno_brief&lt;-pheno_brief[!grepl(&#39;BLOO&#39;, pheno_brief$Code),]

# Remove BLOP, CROH03 and DIAB01 GWASs
pheno_brief&lt;-pheno_brief[!grepl(&#39;BLOP|CROH03|DIAB01&#39;, pheno_brief$Code),]
 
# Remove entries with missing sample size information
pheno_brief&lt;-pheno_brief[!is.na(pheno_brief$sample_size_discovery),]

# Extract the most recent and largest GWAS for each phenotype
pheno_brief_bigest&lt;-NULL
for(i in unique(pheno_brief$trait)){
  tmp&lt;-pheno_brief[pheno_brief$trait == i,]
  tmp&lt;-tmp[rev(order(tmp$sample_size_discovery)),]
  pheno_brief_bigest&lt;-rbind(pheno_brief_bigest,tmp[1,])
}

# Extract those with sample size &gt;15000
pheno_brief_bigest_big&lt;-pheno_brief_bigest[pheno_brief_bigest$sample_size_discovery &gt; 15000,]

# Remove GWAS from MAGNETIC as we are not looking at cardiometabolic traits and is excessive.
pheno_brief_bigest_big_nomag&lt;-pheno_brief_bigest_big[pheno_brief_bigest_big$consortium !=&#39;MAGNETIC&#39;,]

pheno_brief_bigest_big_nomag$gwas_list&lt;-paste0(&#39;/mnt/lustre/groups/ukbiobank/sumstats/munged/&#39;,pheno_brief_bigest_big_nomag$Code,&#39;.sumstats.gz&#39;)

write.table(pheno_brief_bigest_big_nomag[c(&#39;Code&#39;,&#39;gwas_list&#39;)], &#39;~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutTEDS.txt&#39;, col.names=F, row.names=F, quote=F)

q()
n</code></pre>
</details>
</div>
<div id="prepare-score-files-and-scaling-files-for-polygenic-scoring" class="section level2">
<h2><span class="header-section-number">4.2</span> Prepare score files and scaling files for polygenic scoring</h2>
<p>The score files should be based on the LD structure of the ancestry matching the GWAS (typically European). The following script uses .sumstats.gz files produced by the LDSC munge_sumstats.py.</p>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>###
# Run for all in ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt
###
# Create file listing GWAS that haven&#39;t been processed.
&gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic/todo.txt
for gwas in $(cut -f 1 -d &#39; &#39; ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt);do
if [ ! -f /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic/${gwas}/1KGPhase3.w_hm3.${gwas}.EUR.scale ]; then
echo $gwas &gt;&gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic/todo.txt
fi
done

n=0
for gwas in $(cat /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic/todo.txt);do
qsub -N $(echo job$(($n+20))) -hold_jid $(echo job$(($n+0))) -l h_vmem=6G /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/polygenic_score_file_creator.R \
--ref_plink_chr /users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.w_hm3.chr \
--ref_keep /users/k1806347/brc_scratch/Data/1KG/Phase3/keep_files/EUR_samples.keep \
--sumstats /mnt/lustre/groups/ukbiobank/sumstats/munged/${gwas}.sumstats.gz \
--plink /users/k1806347/brc_scratch/Software/plink1.9.sh \
--memory 3000 \
--output /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic/${gwas}/1KGPhase3.w_hm3.${gwas} \
--ref_pop_scale /users/k1806347/brc_scratch/Data/1KG/Phase3/super_pop_keep.list
n=$(($n+1))
done

###
# Run for all in ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutTEDS.txt
###
&gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic/todo.txt
for gwas in $(cut -f 1 -d &#39; &#39; ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutTEDS.txt);do
if [ ! -f /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic/${gwas}/1KGPhase3.w_hm3.${gwas}.EUR.scale ]; then
echo $gwas &gt;&gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic/todo.txt
fi
done

n=0
for gwas in $(cat /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic/todo.txt);do
qsub -N $(echo job$(($n+5))) -hold_jid $(echo job$(($n+0))) -l h_vmem=6G /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/polygenic_score_file_creator.R \
    --ref_plink_chr /users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.w_hm3.chr \
    --ref_keep /users/k1806347/brc_scratch/Data/1KG/Phase3/keep_files/EUR_samples.keep \
    --sumstats /mnt/lustre/groups/ukbiobank/sumstats/munged/${gwas}.sumstats.gz \
    --plink /users/k1806347/brc_scratch/Software/plink1.9.sh \
  --memory 3000 \
    --output /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic/${gwas}/1KGPhase3.w_hm3.${gwas} \
    --ref_pop_scale /users/k1806347/brc_scratch/Data/1KG/Phase3/super_pop_keep.list
n=$(($n+1))
done</code></pre>
</details>
</div>
<div id="prepare-score-files-and-scaling-files-for-polygenic-scoring-using-lassosum" class="section level2">
<h2><span class="header-section-number">4.3</span> Prepare score files and scaling files for polygenic scoring using lassosum</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>###
# Run for all in ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt
###
mkdir /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic_lassosum
&gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic_lassosum/todo.txt
# for gwas in $(cut -f 1 -d &#39; &#39; ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt);do
for gwas in $(echo DEPR06 COLL01 HEIG03 BODY03);do
if [ ! -f /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic_lassosum/${gwas}/1KGPhase3.w_hm3.${gwas}.EUR.scale ]; then
echo $gwas &gt;&gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic_lassosum/todo.txt
fi
done

n=0
for gwas in $(cat /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic_lassosum/todo.txt);do
qsub -N $(echo job$(($n+5))) -hold_jid $(echo job$(($n+0))) -l h_vmem=10G /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/polygenic_score_file_creator_lassosum.R \
    --ref_plink_gw /users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.w_hm3.GW \
    --ref_keep /users/k1806347/brc_scratch/Data/1KG/Phase3/keep_files/EUR_samples.keep \
    --sumstats /mnt/lustre/groups/ukbiobank/sumstats/munged/${gwas}.sumstats.gz \
    --output /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic_lassosum/${gwas}/1KGPhase3.w_hm3.${gwas} \
    --ref_pop_scale /users/k1806347/brc_scratch/Data/1KG/Phase3/super_pop_keep.list
n=$(($n+1))
done

# Lassosum pseudovalidation does not seem to perform well.</code></pre>
</details>
</div>
<div id="prepare-score-and-scale-files-for-polygenic-scoring-using-prscs" class="section level2">
<h2><span class="header-section-number">4.4</span> Prepare score and scale files for polygenic scoring using PRScs</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>cd /users/k1806347/brc_scratch/Software
# Download software
git clone ssh://git@github.com/getian107/PRScs.git
# Download required reference data
wget https://www.dropbox.com/s/p9aqanhxvxaqv8k/ldblk_1kg_eur.tar.gz?dl=0
tar xvzf ldblk_1kg_eur.tar.gz?dl=0

mkdir /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic_PRScs

&gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic_PRScs/todo.txt
#for gwas in $(cut -f 1 -d &#39; &#39; ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt);do
for gwas in $(echo DEPR06 COLL01 HEIG03 BODY03);do
if [ ! -f /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic_PRScs/${gwas}/1KGPhase3.w_hm3.${gwas}.EUR.scale ]; then
echo $gwas &gt;&gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic_PRScs/todo.txt
fi
done

n=0
for gwas in $(cat /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic_PRScs/todo.txt);do
qsub -N $(echo job$(($n+15))) -hold_jid $(echo job$(($n+0))) -pe smp 6 -l h_vmem=6G /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/polygenic_score_file_creator_PRScs.R \
--ref_plink_chr /users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.w_hm3.chr \
--ref_keep /users/k1806347/brc_scratch/Data/1KG/Phase3/keep_files/EUR_samples.keep \
--sumstats /mnt/lustre/groups/ukbiobank/sumstats/munged/${gwas}.sumstats.gz \
--plink /users/k1806347/brc_scratch/Software/plink1.9.sh \
--memory 5000 \
--output /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_poylygenic_PRScs/${gwas}/1KGPhase3.w_hm3.${gwas} \
--ref_pop_scale /users/k1806347/brc_scratch/Data/1KG/Phase3/super_pop_keep.list \
--PRScs_path /users/k1806347/brc_scratch/Software/PRScs/PRScs.py \
--PRScs_ref_path /users/k1806347/brc_scratch/Software/PRScs/ldblk_1kg_eur \
--n_cores 6 \
--phi_param 1e-6,1e-4,1e-2,1,auto
n=$(($n+1))
done</code></pre>
</details>
<hr />
</div>
</div>
<div id="prepare-files-for-functionally-informed-polygenic-scoring" class="section level1">
<h1><span class="header-section-number">5</span> Prepare files for functionally informed polygenic scoring</h1>
<div id="perform-twas-using-all-tissue-data-and-gwas" class="section level2">
<h2><span class="header-section-number">5.1</span> Perform TWAS using all tissue data and GWAS</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>mkdir -p ~/brc_scratch/Data/TWAS_sumstats/FUSION

module add general/R/3.5.0
R

library(data.table)

# Read in full list of SNP-weights
weights&lt;-list.files(path=&#39;/mnt/lustre/groups/biomarkers-brc-mh/TWAS_resource/FUSION/SNP-weights/.&#39;, recursive=F)

# Write a file listing all SNP-weight sets.
write.table(weights, &#39;~/brc_scratch/Data/TWAS_sumstats/FUSION/snp_weight_list.txt&#39;, col.names=F, row.names=F, quote=F)

# Create a .pos file containing SNP-weights for all tissues.
pos&lt;-NULL
for(i in weights){
  pos_tmp&lt;-data.frame(fread(paste0(&#39;/mnt/lustre/groups/biomarkers-brc-mh/TWAS_resource/FUSION/SNP-weights/&#39;,i,&#39;/&#39;,i,&#39;.pos&#39;)))
  pos_tmp$PANEL&lt;-i
  pos_tmp$WGT&lt;-paste0(i,&#39;/&#39;,pos_tmp$WGT)
  pos&lt;-rbind(pos,pos_tmp[c(&#39;PANEL&#39;,&#39;WGT&#39;,&#39;ID&#39;,&#39;CHR&#39;,&#39;P0&#39;,&#39;P1&#39;)])
}

write.table(pos, &#39;~/brc_scratch/Data/TWAS_sumstats/FUSION/All_tissues.pos&#39;, col.names=T, row.names=F, quote=F)

q()
n

# Perform TWAS for all selected GWAS and all tissues
# Create file listing GWAS that haven&#39;t been converted to TWAS
###
# Run for all in ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt
###
&gt; ~/brc_scratch/Data/TWAS_sumstats/FUSION/todo.txt
for gwas in $(cut -f 1 -d &#39; &#39; ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt);do
if [ ! -f ~/brc_scratch/Data/TWAS_sumstats/FUSION/${gwas}/${gwas}_res_GW.txt ]; then
grep $gwas ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt &gt;&gt; ~/brc_scratch/Data/TWAS_sumstats/FUSION/todo.txt
fi
done

qsub -l h_vmem=6G -pe smp 8 -tc 3 -t 1-$(wc -l ~/brc_scratch/Data/TWAS_sumstats/FUSION/todo.txt | cut -d&#39; &#39; -f1) /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/Run_TWAS_new.sh \
  --gwas_list ~/brc_scratch/Data/TWAS_sumstats/FUSION/todo.txt \
  --pos ~/brc_scratch/Data/TWAS_sumstats/FUSION/All_tissues.pos \
  --outdir ~/brc_scratch/Data/TWAS_sumstats/FUSION \
  --ncores 8
  
# Create a list of TWAS that have less than 25% missing TWAS.Z
module add general/R/3.5.0
R
library(data.table)
gwas&lt;-fread(&#39;~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutUKBB.txt&#39;, header=F)$V1
twas_comp&lt;-NULL
twas_incomp&lt;-NULL
for(gwas_name in gwas){
    twas&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/&#39;,gwas_name,&#39;/&#39;,gwas_name,&#39;_res_GW.txt&#39;))
    if((sum(is.na(twas$TWAS.Z)) / dim(twas)[1]) &lt; 0.25){
        twas_comp&lt;-c(twas_comp,gwas_name)
    } else {
        twas_incomp&lt;-c(twas_incomp,gwas_name)
    }
}

write.table(twas_comp, &#39;/users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/Largest_TWAS_over15K_withoutUKBB_75comp.txt&#39;, col.names=F, row.names=F, quote=F)
q()
n

###
# Run for all in ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutTEDS.txt
###
&gt; ~/brc_scratch/Data/TWAS_sumstats/FUSION/todo.txt
for gwas in $(cut -f 1 -d &#39; &#39; ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutTEDS.txt);do
if [ ! -f ~/brc_scratch/Data/TWAS_sumstats/FUSION/${gwas}/${gwas}_res_GW.txt ]; then
grep $gwas ~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutTEDS.txt &gt;&gt; ~/brc_scratch/Data/TWAS_sumstats/FUSION/todo.txt
fi
done

qsub -l h_vmem=6G -pe smp 8 -tc 3 -t 1-$(wc -l ~/brc_scratch/Data/TWAS_sumstats/FUSION/todo.txt | cut -d&#39; &#39; -f1) /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/Run_TWAS_new.sh \
  --gwas_list ~/brc_scratch/Data/TWAS_sumstats/FUSION/todo.txt \
  --pos ~/brc_scratch/Data/TWAS_sumstats/FUSION/All_tissues.pos \
  --outdir ~/brc_scratch/Data/TWAS_sumstats/FUSION \
  --ncores 8
  
# Create a list of TWAS that have less than 25% missing TWAS.Z
module add general/R/3.5.0
R
library(data.table)
gwas&lt;-fread(&#39;~/brc_scratch/Data/GWAS_sumstats/Largest_GWAS_over15K_withoutTEDS.txt&#39;, header=F)$V1
twas_comp&lt;-NULL
twas_incomp&lt;-NULL
for(gwas_name in gwas){
    twas&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/&#39;,gwas_name,&#39;/&#39;,gwas_name,&#39;_res_GW.txt&#39;))
    if((sum(is.na(twas$TWAS.Z)) / dim(twas)[1]) &lt; 0.25){
        twas_comp&lt;-c(twas_comp,gwas_name)
    } else {
        twas_incomp&lt;-c(twas_incomp,gwas_name)
    }
}

write.table(twas_comp, &#39;/users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/Largest_TWAS_over15K_withoutTEDS_75comp.txt&#39;, col.names=F, row.names=F, quote=F)
q()
n</code></pre>
</details>
</div>
<div id="prepare-score-files-and-scaling-files-for-predicting-gene-expression" class="section level2">
<h2><span class="header-section-number">5.2</span> Prepare score files and scaling files for predicting gene expression</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>mkdir -p ~/brc_scratch/Data/FUSION/SCORE_FILES

# Create SCORE files and expression reference.
qsub -pe smp 15 -l h_vmem=2G /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/FUSION_score_file_creator.R \
  --weights ~/brc_scratch/Data/TWAS_sumstats/FUSION/All_tissues.pos \
  --weights_dir /mnt/lustre/groups/biomarkers-brc-mh/TWAS_resource/FUSION/SNP-weights \
  --output ~/brc_scratch/Data/FUSION/SCORE_FILES \
  --n_cores 15</code></pre>
</details>
</div>
<div id="predict-functional-genomic-features-mainly-expression-in-the-reference" class="section level2">
<h2><span class="header-section-number">5.3</span> Predict functional genomic features (mainly expression) in the reference</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code># Calculate features based on each SNP-weight set. To not swamp the cluster, submit only three weights at a time.
# Create file listing weights that haven&#39;t been predicted in the reference.
&gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/Predicted_expression/FUSION/todo.txt
for weights in $(cat ~/brc_scratch/Data/TWAS_sumstats/FUSION/snp_weight_list.txt);do
if [ ! -f /users/k1806347/brc_scratch/Data/1KG/Phase3/Predicted_expression/FUSION/${weights}/1KGPhase3.w_hm3.FUSION.${weights}.predictions.gz ]; then
echo $weights &gt;&gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/Predicted_expression/FUSION/todo.txt
fi
done

n=0
for weights in $(cat /users/k1806347/brc_scratch/Data/1KG/Phase3/Predicted_expression/FUSION/todo.txt);do
qsub -N $(echo job$(($n+2))) -hold_jid $(echo job$(($n+0))) -pe smp 5 -l h_vmem=8G /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/FUSION_ref_scorer.R \
  --ref_plink_chr /users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.w_hm3.chr \
  --weights /mnt/lustre/groups/biomarkers-brc-mh/TWAS_resource/FUSION/SNP-weights/${weights}/${weights}.pos \
  --output /users/k1806347/brc_scratch/Data/1KG/Phase3/Predicted_expression/FUSION/${weights}/1KGPhase3.w_hm3.FUSION.${weights} \
  --plink ~/brc_scratch/Software/plink1.9.sh \
  --n_cores 5 \
  --pigz /users/k1806347/brc_scratch/Software/pigz.sh \
  --score_files ~/brc_scratch/Data/FUSION/SCORE_FILES \
  --ref_pop_scale /users/k1806347/brc_scratch/Data/1KG/Phase3/super_pop_keep.list
n=$(($n+1))
done</code></pre>
</details>
</div>
<div id="prepare-score-files-and-scaling-files-for-functionally-informed-polygenic-scores" class="section level2">
<h2><span class="header-section-number">5.4</span> Prepare score files and scaling files for functionally informed polygenic scores</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>######
# Calculate for /users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/Largest_TWAS_over15K_withoutUKBB_75comp.txt
######
&gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/todo.txt
for gwas in $(cat /users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/Largest_TWAS_over15K_withoutUKBB_75comp.txt);do
for weights in $(cat ~/brc_scratch/Data/TWAS_sumstats/FUSION/snp_weight_list.txt);do
if [ ! -f /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/${gwas}/1KGPhase3.w_hm3.EUR.FUSION.${gwas}.${weights}.scale ]; then
echo $gwas $weights &gt;&gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/todo.txt
fi
done
done

for i in $(seq 1 $(wc -l /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/todo.txt | cut -d &#39; &#39; -f 1));do
gwas=$(awk -v var=&quot;$i&quot; &#39;NR == var {print $1}&#39; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/todo.txt)
weights=$(awk -v var=&quot;$i&quot; &#39;NR == var {print $2}&#39; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/todo.txt)

qsub /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/ref_funtionally_informed_risk_scorer.R \
  --twas_results /users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/${gwas}/${gwas}_res_GW.txt \
  --ref_feature_pred /users/k1806347/brc_scratch/Data/1KG/Phase3/Predicted_expression/FUSION/${weights}/1KGPhase3.w_hm3.FUSION.${weights}.predictions.gz \
  --output /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/${gwas}/1KGPhase3.w_hm3.EUR.FUSION.${gwas}.${weights} \
  --ref_keep /users/k1806347/brc_scratch/Data/1KG/Phase3/keep_files/EUR_samples.keep \
  --ref_scale /users/k1806347/brc_scratch/Data/1KG/Phase3/Predicted_expression/FUSION/${weights}/1KGPhase3.w_hm3.FUSION.${weights}.EUR.scale \
  --panel ${weights}

sleep 1
done
</code></pre>
</details>
<hr />
</div>
</div>
<div id="redundant-code-for-research" class="section level1">
<h1><span class="header-section-number">6</span> Redundant code for research</h1>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>###
# Calculate GeRSs weighting genes by R2 and TWAS.Z
###
&gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/todo_R2weighted.txt
for gwas in $(cat /users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/Largest_TWAS_over15K_withoutUKBB_75comp.txt);do
for weights in $(cat ~/brc_scratch/Data/TWAS_sumstats/FUSION/snp_weight_list.txt);do
if [ ! -f /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/${gwas}/1KGPhase3.w_hm3.EUR.FUSION.${gwas}.${weights}.R2weighted.scale ]; then
echo $gwas $weights &gt;&gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/todo_R2weighted.txt
fi
done
done

for i in $(seq 1 $(wc -l /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/todo_R2weighted.txt | cut -d &#39; &#39; -f 1));do
gwas=$(awk -v var=&quot;$i&quot; &#39;NR == var {print $1}&#39; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/todo_R2weighted.txt)
weights=$(awk -v var=&quot;$i&quot; &#39;NR == var {print $2}&#39; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/todo_R2weighted.txt)

qsub /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/ref_funtionally_informed_risk_scorer.R \
  --twas_results /users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/${gwas}/${gwas}_res_GW.txt \
  --ref_feature_pred /users/k1806347/brc_scratch/Data/1KG/Phase3/Predicted_expression/FUSION/${weights}/1KGPhase3.w_hm3.FUSION.${weights}.predictions.gz \
  --output /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/${gwas}/1KGPhase3.w_hm3.EUR.FUSION.${gwas}.${weights}.R2weighted \
  --ref_keep /users/k1806347/brc_scratch/Data/1KG/Phase3/keep_files/EUR_samples.keep \
  --ref_scale /users/k1806347/brc_scratch/Data/1KG/Phase3/Predicted_expression/FUSION/${weights}/1KGPhase3.w_hm3.FUSION.${weights}.EUR.scale \
  --panel ${weights} \
  --r2_weighted T

sleep 5
done

# Experiment finished. Don&#39;t calculate R2 weighted GeRSs.
# Delete R2 weighted reference files

######
# Calculate all tissue GeRSs
######

# Create a file containing a list of gene expression files, and a list of scale files
ls /users/k1806347/brc_scratch/Data/1KG/Phase3/Predicted_expression/FUSION/*/1KGPhase3.w_hm3.FUSION.*.predictions.gz &gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/Predicted_expression/FUSION/1KGPhase3.w_hm3.FUSION.predictions_list
ls /users/k1806347/brc_scratch/Data/1KG/Phase3/Predicted_expression/FUSION/*/1KGPhase3.w_hm3.FUSION.*.EUR.scale &gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/Predicted_expression/FUSION/1KGPhase3.w_hm3.FUSION.EUR.scales_list

qrsh -l h_vmem=25G
module add general/R/3.5.0
module add compilers/gcc/8.1.0
module add general/python/2.7.10
R

qsub -l h_vmem=30G /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/ref_funtionally_informed_risk_scorer.R \
  --twas_results /users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/DEPR07/DEPR07_res_GW.txt \
  --ref_feature_pred /users/k1806347/brc_scratch/Data/1KG/Phase3/Predicted_expression/FUSION/1KGPhase3.w_hm3.FUSION.predictions_list \
  --output /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/DEPR07/1KGPhase3.w_hm3.EUR.FUSION.DEPR07.AllTissue \
  --ref_keep /users/k1806347/brc_scratch/Data/1KG/Phase3/keep_files/EUR_samples.keep \
  --ref_scale /users/k1806347/brc_scratch/Data/1KG/Phase3/Predicted_expression/FUSION/1KGPhase3.w_hm3.FUSION.EUR.scales_list

######
# Calculate for /users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/Largest_TWAS_over15K_withoutTEDS_75comp.txt
######

&gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/todo.txt
# for gwas in $(cat /users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/Largest_TWAS_over15K_withoutTEDS_75comp.txt);do
for gwas in $(echo ADHD02 BODY11 HEIG03 INTE03);do
for weights in $(cat ~/brc_scratch/Data/TWAS_sumstats/FUSION/snp_weight_list.txt);do
if [ ! -f /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/${gwas}/1KGPhase3.w_hm3.EUR.FUSION.${gwas}.${weights}.scale ]; then
echo $gwas $weights &gt;&gt; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/todo.txt
fi
done
done

for i in $(seq 1 $(wc -l /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/todo.txt | cut -d &#39; &#39; -f 1));do
gwas=$(awk -v var=&quot;$i&quot; &#39;NR == var {print $1}&#39; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/todo.txt)
weights=$(awk -v var=&quot;$i&quot; &#39;NR == var {print $2}&#39; /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/todo.txt)

qsub /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/Scripts/GenoPred_Pipeline/ref_funtionally_informed_risk_scorer.R \
  --twas_results /users/k1806347/brc_scratch/Data/TWAS_sumstats/FUSION/${gwas}/${gwas}_res_GW.txt \
  --ref_feature_pred /users/k1806347/brc_scratch/Data/1KG/Phase3/Predicted_expression/FUSION/${weights}/1KGPhase3.w_hm3.FUSION.${weights}.predictions.gz \
  --output /users/k1806347/brc_scratch/Data/1KG/Phase3/Score_files_for_functionally_informed_risk_scores/${gwas}/1KGPhase3.w_hm3.EUR.FUSION.${gwas}.${weights} \
  --ref_keep /users/k1806347/brc_scratch/Data/1KG/Phase3/keep_files/EUR_samples.keep \
  --ref_scale /users/k1806347/brc_scratch/Data/1KG/Phase3/Predicted_expression/FUSION/${weights}/1KGPhase3.w_hm3.FUSION.${weights}.EUR.scale \
  --panel ${weights}

sleep 1
done
</code></pre>
</details>
<hr />
<details>
<p><summary>Session info</summary></p>
<p>Date knitted: 26 July, 2019</p>
<pre><code>## R version 3.5.0 (2018-04-23)
## Platform: x86_64-pc-linux-gnu (64-bit)
## Running under: Scientific Linux release 6.6 (Carbon)
## 
## Matrix products: default
## BLAS: /opt/apps/general/R/3.5.0/lib64/R/lib/libRblas.so
## LAPACK: /opt/apps/general/R/3.5.0/lib64/R/lib/libRlapack.so
## 
## locale:
##  [1] LC_CTYPE=en_GB       LC_NUMERIC=C         LC_TIME=en_GB       
##  [4] LC_COLLATE=en_GB     LC_MONETARY=en_GB    LC_MESSAGES=en_GB   
##  [7] LC_PAPER=en_GB       LC_NAME=C            LC_ADDRESS=C        
## [10] LC_TELEPHONE=C       LC_MEASUREMENT=en_GB LC_IDENTIFICATION=C 
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] DT_0.7
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.1      later_0.7.2     digest_0.6.18   mime_0.5       
##  [5] R6_2.4.0        jsonlite_1.5    xtable_1.8-2    magrittr_1.5   
##  [9] evaluate_0.13   stringi_1.2.4   promises_1.0.1  rmarkdown_1.13 
## [13] tools_3.5.0     stringr_1.3.1   htmlwidgets_1.3 crosstalk_1.0.0
## [17] shiny_1.0.5     httpuv_1.4.3    xfun_0.6.1      yaml_2.1.19    
## [21] compiler_3.5.0  htmltools_0.3.6 knitr_1.22</code></pre>
</details>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
