<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Converting Polygenic Scores into Estimates of Absolute Risk</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#section-TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#section-TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="section-TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">GenoPred</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/opain/GenoPred">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="section-header">



<h1 class="title toc-ignore">Converting Polygenic Scores into Estimates of Absolute Risk</h1>

</div>


<style>
p.caption {
  font-size: 1.5em;
}
</style>
<style type="text/css">
pre code, pre, code {
  white-space: pre !important;
  overflow-x: scroll !important;
  word-break: keep-all !important;
  word-wrap: initial !important;
}
</style>
<p><br/></p>
<hr />
<p>This page is a sandbox for validating summary statistic based approaches for presenting polygenic scores results to the individual, as is done on the Impute.Me website. First, a polygenic scores for UK Biobank phenotypes are derived and evaluated, using a 10-fold cross validation procedure to avoid sample overlap. Then we experiment with methods for estimating the AUC or R2 of a polygenic score from summary statistics only. Then we compare predicted and observed estimates of absolute risk for binary outcomes and absolute quantitative trait prediction. If this, approach is deemed valid, it will provide a way of interpreting an individuals polygenic score, whilst considering the distribution of the outcome, and the predictive utility of the polygenic score. This will help to avoid misinterpretation of polygenic scores.</p>
<p>Thank you Alex Gillett for writing function for estimating proportion of cases within PRS quantiles.</p>
<hr />
<div id="section-create-training-and-test-sample-for-several-phenotypes-in-ukb" class="section level1">
<h1><span class="header-section-number">1</span> Create training and test sample for several phenotypes in UKB</h1>
<p>Use the same phenotypes as other GenoPred projects. To maximise power, lets use a 10-fold cross validation procedure, whereby we split the cases and controls for each outcome into 10 parts, then perform a GWAS within each fold. Then we create GWAS sumstats using 9 of 10 subsets, and calculate polygenic scores from the results for the remaining part of the sample. I have already written code for a similar process when playing with the BWAS project.</p>
<hr />
<div id="section-split-ukb-into-10-roughly-equal-parts" class="section level2">
<h2><span class="header-section-number">1.1</span> Split UKB into 10 roughly equal parts</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="r"><code>system(&#39;mkdir -p /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS&#39;)

# Create keep file for each fold
library(data.table)
QC&lt;-fread(&#39;/users/k1806347/brc_scratch/Analyses/PRS_comparison/UKBB_outcomes_for_prediction/ukb18177_glanville_post_qc_id_list.UpdateIDs.fam&#39;)
names(QC)&lt;-c(&#39;FID&#39;,&#39;IID&#39;)

pheno_all_2_QC&lt;-pheno_all_2[(pheno_all_2$IID %in% QC$V2),]

N &lt;- 10
set.seed(1)
subsets&lt;-split(QC, sample(1:N, nrow(QC), replace=T))

for(i in 1:length(subsets)){
  write.table(subsets[[i]], paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_&#39;,i,&#39;.keep&#39;), col.names=F, row.names=F, quote=F)
}</code></pre>
</details>
<hr />
</div>
<div id="section-prepare-covariates-file" class="section level2">
<h2><span class="header-section-number">1.2</span> Prepare covariates file</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>
library(data.table)

# Read in covariate data
geno_covar&lt;-fread(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/ukb18177_glanville_covariates.UpdateIDs.txt&#39;)
sex&lt;-fread(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/UKBB_Sex.pheno&#39;)
sex$Sex&lt;-sex$Sex+1

age&lt;-fread(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/UKBB_Age.pheno&#39;)

# Dummy code batch and assessment_centre
batch_dum&lt;-data.table(FID=geno_covar$FID, IID=geno_covar$IID, model.matrix(~ as.factor(batch)-1, geno_covar)[,-1]+1)
names(batch_dum)&lt;-c(&#39;FID&#39;,&#39;IID&#39;,paste0(&#39;batch&#39;, 1:(dim(batch_dum)[2]-2)))
assessment_centre_dum&lt;-data.table(FID=geno_covar$FID, IID=geno_covar$IID, model.matrix(~ as.factor(assessment_centre)-1, geno_covar)[,-1]+1)
names(assessment_centre_dum)&lt;-c(&#39;FID&#39;,&#39;IID&#39;,paste0(&#39;centre&#39;, 1:(dim(assessment_centre_dum)[2]-2)))
geno_covar$batch&lt;-NULL
geno_covar$assessment_centre&lt;-NULL

covs&lt;-Reduce(function(...) merge(..., all=F, by=c(&#39;FID&#39;,&#39;IID&#39;)), list(geno_covar, sex, age, batch_dum,assessment_centre_dum))

write.table(covs, &#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/ukb18177_glanville_covariates.UpdateIDs.Age.Sex.forPLINK.txt&#39;, quote=F, col.names=T, row.names=F)
</code></pre>
</details>
<p>Note. Running a regression with all covariates does not work due to multicolinearity. It also takes a very long time to run the GWAS. An alternative approach which seems to work well is regressing covariates out in advance, and then using the residuals in a chi-square test.</p>
<hr />
</div>
<div id="section-calculate-phenotype-residuals" class="section level2">
<h2><span class="header-section-number">1.3</span> Calculate phenotype residuals</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="r"><code>library(data.table)

####
# Prepare covariate data
####

# Read in covariate data
geno_covar&lt;-fread(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/ukb18177_glanville_covariates.UpdateIDs.txt&#39;)
sex&lt;-fread(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/UKBB_Sex.pheno&#39;)
age&lt;-fread(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/UKBB_Age.pheno&#39;)

covs&lt;-Reduce(function(...) merge(..., all=F, by=c(&#39;FID&#39;,&#39;IID&#39;)), list(geno_covar, sex, age))

# Convert catagorical variables into factors so they are dummy coded in the regression
covs$batch&lt;-factor(covs$batch)
covs$assessment_centre&lt;-factor(covs$assessment_centre)

# Read in list of individuals passing QC
QC&lt;-fread(&#39;/users/k1806347/brc_scratch/Analyses/PRS_comparison/UKBB_outcomes_for_prediction/ukb18177_glanville_post_qc_id_list.UpdateIDs.fam&#39;)
names(QC)&lt;-c(&#39;FID&#39;,&#39;IID&#39;)

# Merge all data
covs&lt;-Reduce(function(...) merge(..., all=F, by=c(&#39;FID&#39;,&#39;IID&#39;)), list(covs, QC))

###
# Residualise each phenotype within each subset
###

pheno&lt;-c(&#39;Depression&#39;,&#39;Intelligence&#39;,&#39;BMI&#39;,&#39;Height&#39;,&#39;T2D&#39;,&#39;CAD&#39;,&#39;IBD&#39;,&#39;MultiScler&#39;,&#39;RheuArth&#39;)
pheno_file&lt;-c(&#39;ever_depressed_pheno_final.UpdateIDs.txt&#39;,&#39;UKBB_Fluid.intelligence.score.UpdateIDs.pheno&#39;,&#39;UKBB_BMI.score.UpdateIDs.pheno&#39;,&#39;UKBB_Height.score.UpdateIDs.pheno&#39;,&#39;t2d_only_111119.UpdateIDs.txt&#39;,&#39;cad_only_111119.UpdateIDs.txt&#39;,&#39;UKBB.IBD.txt&#39;,&#39;UKBB.MultiScler.txt&#39;,&#39;UKBB.RheuArth.txt&#39;)

for(i in 1:length(pheno)){
  print(pheno[i])
  
  # Read in phenotype file
  pheno_i&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/&#39;,pheno[i],&#39;/&#39;,pheno_file[i]))
  names(pheno_i)[3]&lt;-&#39;pheno&#39;
  
  # Determine whether binary
  if(length(unique(pheno_i$pheno[!is.na(pheno_i$pheno)])) == 2){
    family_i&lt;-&#39;binomial&#39;
  } else {
    family_i&lt;-&#39;gaussian&#39;
  }
  
  # Merge pheno and covar data
  pheno_i_covs&lt;-merge(pheno_i, covs, by=c(&#39;FID&#39;,&#39;IID&#39;), all=T)
  
  pheno_i_resid&lt;-NULL
  for(subset_i in 1:10){
    # Read in subset keep file
    subset_keep&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_&#39;,subset_i,&#39;.keep&#39;))
    
    # Subset pheno and covar data
    pheno_i_covs_subset_i&lt;-pheno_i_covs[(pheno_i_covs$FID %in% subset_keep$V1),]
    
    # Calculate residuals
    resid_tmp&lt;-as.numeric(scale(resid(glm(pheno ~ ., family=family_i, data=pheno_i_covs_subset_i[,-1:-2], na.action=&#39;na.exclude&#39;))))
    
    pheno_i_resid_subset_i&lt;-data.frame(FID=pheno_i_covs_subset_i$FID,
                              IID=pheno_i_covs_subset_i$IID,
                              pheno_resid=resid_tmp)
    
    pheno_i_resid&lt;-rbind(pheno_i_resid, pheno_i_resid_subset_i)
  }
  
  # Save phenotype file
  write.table(pheno_i_resid, paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/&#39;,pheno[i],&#39;/&#39;,pheno[i],&#39;_LOO_resid.txt&#39;), col.names=T, row.name=F, quote=F)
  
}</code></pre>
</details>
<hr />
</div>
<div id="section-run-gwas-within-each-subset-for-each-phenotype" class="section level2">
<h2><span class="header-section-number">1.4</span> Run GWAS within each subset for each phenotype</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>
pheno=$(echo Depression Intelligence BMI Height T2D CAD IBD MultiScler RheuArth)

for subset in $(seq 1 10);do
mkdir /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_${subset}
  for i in $(seq 2 2); do
    pheno_i=$(echo ${pheno} | cut -f ${i} -d &#39; &#39;)

    for chr in $(seq 1 22); do
        sbatch -p brc,shared --mem 5G -t 00:10:00 /users/k1806347/brc_scratch/Software/plink1.9.sh \
          --bfile /users/k1806347/brc_scratch/Data/UKBB/Genotype/Harmonised/UKBB.w_hm3.QCd.AllSNP.chr${chr} \
          --pheno /users/k1806347/brc_scratch/Data/UKBB/Phenotype/${pheno_i}/${pheno_i}_LOO_resid.txt \
          --keep /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_${subset}.keep \
          --assoc \
          --maf 0.01 \
          --geno 0.05 \
          --allow-no-sex \
          --out /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_${subset}/UKBB.w_hm3.QCd.AllSNP.Subset_${subset}.${pheno_i}.chr${chr}
      done
  done
  sleep 600
done
</code></pre>
</details>
<hr />
</div>
<div id="section-meta-analyse-loo-results" class="section level2">
<h2><span class="header-section-number">1.5</span> Meta-analyse LOO results</h2>
<hr />
<div id="section-prepare-sumstats-for-metal" class="section level3">
<h3><span class="header-section-number">1.5.1</span> Prepare sumstats for METAL</h3>
<details>
<p><summary>Show code</summary></p>
<pre class="r"><code># Format results for use in METAL
library(data.table)

# Read in bim file
bim&lt;-NULL
for(chr in 1:22){
  bim_chr&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/Genotype/Harmonised/UKBB.w_hm3.QCd.AllSNP.chr&#39;,chr,&#39;.bim&#39;))
  bim&lt;-rbind(bim,bim_chr)
}

pheno&lt;-c(&#39;Depression&#39;,&#39;Intelligence&#39;,&#39;BMI&#39;,&#39;Height&#39;,&#39;T2D&#39;,&#39;CAD&#39;,&#39;IBD&#39;,&#39;MultiScler&#39;,&#39;RheuArth&#39;)

for(subset_i in 1:10){
  for(pheno_i in pheno[2]){
  gwas_i&lt;-NULL
    for(chr in 1:22){
          gwas_i_chr&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_&#39;,subset_i,&#39;/UKBB.w_hm3.QCd.AllSNP.Subset_&#39;,subset_i,&#39;.&#39;,pheno_i,&#39;.chr&#39;,chr,&#39;.qassoc&#39;))
          gwas_i_chr&lt;-merge(gwas_i_chr, bim, by.x=&#39;SNP&#39;, by.y=&#39;V2&#39;)
          gwas_i_chr&lt;-gwas_i_chr[,c(&#39;CHR&#39;,&#39;SNP&#39;,&#39;BP&#39;,&#39;V5&#39;,&#39;V6&#39;,&#39;BETA&#39;,&#39;SE&#39;,&#39;P&#39;,&#39;NMISS&#39;)]
          names(gwas_i_chr)&lt;-c(&#39;CHR&#39;,&#39;SNP&#39;,&#39;BP&#39;,&#39;A1&#39;,&#39;A2&#39;,&#39;BETA&#39;,&#39;SE&#39;,&#39;P&#39;,&#39;N&#39;)
          gwas_i_chr&lt;-gwas_i_chr[complete.cases(gwas_i_chr),]
      gwas_i&lt;-rbind(gwas_i, gwas_i_chr)
    }
    
    fwrite(gwas_i, paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_&#39;,subset_i,&#39;/UKBB.w_hm3.QCd.AllSNP.Subset_&#39;,subset_i,&#39;.&#39;,pheno_i,&#39;.GW.qassoc.clean&#39;), sep=&#39; &#39;, na=&#39;NA&#39;, quote=F)
  }
}</code></pre>
</details>
<hr />
</div>
<div id="section-run-meta-analysis-leaving-one-subset-out-each-time" class="section level3">
<h3><span class="header-section-number">1.5.2</span> Run meta-analysis leaving one subset out each time</h3>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>
# Delete per chromosome files
rm /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/*/*.chr*

# Run METAL using all subsets first
mkdir /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta

# Iteratively meta-analyse across all bar one subsets using METAL.
for subset in $(seq 1 10);do
for pheno in $(echo Intelligence); do

cat &gt; /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/metal_subset_template.sh &lt;&lt;EOF
MARKER SNP
ALLELE A1 A2
EFFECT BETA
PVALUE P
SCHEME STDERR
STDERR SE

PROCESS /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_1/UKBB.w_hm3.QCd.AllSNP.Subset_1.${pheno}.GW.qassoc.clean
PROCESS /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_2/UKBB.w_hm3.QCd.AllSNP.Subset_2.${pheno}.GW.qassoc.clean
PROCESS /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_3/UKBB.w_hm3.QCd.AllSNP.Subset_3.${pheno}.GW.qassoc.clean
PROCESS /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_4/UKBB.w_hm3.QCd.AllSNP.Subset_4.${pheno}.GW.qassoc.clean
PROCESS /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_5/UKBB.w_hm3.QCd.AllSNP.Subset_5.${pheno}.GW.qassoc.clean
PROCESS /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_6/UKBB.w_hm3.QCd.AllSNP.Subset_6.${pheno}.GW.qassoc.clean
PROCESS /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_7/UKBB.w_hm3.QCd.AllSNP.Subset_7.${pheno}.GW.qassoc.clean
PROCESS /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_8/UKBB.w_hm3.QCd.AllSNP.Subset_8.${pheno}.GW.qassoc.clean
PROCESS /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_9/UKBB.w_hm3.QCd.AllSNP.Subset_9.${pheno}.GW.qassoc.clean
PROCESS /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_10/UKBB.w_hm3.QCd.AllSNP.Subset_10.${pheno}.GW.qassoc.clean

OUTFILE /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/metal_excl_Subset_${subset}_${pheno} .tbl
ANALYZE 

QUIT

EOF

# Delete line containing subset
sed &quot;/\\.Subset_${subset}\\./d&quot; /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/metal_subset_template.sh &gt; /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/metal_subset_${subset}_${pheno}.sh

sbatch -p brc,shared /users/k1806347/brc_scratch/Software/metal.sh /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/metal_subset_${subset}_${pheno}.sh

done
done

# Delete the script files
rm /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/*sh
</code></pre>
</details>
<hr />
</div>
</div>
<div id="section-create-a-file-listing-the-sample-size-for-each-variant-and-all-phenotype" class="section level2">
<h2><span class="header-section-number">1.6</span> Create a file listing the sample size for each variant and all phenotype</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="r"><code>library(data.table)

pheno&lt;-c(&#39;Intelligence&#39;)

for(pheno_i in pheno[1]){
  for(subset in as.character(1:10)){
    gwas&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_&#39;,subset,&#39;/UKBB.w_hm3.QCd.AllSNP.Subset_&#39;,subset,&#39;.&#39;,pheno_i,&#39;.GW.qassoc.clean&#39;))
    
    if(subset == 1){
        N_tab_all&lt;-gwas[,c(&#39;SNP&#39;,&#39;N&#39;),with=F]
    } else {
        N_tab_all&lt;-merge(N_tab_all, gwas[,c(&#39;SNP&#39;,&#39;N&#39;),with=F], by=&#39;SNP&#39;)
    }
    
    names(N_tab_all)[names(N_tab_all) == &#39;N&#39;]&lt;-paste0(&#39;Subset_&#39;,subset,&#39;_N&#39;)

  }
  
  write.table(N_tab_all, paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/N_table_&#39;,pheno_i,&#39;.txt&#39;), col.names=T, row.names=F, quote=F)
}</code></pre>
</details>
<hr />
</div>
<div id="section-polygenic-scoring" class="section level2">
<h2><span class="header-section-number">1.7</span> Polygenic scoring</h2>
<p>Now we calculate polygenic scores for these phenotypes in UK Biobank, using the independent summary statistics. Lets use the standard PRScs method (best) and pT+clump method (traditional).</p>
<hr />
<div id="section-format-the-loo-meta-analysis-and-full-meta-analysis-results-for-polygenic-scoring" class="section level3">
<h3><span class="header-section-number">1.7.1</span> Format the LOO-meta-analysis and full meta-analysis results for polygenic scoring</h3>
<details>
<p><summary>Show code</summary></p>
<pre class="r"><code>library(data.table)

pheno&lt;-c(&#39;Depression&#39;,&#39;Intelligence&#39;,&#39;BMI&#39;,&#39;Height&#39;,&#39;T2D&#39;,&#39;CAD&#39;,&#39;IBD&#39;,&#39;MultiScler&#39;,&#39;RheuArth&#39;)

for(subset_i in 1:10){
  for(pheno_i in pheno[2]){
    gwas&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/metal_excl_Subset_&#39;,subset_i,&#39;_&#39;,pheno_i,&#39;1.tbl&#39;))
    names(gwas)&lt;-c(&#39;SNP&#39;,&#39;A1&#39;,&#39;A2&#39;,&#39;BETA&#39;,&#39;SE&#39;,&#39;P&#39;,&#39;Direction&#39;)
    gwas$Z&lt;-gwas$BETA/gwas$SE
    gwas&lt;-gwas[,c(&#39;SNP&#39;,&#39;A1&#39;,&#39;A2&#39;,&#39;Z&#39;),with=F]
    gwas$A1&lt;-toupper(gwas$A1)
    gwas$A2&lt;-toupper(gwas$A2)
    
    N_tab&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/N_table_&#39;,pheno_i,&#39;.txt&#39;))
    
    N_tab$excl_subset&lt;-rowSums(N_tab[,names(N_tab)[!grepl(paste0(&#39;SNP|Subset_&#39;,subset_i,&#39;_N&#39;), names(N_tab))],with=F])
  
  gwas&lt;-merge(gwas, N_tab[,c(&#39;SNP&#39;,&#39;excl_subset&#39;), with=F], by=&#39;SNP&#39;)
  
  names(gwas)[names(gwas) == &#39;excl_subset&#39;]&lt;-&#39;N&#39;
  
    fwrite(gwas, paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/metal_excl_Subset_&#39;,subset_i,&#39;_&#39;,pheno_i,&#39;.clean&#39;), sep=&#39; &#39;, na=&#39;NA&#39;, quote=F)
  }
}</code></pre>
</details>
<hr />
</div>
<div id="section-compress-the-sumstats" class="section level3">
<h3><span class="header-section-number">1.7.2</span> Compress the sumstats</h3>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>for pheno in $(echo Intelligence); do
  for subset in $(seq 1 10);do
    /users/k1806347/brc_scratch/Software/pigz /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/metal_excl_Subset_${subset}_${pheno}.clean
  done
done</code></pre>
</details>
<hr />
</div>
<div id="section-prscs" class="section level3">
<h3><span class="header-section-number">1.7.3</span> PRScs</h3>
<hr />
<div id="section-run-prscs" class="section level4">
<h4><span class="header-section-number">1.7.3.1</span> Run PRScs</h4>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>
# Run PRScs
for pheno in $(echo Intelligence); do
  for subset in $(seq 1 10);do

    sbatch -p brc,shared -n 4 --mem 6G /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/MyGit/GenoPred/Scripts/polygenic_score_file_creator_PRScs/polygenic_score_file_creator_PRScs.R \
    --ref_plink_chr /users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.w_hm3.chr \
    --sumstats /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/metal_excl_Subset_${subset}_${pheno}.clean.gz \
    --plink /users/k1806347/brc_scratch/Software/plink1.9.sh \
    --memory 5000 \
    --output /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/PRScs/${pheno}/excl_Subset_${subset}/PRScs_excl_Subset_${subset}_${pheno} \
    --ref_pop_scale /users/k1806347/brc_scratch/Data/1KG/Phase3/super_pop_keep.list \
    --PRScs_path /users/k1806347/brc_scratch/Software/PRScs.sh \
    --PRScs_ref_path /users/k1806347/brc_scratch/Software/PRScs/ldblk_1kg_eur \
    --n_cores 4 \
    --phi_param auto

  done
done

# Calculate polygenic scores in each subset
for pheno in $(echo BMI Intelligence CAD); do
  for subset in $(seq 1 10);do
  
    mkdir -p /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/PRScs/${pheno}/Subset_${subset}
    
    sbatch -n 1 --mem 10G -t 1:00:00 -p brc,shared /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/MyGit/GenoPred/Scripts/Scaled_polygenic_scorer_PRScs/Scaled_polygenic_scorer_PRScs.R \
      --target_plink_chr /users/k1806347/brc_scratch/Data/UKBB/Genotype/Harmonised/UKBB.w_hm3.QCd.AllSNP.chr \
      --target_keep /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_${subset}.keep \
      --ref_score /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/PRScs/${pheno}/excl_Subset_${subset}/PRScs_excl_Subset_${subset}_${pheno} \
      --ref_scale /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/PRScs/${pheno}/excl_Subset_${subset}/PRScs_excl_Subset_${subset}_${pheno}.EUR.scale \
      --ref_freq_chr /users/k1806347/brc_scratch/Data/1KG/Phase3/freq_files/EUR/1KGPhase3.w_hm3.EUR.chr \
      --plink /users/k1806347/brc_scratch/Software/plink1.9.sh \
      --output /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/PRScs/${pheno}/Subset_${subset}/Subset_${subset}_${pheno}_PRScs.Phi
  done
done
</code></pre>
</details>
<hr />
</div>
<div id="section-evaluate-predictive-utility-of-prs" class="section level4">
<h4><span class="header-section-number">1.7.3.2</span> Evaluate predictive utility of PRS</h4>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code># Combine the polygenic scores for each subset
library(data.table)

####
# Prepare covariate data
####

# Read in covariate data
geno_covar&lt;-fread(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/ukb18177_glanville_covariates.UpdateIDs.txt&#39;)
sex&lt;-fread(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/UKBB_Sex.pheno&#39;)
age&lt;-fread(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/UKBB_Age.pheno&#39;)

covs&lt;-Reduce(function(...) merge(..., all=F, by=c(&#39;FID&#39;,&#39;IID&#39;)), list(geno_covar, sex, age))

# Convert catagorical variables into factors so they are dummy coded in the regression
covs$batch&lt;-factor(covs$batch)
covs$assessment_centre&lt;-factor(covs$assessment_centre)

# Read in list of individuals passing QC
QC&lt;-fread(&#39;/users/k1806347/brc_scratch/Analyses/PRS_comparison/UKBB_outcomes_for_prediction/ukb18177_glanville_post_qc_id_list.UpdateIDs.fam&#39;)
names(QC)&lt;-c(&#39;FID&#39;,&#39;IID&#39;)

# Merge all data
covs&lt;-Reduce(function(...) merge(..., all=F, by=c(&#39;FID&#39;,&#39;IID&#39;)), list(covs, QC))

###
# Read in pheno type and PRS data, regress covariates from PRS within subset, and the estimate R2 and AUC across subsets.
###

pheno&lt;-c(&#39;Depression&#39;,&#39;Intelligence&#39;,&#39;BMI&#39;,&#39;Height&#39;,&#39;T2D&#39;,&#39;CAD&#39;,&#39;IBD&#39;,&#39;MultiScler&#39;,&#39;RheuArth&#39;)
pheno_file&lt;-c(&#39;ever_depressed_pheno_final.UpdateIDs.txt&#39;,&#39;UKBB_Fluid.intelligence.score.UpdateIDs.pheno&#39;,&#39;UKBB_BMI.score.UpdateIDs.pheno&#39;,&#39;UKBB_Height.score.UpdateIDs.pheno&#39;,&#39;t2d_only_111119.UpdateIDs.txt&#39;,&#39;cad_only_111119.UpdateIDs.txt&#39;,&#39;UKBB.IBD.txt&#39;,&#39;UKBB.MultiScler.txt&#39;,&#39;UKBB.RheuArth.txt&#39;)
prev=c(0.15,NA,NA,NA,0.05,0.03,0.013,0.00164,0.005)

pheno_res&lt;-NULL
for(i in c(1,2,3,5,6)){
  print(pheno[i])
  
  # Read in phenotype file
  pheno_i&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/&#39;,pheno[i],&#39;/&#39;,pheno_file[i]))
  names(pheno_i)[3]&lt;-&#39;pheno&#39;
  
  # Determine whether binary
  if(length(unique(pheno_i$pheno[!is.na(pheno_i$pheno)])) == 2){
    family_i&lt;-&#39;binomial&#39;
  } else {
    family_i&lt;-&#39;gaussian&#39;
  }
  
  # Merge pheno and covar data
  pheno_i_covs&lt;-merge(pheno_i, covs, by=c(&#39;FID&#39;,&#39;IID&#39;), all=T)

  pheno_i_covs_prs&lt;-NULL
  for(subset_i in 1:10){
    # Read in PRS for subset      
    prs_var_subset&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/PRScs/&#39;,pheno[i],&#39;/Subset_&#39;,subset_i,&#39;/Subset_&#39;,subset_i,&#39;_&#39;,pheno[i],&#39;_PRScs.Phi.PRScs_profiles&#39;))
    
    # Merge with pheno and covs
    pheno_i_covs_prs_subset&lt;-merge(pheno_i_covs, prs_var_subset, by=c(&#39;FID&#39;,&#39;IID&#39;))
    
    # Remove incomplete rows
    pheno_i_covs_prs_subset&lt;-pheno_i_covs_prs_subset[complete.cases(pheno_i_covs_prs_subset),]

    # Regress covariates out of the PRS
    pheno_i_covs_prs_subset$SCORE_phiauto&lt;-as.numeric(scale(resid(glm(SCORE_phiauto ~ ., family=&#39;gaussian&#39;, data=pheno_i_covs_prs_subset[,-1:-3]))))
    
    pheno_i_covs_prs&lt;-rbind(pheno_i_covs_prs, pheno_i_covs_prs_subset)
  }
  
  # Run regression between outcome and PRS residuals
  model&lt;-glm(pheno ~ SCORE_phiauto, data=pheno_i_covs_prs, family=family_i)
  summary_model&lt;-summary(model)
  
  # Calculate Observed R2, Liability R2 and AUC
  obs_R2&lt;-cor(pheno_i_covs_prs$pheno, pheno_i_covs_prs$SCORE_phiauto)^2
  
  if(family_i == &#39;binomial&#39;){
    library(&#39;fmsb&#39;)
    Nag_R2&lt;-NagR2&lt;-NagelkerkeR2(model)$R2
    h2l_R2N &lt;- function(k, r2n, p) {
      # k baseline disease risk
      # r2n Nagelkerke&#39;s attributable to genomic profile risk score
      # proportion of sample that are cases
      # calculates proportion of variance explained on the liability scale
      #from ABC at http://www.complextraitgenomics.com/software/
      #Lee SH, Goddard ME, Wray NR, Visscher PM. (2012) A better coefficient of determination for genetic profile analysis. Genet Epidemiol. 2012 Apr;36(3):214-24.
      x &lt;- qnorm(1 - k)
      z &lt;- dnorm(x)
      i &lt;- z / k
      cc &lt;- k * (1 - k) * k * (1 - k) / (z^2 * p * (1 - p))
      theta &lt;- i * ((p - k)/(1 - k)) * (i * ((p - k) / ( 1 - k)) - x)
      e &lt;- 1 - p^(2 * p) * (1 - p)^(2 * (1 - p))
      h2l_R2N &lt;- cc * e * r2n / (1 + cc * e * theta * r2n)
    }
    liab_R2&lt;-h2l_R2N(prev[i], Nag_R2, mean(pheno_i_covs_prs$pheno))
    library(pROC)
    auc_prs&lt;-auc(pheno_i_covs_prs$pheno, pheno_i_covs_prs$SCORE_phiauto)
    
      pheno_res&lt;-rbind(pheno_res, data.frame( Phenotype=pheno[i],
                                              Estimate=coef(summary_model)[2,1],
                                              SE=coef(summary_model)[2,2],
                                              P=coef(summary_model)[2,4],
                                              R2_obs=obs_R2,
                                              R2_nag=Nag_R2,
                                              R2_liab=liab_R2,
                                              AUC=auc_prs,
                                              N=length(pheno_i_covs_prs$pheno),
                                              Ncase=sum(pheno_i_covs_prs$pheno == 1),
                                              Ncon=sum(pheno_i_covs_prs$pheno == 0),
                                              Pop_prev=prev[i]))
                                            
  } else {
    
    pheno_res&lt;-rbind(pheno_res, data.frame( Phenotype=pheno[i],
                                            Estimate=coef(summary_model)[2,1],
                                            SE=coef(summary_model)[2,2],
                                            P=coef(summary_model)[2,4],
                                            R2_obs=obs_R2,
                                            R2_nag=NA,
                                            R2_liab=NA,
                                            AUC=NA,
                                            N=length(pheno_i_covs_prs$pheno),
                                            Ncase=NA,
                                            Ncon=NA,
                                            Pop_prev=NA))

  }
}

write.csv(pheno_res, &#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/PRScs/Pheno_PRS_assoc_res.csv&#39;, row.names=F, quote=F)
</code></pre>
</details>
<hr />
</div>
</div>
<div id="section-ptclump" class="section level3">
<h3><span class="header-section-number">1.7.4</span> pT+clump</h3>
<hr />
<div id="section-run-ptclump" class="section level4">
<h4><span class="header-section-number">1.7.4.1</span> Run pT+clump</h4>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>for pheno in $(echo Intelligence); do
  for subset in $(seq 1 10);do

    sbatch -p brc,shared --mem 6G /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/MyGit/GenoPred/Scripts/polygenic_score_file_creator/polygenic_score_file_creator.R \
      --ref_plink_chr /users/k1806347/brc_scratch/Data/1KG/Phase3/1KGPhase3.w_hm3.chr \
      --sumstats /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/metal_excl_Subset_${subset}_${pheno}.clean.gz \
      --plink /users/k1806347/brc_scratch/Software/plink1.9.sh \
      --memory 5000 \
      --output /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/pTclump/${pheno}/excl_Subset_${subset}/pTclump_excl_Subset_${subset}_${pheno} \
      --ref_pop_scale /users/k1806347/brc_scratch/Data/1KG/Phase3/super_pop_keep.list
done
done

# Calculate polygenic scores in each subset
for pheno in $(echo Intelligence); do
  for subset in $(seq 1 10);do
  
    mkdir -p /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/PRScs/${pheno}/Subset_${subset}
    
    sbatch --mem 10G -p brc,shared -J pT_clump /users/k1806347/brc_scratch/Software/Rscript.sh /users/k1806347/brc_scratch/Software/MyGit/GenoPred/Scripts/Scaled_polygenic_scorer/Scaled_polygenic_scorer.R \
      --target_plink_chr /users/k1806347/brc_scratch/Data/UKBB/Genotype/Harmonised/UKBB.w_hm3.QCd.AllSNP.chr \
      --target_keep /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/Subset_${subset}.keep \
    --ref_score /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/pTclump/${pheno}/excl_Subset_${subset}/pTclump_excl_Subset_${subset}_${pheno} \
    --ref_scale /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/pTclump/${pheno}/excl_Subset_${subset}/pTclump_excl_Subset_${subset}_${pheno}.EUR.scale \
    --pheno_name ${pheno} \
    --ref_freq_chr /users/k1806347/brc_scratch/Data/1KG/Phase3/freq_files/EUR/1KGPhase3.w_hm3.EUR.chr \
    --plink /users/k1806347/brc_scratch/Software/plink1.9.sh \
    --output /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/pTclump/${pheno}/Subset_${subset}/Subset_${subset}_${pheno}_pTclump

  done
done</code></pre>
</details>
<hr />
</div>
<div id="section-evaluate-predictive-utility-of-prs-1" class="section level4">
<h4><span class="header-section-number">1.7.4.2</span> Evaluate predictive utility of PRS</h4>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code># Combine the polygenic scores for each subset
library(data.table)

####
# Prepare covariate data
####

# Read in covariate data
geno_covar&lt;-fread(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/ukb18177_glanville_covariates.UpdateIDs.txt&#39;)
sex&lt;-fread(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/UKBB_Sex.pheno&#39;)
age&lt;-fread(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/UKBB_Age.pheno&#39;)

covs&lt;-Reduce(function(...) merge(..., all=F, by=c(&#39;FID&#39;,&#39;IID&#39;)), list(geno_covar, sex, age))

# Convert catagorical variables into factors so they are dummy coded in the regression
covs$batch&lt;-factor(covs$batch)
covs$assessment_centre&lt;-factor(covs$assessment_centre)

# Read in list of individuals passing QC
QC&lt;-fread(&#39;/users/k1806347/brc_scratch/Analyses/PRS_comparison/UKBB_outcomes_for_prediction/ukb18177_glanville_post_qc_id_list.UpdateIDs.fam&#39;)
names(QC)&lt;-c(&#39;FID&#39;,&#39;IID&#39;)

# Merge all data
covs&lt;-Reduce(function(...) merge(..., all=F, by=c(&#39;FID&#39;,&#39;IID&#39;)), list(covs, QC))

###
# Read in pheno type and PRS data, regress covariates from PRS within subset, and the estimate R2 and AUC across subsets.
###

pheno&lt;-c(&#39;Depression&#39;,&#39;Intelligence&#39;,&#39;BMI&#39;,&#39;Height&#39;,&#39;T2D&#39;,&#39;CAD&#39;,&#39;IBD&#39;,&#39;MultiScler&#39;,&#39;RheuArth&#39;)
pheno_file&lt;-c(&#39;ever_depressed_pheno_final.UpdateIDs.txt&#39;,&#39;UKBB_Fluid.intelligence.score.UpdateIDs.pheno&#39;,&#39;UKBB_BMI.score.UpdateIDs.pheno&#39;,&#39;UKBB_Height.score.UpdateIDs.pheno&#39;,&#39;t2d_only_111119.UpdateIDs.txt&#39;,&#39;cad_only_111119.UpdateIDs.txt&#39;,&#39;UKBB.IBD.txt&#39;,&#39;UKBB.MultiScler.txt&#39;,&#39;UKBB.RheuArth.txt&#39;)
prev=c(0.15,NA,NA,NA,0.05,0.03,0.013,0.00164,0.005)

for(i in c(2)){
  print(pheno[i])
  
  # Read in phenotype file
  pheno_i&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/&#39;,pheno[i],&#39;/&#39;,pheno_file[i]))
  names(pheno_i)[3]&lt;-&#39;pheno&#39;
  
  # Determine whether binary
  if(length(unique(pheno_i$pheno[!is.na(pheno_i$pheno)])) == 2){
    family_i&lt;-&#39;binomial&#39;
  } else {
    family_i&lt;-&#39;gaussian&#39;
  }
  
  # Merge pheno and covar data
  pheno_i_covs&lt;-merge(pheno_i, covs, by=c(&#39;FID&#39;,&#39;IID&#39;), all=T)

  pheno_res&lt;-NULL
  pheno_i_covs_prs&lt;-NULL
  for(subset_i in 1:10){
    print(subset_i)
    # Read in PRS for subset
    prs_var_subset&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/pTclump/&#39;,pheno[i],&#39;/Subset_&#39;,subset_i,&#39;/Subset_&#39;,subset_i,&#39;_&#39;,pheno[i],&#39;_pTclump.profiles&#39;))
    
    names(prs_var_subset)&lt;-gsub(&#39;-&#39;,&#39;_&#39;,names(prs_var_subset))

    if(subset_i != 1){
      prs_var_subset&lt;-prs_var_subset[,(names(prs_var_subset) %in% names(pheno_i_covs_prs)), with=F]
    }
    
    # Identify pT columns
    pT&lt;-gsub(paste0(pheno[i],&#39;_&#39;),&#39;&#39;,names(prs_var_subset)[-1:-2])

    # Merge with pheno and covs
    pheno_i_covs_prs_subset&lt;-merge(pheno_i_covs, prs_var_subset, by=c(&#39;FID&#39;,&#39;IID&#39;))
    
    # Remove incomplete rows
    pheno_i_covs_prs_subset&lt;-pheno_i_covs_prs_subset[complete.cases(pheno_i_covs_prs_subset),]
    
    for(pT_i in pT){
    
    # Regress covariates out of the PRS
    pheno_i_covs_prs_subset[[paste0(pheno[i],&#39;_&#39;,pT_i)]]&lt;-as.numeric(scale(resid(glm(paste0(pheno[i],&#39;_&#39;,pT_i,&#39; ~ .&#39;), family=&#39;gaussian&#39;, data=pheno_i_covs_prs_subset[,-1:-3]))))
    
    }
    
    pheno_i_covs_prs&lt;-rbind(pheno_i_covs_prs, pheno_i_covs_prs_subset)
  }
  
  # Run regression between outcome and PRS residuals
  for(pT_i in pT){

    model&lt;-glm(paste0(&#39;pheno ~ &#39;,pheno[i],&#39;_&#39;,pT_i), data=pheno_i_covs_prs, family=family_i)
    summary_model&lt;-summary(model)
    
    # Calculate Observed R2, Liability R2 and AUC
    obs_R2&lt;-cor(pheno_i_covs_prs$pheno, pheno_i_covs_prs[[paste0(pheno[i],&#39;_&#39;,pT_i)]])^2
    
    if(family_i == &#39;binomial&#39;){
      library(&#39;fmsb&#39;)
      Nag_R2&lt;-NagR2&lt;-NagelkerkeR2(model)$R2
      h2l_R2N &lt;- function(k, r2n, p) {
        # k baseline disease risk
        # r2n Nagelkerke&#39;s attributable to genomic profile risk score
        # proportion of sample that are cases
        # calculates proportion of variance explained on the liability scale
        #from ABC at http://www.complextraitgenomics.com/software/
        #Lee SH, Goddard ME, Wray NR, Visscher PM. (2012) A better coefficient of determination for genetic profile analysis. Genet Epidemiol. 2012 Apr;36(3):214-24.
        x &lt;- qnorm(1 - k)
        z &lt;- dnorm(x)
        i &lt;- z / k
        cc &lt;- k * (1 - k) * k * (1 - k) / (z^2 * p * (1 - p))
        theta &lt;- i * ((p - k)/(1 - k)) * (i * ((p - k) / ( 1 - k)) - x)
        e &lt;- 1 - p^(2 * p) * (1 - p)^(2 * (1 - p))
        h2l_R2N &lt;- cc * e * r2n / (1 + cc * e * theta * r2n)
      }
      liab_R2&lt;-h2l_R2N(prev[i], Nag_R2, mean(pheno_i_covs_prs$pheno))
      library(pROC)
      auc_prs&lt;-auc(pheno_i_covs_prs$pheno, pheno_i_covs_prs[[paste0(pheno[i],&#39;_&#39;,pT_i)]])
      
        pheno_res&lt;-rbind(pheno_res, data.frame( Phenotype=pheno[i],
                                                Estimate=coef(summary_model)[2,1],
                                                SE=coef(summary_model)[2,2],
                                                P=coef(summary_model)[2,4],
                                                R2_obs=obs_R2,
                                                R2_nag=Nag_R2,
                                                R2_liab=liab_R2,
                                                AUC=auc_prs,
                                                N=length(pheno_i_covs_prs$pheno),
                                                Ncase=sum(pheno_i_covs_prs$pheno == 1),
                                                Ncon=sum(pheno_i_covs_prs$pheno == 0),
                                                Pop_prev=prev[i],
                                                pT=pT_i))
                                              
    } else {
      
      pheno_res&lt;-rbind(pheno_res, data.frame( Phenotype=pheno[i],
                                              Estimate=coef(summary_model)[2,1],
                                              SE=coef(summary_model)[2,2],
                                              P=coef(summary_model)[2,4],
                                              R2_obs=obs_R2,
                                              R2_nag=NA,
                                              R2_liab=NA,
                                              AUC=NA,
                                              N=length(pheno_i_covs_prs$pheno),
                                              Ncase=NA,
                                              Ncon=NA,
                                              Pop_prev=NA,
                                              pT=pT_i))
  
    }
  }
write.csv(pheno_res,paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/pTclump/&#39;,pheno[i],&#39;_PRS_assoc_res.csv&#39;), row.names=F, quote=F)
}
</code></pre>
</details>
<p><br/></p>
<hr />
</div>
</div>
</div>
</div>
<div id="section-compare-prs-auc-values-to-those-derived-using-g-wiz" class="section level1">
<h1><span class="header-section-number">2</span> Compare PRS AUC values to those derived using G-WIZ</h1>
<p>We will calculate the AUC using GWIZ using the leave one out meta-analysis summary statistics, and then average the AUC results. This will hopefully tell us how much variance GWAS expects the LOO sumstats to explain in the left out subset.</p>
<hr />
<div id="section-compute-allele-frequencies" class="section level2">
<h2><span class="header-section-number">2.1</span> Compute allele frequencies</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="bash"><code>for chr in $(seq 1 22); do
    sbatch -p brc,shared --mem 5G -t 00:10:00 /users/k1806347/brc_scratch/Software/plink1.9.sh \
      --bfile /users/k1806347/brc_scratch/Data/UKBB/Genotype/Harmonised/UKBB.w_hm3.QCd.AllSNP.chr${chr} \
      --keep /users/k1806347/brc_scratch/Analyses/PRS_comparison/UKBB_outcomes_for_prediction/ukb18177_glanville_post_qc_id_list.UpdateIDs.fam \
      --maf 0.01 \
      --geno 0.05 \
      --freq \
      --allow-no-sex \
      --out /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/allele_freq_chr${chr}
done
</code></pre>
</details>
<hr />
</div>
<div id="section-format-gwas-summary-statistics" class="section level2">
<h2><span class="header-section-number">2.2</span> Format GWAS summary statistics</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="r"><code>library(data.table)

pheno&lt;-c(&#39;Depression&#39;,&#39;Intelligence&#39;,&#39;BMI&#39;,&#39;Height&#39;,&#39;T2D&#39;,&#39;CAD&#39;,&#39;IBD&#39;,&#39;MultiScler&#39;,&#39;RheuArth&#39;)
pheno_file&lt;-c(&#39;ever_depressed_pheno_final.UpdateIDs.txt&#39;,&#39;UKBB_Fluid.intelligence.score.UpdateIDs.pheno&#39;,&#39;UKBB_BMI.score.UpdateIDs.pheno&#39;,&#39;UKBB_Height.score.UpdateIDs.pheno&#39;,&#39;t2d_only_111119.UpdateIDs.txt&#39;,&#39;cad_only_111119.UpdateIDs.txt&#39;,&#39;UKBB.IBD.txt&#39;,&#39;UKBB.MultiScler.txt&#39;,&#39;UKBB.RheuArth.txt&#39;)

# Read in covariate data
geno_covar&lt;-fread(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/ukb18177_glanville_covariates.UpdateIDs.txt&#39;)
sex&lt;-fread(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/UKBB_Sex.pheno&#39;)
age&lt;-fread(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/UKBB_Age.pheno&#39;)

covs&lt;-Reduce(function(...) merge(..., all=F, by=c(&#39;FID&#39;,&#39;IID&#39;)), list(geno_covar, sex, age))

# Convert catagorical variables into factors so they are dummy coded in the regression
covs$batch&lt;-factor(covs$batch)
covs$assessment_centre&lt;-factor(covs$assessment_centre)

# Read in list of individuals passing QC
QC&lt;-fread(&#39;/users/k1806347/brc_scratch/Analyses/PRS_comparison/UKBB_outcomes_for_prediction/ukb18177_glanville_post_qc_id_list.UpdateIDs.fam&#39;)
names(QC)&lt;-c(&#39;FID&#39;,&#39;IID&#39;)

# Merge all data
covs&lt;-Reduce(function(...) merge(..., all=F, by=c(&#39;FID&#39;,&#39;IID&#39;)), list(covs, QC))

# Read in allele frequency per variant
freq&lt;-NULL
for(chr in 1:22){
  freq&lt;-rbind(freq, fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/allele_freq_chr&#39;,chr,&#39;.frq&#39;)))
}

freq$A1&lt;-tolower(freq$A1)
freq$A2&lt;-tolower(freq$A2)

for(i in c(5)){
  # Read in pheno file to determine number of cases and controls
  pheno_i&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/&#39;,pheno[i],&#39;/&#39;,pheno_file[i]))
  names(pheno_i)[3]&lt;-&#39;pheno&#39;
  
  # Merge pheno and covar data
  pheno_i_covs&lt;-merge(pheno_i, covs, by=c(&#39;FID&#39;,&#39;IID&#39;), all=T)
  pheno_i_covs&lt;-pheno_i_covs[complete.cases(pheno_i_covs),]
  
  # Identify proportion of cases and controls which can be used to estimate the number of cases and controls in each LOO meta-analysis.
  sample_prev&lt;-mean(pheno_i_covs$pheno)
  
  for(subset_i in 1:10){
    # Read in meta-analysis GWAS sumstats
    gwas&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/metal_excl_Subset_&#39;,subset_i,&#39;_&#39;,pheno[i],&#39;1.tbl&#39;))
    names(gwas)&lt;-c(&#39;SNP&#39;,&#39;A1&#39;,&#39;A2&#39;,&#39;BETA&#39;,&#39;SE&#39;,&#39;P&#39;,&#39;Direction&#39;)
    gwas$OR&lt;-exp(gwas$BETA)
    gwas$phenotype&lt;-&#39;n/a&#39;
    gwas$dataset&lt;-&#39;n/a&#39;
    gwas$model&lt;-&#39;additive&#39;
    
    # Read sample size per variant
    N_tab&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/N_table_&#39;,pheno[i],&#39;.txt&#39;))
    
    N_tab$excl_subset&lt;-rowSums(N_tab[,names(N_tab)[!grepl(paste0(&#39;SNP|Subset_&#39;,subset_i,&#39;_N&#39;), names(N_tab))],with=F])
  
    N_tab$control_size&lt;-round(N_tab$excl_subset*(1-sample_prev))
    N_tab$case_size&lt;-round(N_tab$excl_subset*(sample_prev))
      
    gwas&lt;-merge(gwas, N_tab[,c(&#39;SNP&#39;,&#39;control_size&#39;,&#39;case_size&#39;), with=F], by=&#39;SNP&#39;)
    
    # Merge frequency data
    gwas_same&lt;-merge(gwas, freq[,c(&#39;SNP&#39;,&#39;A1&#39;,&#39;A2&#39;,&#39;MAF&#39;)], by=c(&#39;SNP&#39;,&#39;A1&#39;,&#39;A2&#39;))
    gwas_flip&lt;-merge(gwas, freq[,c(&#39;SNP&#39;,&#39;A1&#39;,&#39;A2&#39;,&#39;MAF&#39;)], by.x=c(&#39;SNP&#39;,&#39;A1&#39;,&#39;A2&#39;),by.y=c(&#39;SNP&#39;,&#39;A2&#39;,&#39;A1&#39;))
    gwas_flip$MAF&lt;-1-gwas_flip$MAF
    gwas&lt;-rbind(gwas_same, gwas_flip)
    
    # OR and MAFs to all be corresponding to the risk allele
    gwas$MAF[gwas$OR &lt; 1]&lt;-1-gwas$MAF[gwas$OR &lt; 1]
    names(gwas)[names(gwas) == &#39;MAF&#39;]&lt;-&#39;risk_allele_freq&#39;
    gwas$OR[gwas$OR &lt; 1]&lt;-exp(-gwas$BETA[gwas$OR &lt; 1])
    
    # Extract LD independent variants
    ld_indep&lt;-NULL
    for(chr in 1:22){
      ld_indep&lt;-rbind(ld_indep, fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/pTclump/&#39;,pheno[i],&#39;/excl_Subset_&#39;,subset_i,&#39;/pTclump_excl_Subset_&#39;,subset_i,&#39;_&#39;,pheno[i],&#39;.chr&#39;,chr,&#39;.range_values&#39;)))
    }
    
    ld_indep_sig&lt;-ld_indep

    # Extract variant with p &lt; 1e-8
    gwas&lt;-gwas[(gwas$SNP %in% ld_indep_sig$V1),]

    gwas&lt;-gwas[,c(&#39;phenotype&#39;,&#39;dataset&#39;,&#39;SNP&#39;,&#39;control_size&#39;,&#39;case_size&#39;,&#39;risk_allele_freq&#39;,&#39;OR&#39;,&#39;model&#39;),with=F]
    names(gwas)[names(gwas) == &#39;SNP&#39;]&lt;-&#39;accession&#39;
    
    gwas$model&lt;-rep(c(&#39;recessive&#39;,&#39;dominant&#39;),dim(gwas)[1])[1:dim(gwas)[1]]
    
      fwrite(gwas, paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/GWIZ/metal_excl_Subset_&#39;,subset_i,&#39;_&#39;,pheno[i],&#39;.GWIZ.csv&#39;), sep=&#39;,&#39;, na=&#39;NA&#39;, quote=F)
  }
}</code></pre>
</details>
<hr />
</div>
<div id="section-run-gwiz" class="section level2">
<h2><span class="header-section-number">2.3</span> Run GWIZ</h2>
<p>GWIZ is an R script. It needs to modification: - It doesn’t allow input files, software and output to be in different directories - It uses the png function which does’t work on Rosalind - It prints the contents of the GWAS sumstats repeatedly and GWIZ is an Rscript that must be modified to allow for different input and output files. I have the script slightly so all files don’t have be stored in the same directory.</p>
<details>
<p><summary>Show code</summary></p>
<pre class="r"><code>sumstat_dir&lt;-&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/GWIZ/&#39;
software_dir&lt;-&#39;/mnt/lustre/users/k1806347/Software/GWIZ-Rscript-master&#39;
out_dir&lt;-&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/GWIZ/&#39;

folderPath &lt;- paste0(sumstat_dir,&quot;Data/&quot;)
filename = &quot;resampled Data&quot;
resultsfilename = &quot;results Data&quot;
dir.create(folderPath)
dir.create(paste0(out_dir,filename))
dir.create(paste0(out_dir,resultsfilename))
folderOut &lt;- paste0(out_dir,filename)

setwd(software_dir)

files &lt;- list.files(sumstat_dir)
files &lt;- files[grep(&quot;.csv&quot;, files)]
aucout &lt;- matrix(NA, nrow=length(files), ncol=2)
for (j in 1:1){
    source(&quot;./modeling/GWAS_functions.0,1,2genotype (attempt 4).R&quot;)
    genereteBatch(sumstat_dir, folderOut, files[[j]])
    studies &lt;- dir(paste0(folderOut,&#39;/out&#39;))
    studies &lt;- studies[grep(&quot;.csv&quot;, studies)]
    source(&quot;./modeling/_modelingFunctions_lda.R&quot;)
    batchAnalysis(paste(folderOut, &quot;/out&quot;, sep=&quot;&quot;), resultsfilename, studies[[j]], verbose = FALSE, outerFolds = 3L, outerRep = 2L)#, classifier = &quot;classif.logreg&quot;) 
    studyname = substring(files[[j]], 1, 13)
    aucout[j,] &lt;- c(studyname, aucanalysis)
    colnames(aucout) &lt;- c(&quot;Study&quot;, &quot;Simulated AUC&quot;)
}

# This code is working for T2D (Subset 1 only: p&lt;1-e4 with AUC=0.5433973. Observed value in UKB is AUC=0.5647935). However, the analysis is very slow when including more relaxed p-value thresholds. I just tried to run using all variants and the session was killed with 10G memory.</code></pre>
</details>
<p><br/></p>
<p><br/></p>
<hr />
</div>
</div>
<div id="section-compare-prs-auc-values-to-those-derived-using-avengeme-and-ldsc" class="section level1">
<h1><span class="header-section-number">3</span> Compare PRS AUC values to those derived using AVENGEME and LDSC</h1>
<p>AVENGEME can estimate the R2 you would expect to see from a polygenic scores given an estimate of heritability and sample size. To estimate heritability and polygenicity, we could use GCTB.</p>
<hr />
<div id="section-estimate-the-snp-based-heritability-using-ldsc" class="section level2">
<h2><span class="header-section-number">3.1</span> Estimate the SNP-based heritability using LDSC</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="r"><code>dir.create(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/LDSC&#39;)

pheno&lt;-c(&#39;Depression&#39;,&#39;Intelligence&#39;,&#39;BMI&#39;,&#39;Height&#39;,&#39;T2D&#39;,&#39;CAD&#39;,&#39;IBD&#39;,&#39;MultiScler&#39;,&#39;RheuArth&#39;)
pheno_file&lt;-c(&#39;ever_depressed_pheno_final.UpdateIDs.txt&#39;,&#39;UKBB_Fluid.intelligence.score.UpdateIDs.pheno&#39;,&#39;UKBB_BMI.score.UpdateIDs.pheno&#39;,&#39;UKBB_Height.score.UpdateIDs.pheno&#39;,&#39;t2d_only_111119.UpdateIDs.txt&#39;,&#39;cad_only_111119.UpdateIDs.txt&#39;,&#39;UKBB.IBD.txt&#39;,&#39;UKBB.MultiScler.txt&#39;,&#39;UKBB.RheuArth.txt&#39;)
prev=c(0.15,NA,NA,NA,0.05,0.03,0.013,0.00164,0.005)

library(data.table)

for(i in c(2)){
  PRS_res&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/pTclump/&#39;,pheno[i],&#39;_PRS_assoc_res.csv&#39;)) 
  sample_prev&lt;-round(PRS_res$Ncase[1]/PRS_res$N[1],2)
  
  for(subset_i in 1:10){
    if(is.na(prev[i])){
      system(paste0(&#39;sbatch -p brc,shared ~/brc_scratch/Software/ldsc.sh --h2 /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/metal_excl_Subset_&#39;,subset_i,&#39;_&#39;,pheno[i],&#39;.clean.gz --ref-ld-chr /users/k1806347/brc_scratch/Data/ldsc/eur_w_ld_chr/ --w-ld-chr /users/k1806347/brc_scratch/Data/ldsc/eur_w_ld_chr/ --out /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/LDSC/metal_excl_Subset_&#39;,subset_i,&#39;_&#39;,pheno[i],&#39;.obs&#39;))
    } else {
      system(paste0(&#39;sbatch -p brc,shared ~/brc_scratch/Software/ldsc.sh --h2 /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/metal_excl_Subset_&#39;,subset_i,&#39;_&#39;,pheno[i],&#39;.clean.gz --ref-ld-chr /users/k1806347/brc_scratch/Data/ldsc/eur_w_ld_chr/ --w-ld-chr /users/k1806347/brc_scratch/Data/ldsc/eur_w_ld_chr/ --samp-prev &#39;,sample_prev,&#39; --pop-prev &#39;,prev[i],&#39; --out /users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/LDSC/metal_excl_Subset_&#39;,subset_i,&#39;_&#39;,pheno[i],&#39;.liab&#39;))
    }
  }
}

# Read in LDSC estimates meta-analyse
library(meta)

meta_h2&lt;-NULL
for(i in c(1,2,3,5,6)){
  if(is.na(prev[i])){
    pheno_ldsc&lt;-NULL
    PRS_res&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/pTclump/&#39;,pheno[i],&#39;_PRS_assoc_res.csv&#39;)) 
    sample_N&lt;-PRS_res$N[1]
    for(subset_i in 1:10){
      log&lt;-read.table(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/LDSC/metal_excl_Subset_&#39;,subset_i,&#39;_&#39;,pheno[i],&#39;.obs.log&#39;), sep=&#39;&amp;&#39;)$V1
      h2_log&lt;-as.character(log[grepl(&#39;Total Observed scale h2&#39;, log)])
      h2_est&lt;-as.numeric(gsub(&#39; .*&#39;,&#39;&#39;,gsub(&#39;.*: &#39;, &#39;&#39;, h2_log)))
      h2_se&lt;-as.numeric(gsub(&quot;\\)&quot;,&#39;&#39;,gsub(&quot;.*\\(&quot;, &#39;&#39;, h2_log)))
      
      pheno_ldsc&lt;-rbind(pheno_ldsc, data.frame(Est=h2_est,
                                               SE=h2_se,
                                               Subset=subset_i))
    }
    meta_pheno_ldsc&lt;-metagen(pheno_ldsc$Est, pheno_ldsc$SE, pheno_ldsc$Subset, comb.random=F)
    
  meta_h2&lt;-rbind(meta_h2,data.frame(Phenotype=pheno[i],
                            H2_liab=NA,
                            H2_obs=meta_pheno_ldsc$TE.fixed,
                            SE=meta_pheno_ldsc$seTE.fixed,
                            P=meta_pheno_ldsc$pval.fixed,
                            pop_prev=NA,
                            sample_prev=NA,
                            N=sample_N))

  } else {
    pheno_ldsc&lt;-NULL
    PRS_res&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/pTclump/&#39;,pheno[i],&#39;_PRS_assoc_res.csv&#39;)) 
    sample_prev&lt;-round(PRS_res$Ncase[1]/PRS_res$N[1],2)
    sample_N&lt;-PRS_res$N[1]
  
    for(subset_i in 1:10){
      log&lt;-read.table(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/LDSC/metal_excl_Subset_&#39;,subset_i,&#39;_&#39;,pheno[i],&#39;.liab.log&#39;), sep=&#39;&amp;&#39;)$V1
      h2_log&lt;-as.character(log[grepl(&#39;Total Liability scale h2&#39;, log)])
      h2_est&lt;-as.numeric(gsub(&#39; .*&#39;,&#39;&#39;,gsub(&#39;.*: &#39;, &#39;&#39;, h2_log)))
      h2_se&lt;-as.numeric(gsub(&quot;\\)&quot;,&#39;&#39;,gsub(&quot;.*\\(&quot;, &#39;&#39;, h2_log)))
      
      pheno_ldsc&lt;-rbind(pheno_ldsc, data.frame(Est=h2_est,
                                               SE=h2_se,
                                               Subset=subset_i))
    }
    meta_pheno_ldsc&lt;-metagen(pheno_ldsc$Est, pheno_ldsc$SE, pheno_ldsc$Subset, comb.random=F)
    
  meta_h2&lt;-rbind(meta_h2,data.frame(Phenotype=pheno[i],
                            H2_liab=meta_pheno_ldsc$TE.fixed,
                            H2_obs=NA,
                            SE=meta_pheno_ldsc$seTE.fixed,
                            P=meta_pheno_ldsc$pval.fixed,
                            pop_prev=prev[i],
                            sample_prev=sample_prev,
                            N=sample_N))
  }
}

write.csv(meta_h2, &#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/LDSC/meta_h2.res.csv&#39;,row.names=F, quote=F)</code></pre>
</details>
<hr />
</div>
<div id="section-estimate-auc-using-avengeme" class="section level2">
<h2><span class="header-section-number">3.2</span> Estimate AUC using AVENGEME</h2>
<details>
<p><summary>Show code</summary></p>
<pre class="r"><code>library(avengeme)

# pi0 parameter doesn&#39;t affect AUC why using a p-value threshold of 1.

pheno&lt;-c(&#39;Depression&#39;,&#39;Intelligence&#39;,&#39;BMI&#39;,&#39;Height&#39;,&#39;T2D&#39;,&#39;CAD&#39;,&#39;IBD&#39;,&#39;MultiScler&#39;,&#39;RheuArth&#39;)

meta_h2&lt;-fread(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/meta/LDSC/meta_h2.res.csv&#39;)

AUC_R2_pred&lt;-NULL
for(i in c(1,2,3,5,6)){
  
  pheno_nsnp&lt;-NULL
  for(subset_i in 1:10){
    tmp&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/pTclump/&#39;,pheno[i],&#39;/excl_Subset_&#39;,subset_i,&#39;/pTclump_excl_Subset_&#39;,subset_i,&#39;_&#39;,pheno[i],&#39;.NSNP_per_pT&#39;))
  
    pheno_nsnp&lt;-rbind(pheno_nsnp, data.frame(Subset=subset_i,
                           NSNP=tmp$NSNP[length(tmp$NSNP)]))
  }

  mean_nsnp&lt;-mean(pheno_nsnp$NSNP)
  
  if(is.na(meta_h2$H2_liab[meta_h2$Phenotype == pheno[i]])){
    tmp&lt;-polygenescore(nsnp=mean_nsnp, n=meta_h2$N[meta_h2$Phenotype == pheno[i]], vg1 = meta_h2$H2_obs[meta_h2$Phenotype == pheno[i]], pupper = c(0, 1), nested = TRUE, weighted = TRUE, binary = F)
    
    pheno_res_pTclump&lt;-read.csv(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/pTclump/&#39;,pheno[i],&#39;_PRS_assoc_res.csv&#39;))
  
    pheno_res_PRScs&lt;-read.csv(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/PRScs/Pheno_PRS_assoc_res.csv&#39;)
    pheno_res_PRScs&lt;-pheno_res_PRScs[pheno_res_PRScs$Phenotype == pheno[i],]
      
    AUC_R2_pred&lt;-rbind(AUC_R2_pred, data.frame(Phenotype=pheno[i],
                                         N=meta_h2$N[meta_h2$Phenotype == pheno[i]],
                                         vg1=meta_h2$H2_liab[meta_h2$Phenotype == pheno[i]],
                                         prevalence=meta_h2$pop_prev[meta_h2$Phenotype == pheno[i]],
                                         sampling=meta_h2$sample_prev[meta_h2$Phenotype == pheno[i]],
                                         NSNP=mean_nsnp,
                                         pred_AUC=NA,
                                         pred_R2=tmp$R2,
                                         pTclump_AUC=NA,
                                         pTclump_R2=pheno_res_pTclump$R2_obs[length(pheno_res_pTclump$R2_obs)],
                                         PRScs_AUC=NA,
                                         PRScs_R2=pheno_res_PRScs$R2_obs[1]))
  
  } else {
    
    tmp&lt;-polygenescore(nsnp=mean_nsnp, n=meta_h2$N[meta_h2$Phenotype == pheno[i]], vg1 = meta_h2$H2_liab[meta_h2$Phenotype == pheno[i]], pupper = c(0, 1), nested = TRUE, weighted = TRUE, binary = T, prevalence = meta_h2$pop_prev[meta_h2$Phenotype == pheno[i]], sampling = meta_h2$sample_prev[meta_h2$Phenotype == pheno[i]])
    
    pheno_res_pTclump&lt;-read.csv(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/pTclump/&#39;,pheno[i],&#39;_PRS_assoc_res.csv&#39;))
  
    pheno_res_PRScs&lt;-read.csv(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/PRScs/Pheno_PRS_assoc_res.csv&#39;)
    pheno_res_PRScs&lt;-pheno_res_PRScs[pheno_res_PRScs$Phenotype == pheno[i],]
    
    AUC_R2_pred&lt;-rbind(AUC_R2_pred, data.frame(Phenotype=pheno[i],
                                         N=meta_h2$N[meta_h2$Phenotype == pheno[i]],
                                         vg1=meta_h2$H2_liab[meta_h2$Phenotype == pheno[i]],
                                         prevalence=meta_h2$pop_prev[meta_h2$Phenotype == pheno[i]],
                                         sampling=meta_h2$sample_prev[meta_h2$Phenotype == pheno[i]],
                                         NSNP=mean_nsnp,
                                         pred_AUC=tmp$AUC,
                                         pred_R2=NA,
                                         pTclump_AUC=pheno_res_pTclump$AUC[length(pheno_res_pTclump$AUC)],
                                         pTclump_R2=NA,
                                         PRScs_AUC=pheno_res_PRScs$AUC[1],
                                         PRScs_R2=NA))
  }
}

# Thes estimates are slightly low compared to the observed. This might be a result of slight overfitting somewhere in my 10FC GWAS procedure. Therefore, AVENGEME might be more accurate for the general user of Impute.Me.

# The PRS R2 and AUC estimates can be raised by reducing the nsnp parameter. Try 90000.

for(i in c(1,2,3,5,6)){
  
  pheno_nsnp&lt;-NULL
  for(subset_i in 1:10){
    tmp&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/10FC_GWAS/pTclump/&#39;,pheno[i],&#39;/excl_Subset_&#39;,subset_i,&#39;/pTclump_excl_Subset_&#39;,subset_i,&#39;_&#39;,pheno[i],&#39;.NSNP_per_pT&#39;))
  
    pheno_nsnp&lt;-rbind(pheno_nsnp, data.frame(Subset=subset_i,
                           NSNP=tmp$NSNP[length(tmp$NSNP)]))
  }

  mean_nsnp&lt;-mean(pheno_nsnp$NSNP)
  
  if(is.na(meta_h2$H2_liab[meta_h2$Phenotype == pheno[i]])){
    tmp&lt;-polygenescore(nsnp=90000, n=meta_h2$N[meta_h2$Phenotype == pheno[i]], vg1 = meta_h2$H2_obs[meta_h2$Phenotype == pheno[i]], pupper = c(0, 1), nested = TRUE, weighted = TRUE, binary = F)
    
    pheno_res_pTclump&lt;-read.csv(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/pTclump/&#39;,pheno[i],&#39;_PRS_assoc_res.csv&#39;))
  
    pheno_res_PRScs&lt;-read.csv(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/PRScs/Pheno_PRS_assoc_res.csv&#39;)
    pheno_res_PRScs&lt;-pheno_res_PRScs[pheno_res_PRScs$Phenotype == pheno[i],]
      
    AUC_R2_pred&lt;-rbind(AUC_R2_pred, data.frame(Phenotype=pheno[i],
                                         N=meta_h2$N[meta_h2$Phenotype == pheno[i]],
                                         vg1=meta_h2$H2_liab[meta_h2$Phenotype == pheno[i]],
                                         prevalence=meta_h2$pop_prev[meta_h2$Phenotype == pheno[i]],
                                         sampling=meta_h2$sample_prev[meta_h2$Phenotype == pheno[i]],
                                         NSNP=90000,
                                         pred_AUC=NA,
                                         pred_R2=tmp$R2,
                                         pTclump_AUC=NA,
                                         pTclump_R2=pheno_res_pTclump$R2_obs[length(pheno_res_pTclump$R2_obs)],
                                         PRScs_AUC=NA,
                                         PRScs_R2=pheno_res_PRScs$R2_obs[1]))
  
  } else {
    
    tmp&lt;-polygenescore(nsnp=90000, n=meta_h2$N[meta_h2$Phenotype == pheno[i]], vg1 = meta_h2$H2_liab[meta_h2$Phenotype == pheno[i]], pupper = c(0, 1), nested = TRUE, weighted = TRUE, binary = T, prevalence = meta_h2$pop_prev[meta_h2$Phenotype == pheno[i]], sampling = meta_h2$sample_prev[meta_h2$Phenotype == pheno[i]])
    
    pheno_res_pTclump&lt;-read.csv(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/pTclump/&#39;,pheno[i],&#39;_PRS_assoc_res.csv&#39;))
  
    pheno_res_PRScs&lt;-read.csv(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/PRScs/Pheno_PRS_assoc_res.csv&#39;)
    pheno_res_PRScs&lt;-pheno_res_PRScs[pheno_res_PRScs$Phenotype == pheno[i],]
    
    AUC_R2_pred&lt;-rbind(AUC_R2_pred, data.frame(Phenotype=pheno[i],
                                         N=meta_h2$N[meta_h2$Phenotype == pheno[i]],
                                         vg1=meta_h2$H2_liab[meta_h2$Phenotype == pheno[i]],
                                         prevalence=meta_h2$pop_prev[meta_h2$Phenotype == pheno[i]],
                                         sampling=meta_h2$sample_prev[meta_h2$Phenotype == pheno[i]],
                                         NSNP=90000,
                                         pred_AUC=tmp$AUC,
                                         pred_R2=NA,
                                         pTclump_AUC=pheno_res_pTclump$AUC[length(pheno_res_pTclump$AUC)],
                                         pTclump_R2=NA,
                                         PRScs_AUC=pheno_res_PRScs$AUC[1],
                                         PRScs_R2=NA))
  }
}

write.csv(AUC_R2_pred, &#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/AUC_predictions.csv&#39;, row.names=F, quote=F)

# The AVENGEME and LDSC approach is very fast and fairly accurate. However, the NSNP parameter is reduced to 90K, the estimates become more accurate.

# Make plot
AUC_obs&lt;-AUC_R2_pred[AUC_R2_pred$NSNP != 90000,c(&#39;Phenotype&#39;,&#39;pTclump_AUC&#39;)]
names(AUC_obs)&lt;-c(&#39;Phenotype&#39;,&#39;AUC&#39;)
AUC_obs$Method&lt;-&#39;Observed&#39;
AUC_pred&lt;-AUC_R2_pred[AUC_R2_pred$NSNP != 90000,c(&#39;Phenotype&#39;,&#39;pred_AUC&#39;)]
names(AUC_pred)&lt;-c(&#39;Phenotype&#39;,&#39;AUC&#39;)
AUC_pred$Method&lt;-&#39;Estimated&#39;
AUC_pred_90k&lt;-AUC_R2_pred[AUC_R2_pred$NSNP == 90000,c(&#39;Phenotype&#39;,&#39;pred_AUC&#39;)]
names(AUC_pred_90k)&lt;-c(&#39;Phenotype&#39;,&#39;AUC&#39;)
AUC_pred_90k$Method&lt;-&quot;Estimated (90k SNP)&quot;
AUC_comp_plot&lt;-do.call(rbind, list(AUC_obs, AUC_pred, AUC_pred_90k))
AUC_comp_plot&lt;-AUC_comp_plot[complete.cases(AUC_comp_plot),]

R2_obs&lt;-AUC_R2_pred[AUC_R2_pred$NSNP != 90000,c(&#39;Phenotype&#39;,&#39;pTclump_R2&#39;)]
names(R2_obs)&lt;-c(&#39;Phenotype&#39;,&#39;R2&#39;)
R2_obs$Method&lt;-&#39;Observed&#39;
R2_pred&lt;-AUC_R2_pred[AUC_R2_pred$NSNP != 90000,c(&#39;Phenotype&#39;,&#39;pred_R2&#39;)]
names(R2_pred)&lt;-c(&#39;Phenotype&#39;,&#39;R2&#39;)
R2_pred$Method&lt;-&#39;Estimated&#39;
R2_pred_90k&lt;-AUC_R2_pred[AUC_R2_pred$NSNP == 90000,c(&#39;Phenotype&#39;,&#39;pred_R2&#39;)]
names(R2_pred_90k)&lt;-c(&#39;Phenotype&#39;,&#39;R2&#39;)
R2_pred_90k$Method&lt;-&quot;Estimated (90k SNP)&quot;
R2_comp_plot&lt;-do.call(rbind, list(R2_obs, R2_pred, R2_pred_90k))
R2_comp_plot&lt;-R2_comp_plot[complete.cases(R2_comp_plot),]

library(ggplot2)
library(cowplot)

bitmap(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/Estimated_AUC_comparison.png&#39;), res=300, unit=&#39;px&#39;, width=1500, height=1000)
print(ggplot(AUC_comp_plot, aes(x=Phenotype, y=AUC, colour=Method, group=Method)) +
  geom_point() +
  geom_line() +
  theme_cowplot(12)) +
  labs(title=&quot;AVENGEME vs. observed pT+clump (pT=1)&quot;)
dev.off()

bitmap(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/Estimated_R2_comparison.png&#39;), res=300, unit=&#39;px&#39;, width=1500, height=1000)
print(ggplot(R2_comp_plot, aes(x=Phenotype, y=R2, colour=Method, group=Method)) +
  geom_point() +
  geom_line() +
  theme_cowplot(12)) +
  labs(title=&quot;AVENGEME vs. observed pT+clump (pT=1)&quot;)
dev.off()</code></pre>
</details>
<details>
<p><summary>Show predicted and observed AUC values</summary></p>
<center>
<div class="figure">
<img src="Images/Validating_ImputeMe_Ideas/Estimated_AUC_comparison.png" alt="Predicted and Observed AUC values" />
<p class="caption">Predicted and Observed AUC values</p>
</div>

</details>
<details>
<p><summary>Show predicted and observed R2 values</summary></p>
<center>
<div class="figure">
<img src="Images/Validating_ImputeMe_Ideas/Estimated_R2_comparison.png" alt="Predicted and Observed R2 values" />
<p class="caption">Predicted and Observed R2 values</p>
</div>

</details>
<p><br/></p>
<hr />
</div>
</div>
<div id="section-compare-observed-and-estimated-absolute-risk-estimates" class="section level1">
<h1><span class="header-section-number">4</span> Compare observed and estimated absolute risk estimates</h1>
<details>
<p><summary>Show code</summary></p>
<pre class="r"><code>library(data.table)

pheno&lt;-c(&#39;Depression&#39;,&#39;Intelligence&#39;,&#39;BMI&#39;,&#39;Height&#39;,&#39;T2D&#39;,&#39;CAD&#39;,&#39;IBD&#39;,&#39;MultiScler&#39;,&#39;RheuArth&#39;)
pheno_file&lt;-c(&#39;ever_depressed_pheno_final.UpdateIDs.txt&#39;,&#39;UKBB_Fluid.intelligence.score.UpdateIDs.pheno&#39;,&#39;UKBB_BMI.score.UpdateIDs.pheno&#39;,&#39;UKBB_Height.score.UpdateIDs.pheno&#39;,&#39;t2d_only_111119.UpdateIDs.txt&#39;,&#39;cad_only_111119.UpdateIDs.txt&#39;,&#39;UKBB.IBD.txt&#39;,&#39;UKBB.MultiScler.txt&#39;,&#39;UKBB.RheuArth.txt&#39;)
prev=c(0.15,NA,NA,NA,0.05,0.03,0.013,0.00164,0.005)

AUC_pred&lt;-read.csv(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/AUC_predictions.csv&#39;)

# Create function for estimating absolute risk
ccprobs.f &lt;- function(PRS_auc=0.641, prev=0.7463, n_quantile=20){
  d &lt;- sqrt(2)*qnorm(PRS_auc)
  mu_case &lt;- d
  mu_control &lt;- 0
  
  varPRS &lt;- prev*(1+(d^2) - (d*prev)^2) + (1-prev)*(1 - (d*prev)^2)
  E_PRS &lt;- d*prev
  
  by_quant&lt;-1/n_quantile
  p_quant &lt;- seq(by_quant, 1-by_quant, by=by_quant)
  quant_vals_PRS &lt;- rep(0, length(p_quant))
  quant_f_solve &lt;- function(x, prev, d, pq){prev*pnorm(x-d) + (1-prev)*pnorm(x) - pq}
  for(i in 1:length(p_quant)){
    quant_vals_PRS[i] &lt;- unlist(uniroot(quant_f_solve, prev=prev, d=d, pq= p_quant[i], interval=c(-2.5, 2.5), extendInt = &quot;yes&quot;, tol=6e-12)$root)
  }
  
  ul_qv_PRS &lt;- matrix(0, ncol=2, nrow=n_quantile)
  ul_qv_PRS[1,1] &lt;- -Inf
  ul_qv_PRS[2:n_quantile,1] &lt;- quant_vals_PRS
  ul_qv_PRS[1:(n_quantile-1),2] &lt;- quant_vals_PRS
  ul_qv_PRS[n_quantile,2] &lt;- Inf
  
  ul_qv_PRS&lt;-cbind(ul_qv_PRS, (ul_qv_PRS[,1:2]-E_PRS)/sqrt(varPRS))

  prob_quantile_case &lt;- pnorm(ul_qv_PRS[,2], mean = mu_case) - pnorm(ul_qv_PRS[,1], mean = mu_case)
  prob_quantile_control &lt;- pnorm(ul_qv_PRS[,2], mean = mu_control) - pnorm(ul_qv_PRS[,1], mean = mu_control)
  p_case_quantile &lt;- (prob_quantile_case*prev)/by_quant
  p_cont_quantile &lt;- (prob_quantile_control*(1-prev))/by_quant

  OR &lt;- p_case_quantile/p_cont_quantile
  OR &lt;- OR/OR[1]
  out &lt;- cbind(ul_qv_PRS[,3:4],p_cont_quantile, p_case_quantile, OR)
  row.names(out) &lt;- 1:n_quantile
  colnames(out) &lt;- c(&quot;q_min&quot;, &quot;q_max&quot;,&quot;p_control&quot;, &quot;p_case&quot;, &quot;OR&quot;)
  
  data.frame(out)
}

for(i in c(1,5,6)){
  print(pheno[i])
  
  ##
  # Calculate estimated absolute risk per quantile
  ##
  
  # Read in AUC predicted by AVENGEME
  PRS_AUC&lt;-AUC_pred$pred_AUC[AUC_pred$Phenotype == pheno[i] &amp; AUC_pred$NSNP != 90000]
  
  # Estimate absolute risk per quantile
  quant_prop_est&lt;-ccprobs.f(PRS_auc=PRS_AUC, prev=prev[i], n_quantile=20)
  quant_prop_est$q&lt;-1:20
  
  quant_prop_est&lt;-quant_prop_est[c(&#39;q&#39;,&#39;q_min&#39;,&#39;q_max&#39;,&#39;p_case&#39;)]
  quant_prop_est$method&lt;-&#39;Estimated&#39;

  quant_prop_est_all&lt;-quant_prop_est
  
  # Read in AUC predicted by AVENGEME using 90k SNP
  PRS_AUC&lt;-AUC_pred$pred_AUC[AUC_pred$Phenotype == pheno[i] &amp; AUC_pred$NSNP == 90000]
  
  # Estimate absolute risk per quantile
  quant_prop_est&lt;-ccprobs.f(PRS_auc=PRS_AUC, prev=prev[i], n_quantile=20)
  quant_prop_est$q&lt;-1:20
  
  quant_prop_est&lt;-quant_prop_est[c(&#39;q&#39;,&#39;q_min&#39;,&#39;q_max&#39;,&#39;p_case&#39;)]
  quant_prop_est$method&lt;-&quot;Estimated (90k SNP)&quot;
  
  quant_prop_est_all&lt;-rbind(quant_prop_est_all,quant_prop_est)
  
  # Read in AUC predicted by AVENGEME using observed AUC
  PRS_AUC&lt;-AUC_pred$pTclump_AUC[AUC_pred$Phenotype == pheno[i] &amp; AUC_pred$NSNP != 90000]
  
  # Estimate absolute risk per quantile
  quant_prop_est&lt;-ccprobs.f(PRS_auc=PRS_AUC, prev=prev[i], n_quantile=20)
  quant_prop_est$q&lt;-1:20
  
  quant_prop_est&lt;-quant_prop_est[c(&#39;q&#39;,&#39;q_min&#39;,&#39;q_max&#39;,&#39;p_case&#39;)]
  quant_prop_est$method&lt;-&quot;Estimated (observed AUC)&quot;
  
  quant_prop_est_all&lt;-rbind(quant_prop_est_all,quant_prop_est)

  ##
  # Calculate observed absolute risk per quantile
  ##
  # Read in phenotype file
  pheno_i&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/&#39;,pheno[i],&#39;/&#39;,pheno_file[i]))
  names(pheno_i)[3]&lt;-&#39;pheno&#39;

  prs_var&lt;-NULL
  for(subset_i in 1:10){
    # Read in the PRS
    prs_var_subset&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/pTclump/&#39;,pheno[i],&#39;/Subset_&#39;,subset_i,&#39;/Subset_&#39;,subset_i,&#39;_&#39;,pheno[i],&#39;_pTclump.profiles&#39;))

    prs_var_subset&lt;-prs_var_subset[,c(&#39;FID&#39;,&#39;IID&#39;,paste0(pheno[i],&#39;_1&#39;)), with=F]
    prs_var&lt;-rbind(prs_var, prs_var_subset)
  }
  pheno_i_prs&lt;-merge(pheno_i,prs_var,by=c(&#39;FID&#39;,&#39;IID&#39;)) 
  pheno_i_prs&lt;-pheno_i_prs[complete.cases(pheno_i_prs),]
  
  # Calculate the proportion of cases within each quantile
  quant_prop&lt;-NULL
  for(quant_i in 1:20){

    quant_prop_est
    quant_prop&lt;-rbind(quant_prop, data.frame(q_min=quant_prop_est$q_min[quant_i],
                                             q_max=quant_prop_est$q_max[quant_i],
                                             p_case=mean(pheno_i_prs$pheno[pheno_i_prs[[paste0(pheno[i],&#39;_1&#39;)]] &gt; quant_prop_est$q_min[quant_i] &amp; pheno_i_prs[[paste0(pheno[i],&#39;_1&#39;)]] &lt; quant_prop_est$q_max[quant_i]]),
                                             p_control=1-mean(pheno_i_prs$pheno[pheno_i_prs[[paste0(pheno[i],&#39;_1&#39;)]] &gt; quant_prop_est$q_min[quant_i] &amp; pheno_i_prs[[paste0(pheno[i],&#39;_1&#39;)]] &lt; quant_prop_est$q_max[quant_i]])))
  }
  
  quant_prop$p_case_liab&lt;-quant_prop$p_case/(mean(pheno_i_prs$pheno)/prev[i])
  quant_prop$p_control_liab&lt;-1-quant_prop$p_case_liab
  
  quant_prop$q&lt;-1:20
  quant_prop&lt;-quant_prop[c(&#39;q&#39;,&#39;q_min&#39;,&#39;q_max&#39;,&#39;p_case_liab&#39;)]
  names(quant_prop)[4]&lt;-&#39;p_case&#39;
  
  quant_prop$method&lt;-&#39;Observed&#39;

  quant_comp&lt;-rbind(quant_prop, quant_prop_est_all)
  
  ##
  # Make a plot comparing the p_case
  ##
  
  library(ggplot2)
  library(cowplot)
  bitmap(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/Quantile_prop_predictions_all_&#39;,pheno[i],&#39;.png&#39;), res=300, unit=&#39;px&#39;, width=1500, height=1000)
  print(ggplot(quant_comp, aes(x=q, y=p_case, colour=method)) +
    geom_point() +
    geom_line() +
    labs(x=&#39;PRS quantile&#39;, y=paste0(&#39;Proportion with &#39;,pheno[i]), colour=&#39;Method&#39;) +
    theme_cowplot(12))
  dev.off()

  bitmap(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/Quantile_prop_predictions_AVENGEME_&#39;,pheno[i],&#39;.png&#39;), res=300, unit=&#39;px&#39;, width=1500, height=1000)
  print(ggplot(quant_comp[quant_comp$method == &#39;Observed&#39; | quant_comp$method == &#39;Estimated&#39;,], aes(x=q, y=p_case, colour=method)) +
    geom_point() +
    geom_line() +
    labs(x=&#39;PRS quantile&#39;, y=paste0(&#39;Proportion with &#39;,pheno[i]), colour=&#39;Method&#39;) +
    theme_cowplot(12))
  dev.off()
  
  bitmap(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/Quantile_prop_predictions_AVENGEME_90k_&#39;,pheno[i],&#39;.png&#39;), res=300, unit=&#39;px&#39;, width=1500, height=1000)
  print(ggplot(quant_comp[quant_comp$method == &#39;Observed&#39; | quant_comp$method == &quot;Estimated (90k SNP)&quot;,], aes(x=q, y=p_case, colour=method)) +
    geom_point() +
    geom_line() +
    labs(x=&#39;PRS quantile&#39;, y=paste0(&#39;Proportion with &#39;,pheno[i]), colour=&#39;Method&#39;) +
    theme_cowplot(12))
  dev.off()
  
  bitmap(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/Quantile_prop_predictions_AVENGEME_observedAUC_&#39;,pheno[i],&#39;.png&#39;), res=300, unit=&#39;px&#39;, width=1500, height=1000)
  print(ggplot(quant_comp[quant_comp$method == &#39;Observed&#39; | quant_comp$method == &quot;Estimated (observed AUC)&quot;,], aes(x=q, y=p_case, colour=method)) +
    geom_point() +
    geom_line() +
    labs(x=&#39;PRS quantile&#39;, y=paste0(&#39;Proportion with &#39;,pheno[i]), colour=&#39;Method&#39;) +
    theme_cowplot(12))
  dev.off()

}

# This works very well. The only issue is whether the predicted AUC is accurate. I think it is safer to use the AVENGEME estimate of AUC and allow for slightly more error when returning results.</code></pre>
</details>
<details>
<p><summary>Show predicted and observed proportion of cases across quantiles</summary></p>
<center>
<p><img src="Images/Validating_ImputeMe_Ideas/Quantile_prop_predictions_all_Depression.png" alt="Predicted and Observed proportion of cases across quantiles" /> <img src="Images/Validating_ImputeMe_Ideas/Quantile_prop_predictions_all_CAD.png" alt="Predicted and Observed proportion of cases across quantiles" /></p>
<div class="figure">
<img src="Images/Validating_ImputeMe_Ideas/Quantile_prop_predictions_all_T2D.png" alt="Predicted and Observed proportion of cases across quantiles" />
<p class="caption">Predicted and Observed proportion of cases across quantiles</p>
</div>

</details>
<p><br/></p>
<hr />
</div>
<div id="section-compare-observed-and-expected-mean-and-sd-of-quantitative-traits-within-expected-quantiles" class="section level1">
<h1><span class="header-section-number">5</span> Compare observed and expected mean and SD of quantitative traits within expected quantiles</h1>
<details>
<p><summary>Show code</summary></p>
<pre class="r"><code>library(data.table)

pheno&lt;-c(&#39;Depression&#39;,&#39;Intelligence&#39;,&#39;BMI&#39;,&#39;Height&#39;,&#39;T2D&#39;,&#39;CAD&#39;,&#39;IBD&#39;,&#39;MultiScler&#39;,&#39;RheuArth&#39;)
pheno_file&lt;-c(&#39;ever_depressed_pheno_final.UpdateIDs.txt&#39;,&#39;UKBB_Fluid.intelligence.score.UpdateIDs.pheno&#39;,&#39;UKBB_BMI.score.UpdateIDs.pheno&#39;,&#39;UKBB_Height.score.UpdateIDs.pheno&#39;,&#39;t2d_only_111119.UpdateIDs.txt&#39;,&#39;cad_only_111119.UpdateIDs.txt&#39;,&#39;UKBB.IBD.txt&#39;,&#39;UKBB.MultiScler.txt&#39;,&#39;UKBB.RheuArth.txt&#39;)
prev=c(0.15,NA,NA,NA,0.05,0.03,0.013,0.00164,0.005)

R2_pred&lt;-read.csv(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/AUC_predictions.csv&#39;)

PRS_abs_quant2&lt;-function(n=100000, PRS_R2=0.3, Outcome_mean=1, Outcome_sd=1, n_quantile=20, seed=1){

  # Simulate height and prs relationship
  set.seed(seed)
  
  Outcome&lt;-rnorm(n, Outcome_mean, Outcome_sd)
  PRS &lt;- as.numeric(scale(Outcome + rnorm(n,mean=0, sd=sqrt(var(Outcome)*(1-PRS_R2)/(PRS_R2)))))
  
  sim_dat&lt;-data.frame(y=Outcome, x=PRS)
  
  # Calculate simulated R2
  cor(sim_dat$x, sim_dat$y)^2
  
  # Split individuals into quantiles
  by_quant&lt;-1/n_quantile
  perc&lt;-quantile(sim_dat$x, probs = seq(0, 1, by=by_quant))
  sim_dat&lt;-data.frame(y=sim_dat$y, x=sim_dat$x, quantile=cut(sim_dat$x, quantile(sim_dat$x, prob = seq(0, 1, length = 1/by_quant+1), type = 5), include.lowest=TRUE))
  
  # Calculate mean and sd of individuals within in each quantile
  outcome_per_bin&lt;-NULL
  for(i in 1:max(as.numeric(sim_dat$quantile), na.rm=T)){
    PRS_bin_temp&lt;-sim_dat$y[which(as.numeric(sim_dat$quantile) == i)]
    temp&lt;-data.frame(q=i, 
                     q_min=as.numeric(gsub(&#39;,.*&#39;,&#39;&#39;,gsub(&quot;\\[&quot;,&#39;&#39;,gsub(&quot;\\(&quot;,&#39;&#39;,levels(sim_dat$quantile)[i])))), 
                     q_max=as.numeric(gsub(&quot;\\]&quot;,&#39;&#39;,gsub(&quot;.*,&quot;,&#39;&#39;,levels(sim_dat$quantile)[i]))), 
                     x_mean=mean(PRS_bin_temp),
                     x_sd=sd(PRS_bin_temp)) 
                     
    outcome_per_bin&lt;-rbind(outcome_per_bin,temp)
  }
  
  outcome_per_bin$q_min[1]&lt;--Inf
  outcome_per_bin$q_max[length(outcome_per_bin$q_max)]&lt;-Inf
  
  outcome_per_bin
}

n_quant&lt;-20

for(i in c(2,3)){
  print(pheno[i])

  # Read in phenotype file
  pheno_i&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/&#39;,pheno[i],&#39;/&#39;,pheno_file[i]))
  names(pheno_i)[3]&lt;-&#39;pheno&#39;
  
  ##
  # Calculate estimated absolute risk per quantile
  ##
  
  # Read in R2 predicted by AVENGEME
  PRS_R2&lt;-R2_pred$pred_R2[R2_pred$Phenotype == pheno[i] &amp; R2_pred$NSNP != 90000]

  # Estimate absolute risk per quantile
  # Use observed mean and sd. Ideally this would come from the most representative sample for the target individual. This would be improved easily by including sex.
  quant_mean_sd_est&lt;-PRS_abs_quant2(PRS_R2=PRS_R2, Outcome_mean=mean(pheno_i$pheno,na.rm=T), Outcome_sd=sd(pheno_i$pheno,na.rm=T), n_quantile=n_quant)
  quant_mean_sd_est$q&lt;-1:n_quant
  
  quant_mean_sd_est&lt;-quant_mean_sd_est[c(&#39;q&#39;,&#39;q_min&#39;,&#39;q_max&#39;,&#39;x_mean&#39;,&#39;x_sd&#39;)]
  quant_mean_sd_est$method&lt;-&#39;Estimated&#39;
  
  quant_mean_sd_est_all&lt;-quant_mean_sd_est
  ##
  # Calculate estimated absolute risk per quantile (NSNP=90k)
  ##
  
  # Read in R2 predicted by AVENGEME
  PRS_R2&lt;-R2_pred$pred_R2[R2_pred$Phenotype == pheno[i] &amp; R2_pred$NSNP == 90000]

  # Estimate absolute risk per quantile
  # Use observed mean and sd. Ideally this would come from the most representative sample for the target individual. This would be improved easily by including sex.
  quant_mean_sd_est&lt;-PRS_abs_quant2(PRS_R2=PRS_R2, Outcome_mean=mean(pheno_i$pheno,na.rm=T), Outcome_sd=sd(pheno_i$pheno,na.rm=T), n_quantile=n_quant)
  quant_mean_sd_est$q&lt;-1:n_quant
  
  quant_mean_sd_est&lt;-quant_mean_sd_est[c(&#39;q&#39;,&#39;q_min&#39;,&#39;q_max&#39;,&#39;x_mean&#39;,&#39;x_sd&#39;)]
  quant_mean_sd_est$method&lt;-&quot;Estimated (90k SNP)&quot;

  quant_mean_sd_est_all&lt;-rbind(quant_mean_sd_est_all, quant_mean_sd_est)

  ##
  # Calculate estimated absolute risk per quantile using observed AUC
  ##
  
  # Read in R2 predicted by AVENGEME
  PRS_R2&lt;-R2_pred$pTclump_R2[R2_pred$Phenotype == pheno[i] &amp; R2_pred$NSNP == 90000]

  # Estimate absolute risk per quantile
  # Use observed mean and sd. Ideally this would come from the most representative sample for the target individual. This would be improved easily by including sex.
  quant_mean_sd_est&lt;-PRS_abs_quant2(PRS_R2=PRS_R2, Outcome_mean=mean(pheno_i$pheno,na.rm=T), Outcome_sd=sd(pheno_i$pheno,na.rm=T), n_quantile=n_quant)
  quant_mean_sd_est$q&lt;-1:n_quant
  
  quant_mean_sd_est&lt;-quant_mean_sd_est[c(&#39;q&#39;,&#39;q_min&#39;,&#39;q_max&#39;,&#39;x_mean&#39;,&#39;x_sd&#39;)]
  quant_mean_sd_est$method&lt;-&quot;Estimated (observed R2)&quot;

  quant_mean_sd_est_all&lt;-rbind(quant_mean_sd_est_all, quant_mean_sd_est)

  ##
  # Calculate observed absolute risk per quantile
  ##
  # Read in phenotype file
  pheno_i&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/Phenotype/&#39;,pheno[i],&#39;/&#39;,pheno_file[i]))
  names(pheno_i)[3]&lt;-&#39;pheno&#39;

  prs_var&lt;-NULL
  for(subset_i in 1:10){
    # Read in the PRS
    prs_var_subset&lt;-fread(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/pTclump/&#39;,pheno[i],&#39;/Subset_&#39;,subset_i,&#39;/Subset_&#39;,subset_i,&#39;_&#39;,pheno[i],&#39;_pTclump.profiles&#39;))

    prs_var_subset&lt;-prs_var_subset[,c(&#39;FID&#39;,&#39;IID&#39;,paste0(pheno[i],&#39;_1&#39;)), with=F]
    prs_var&lt;-rbind(prs_var, prs_var_subset)
  }
  pheno_i_prs&lt;-merge(pheno_i,prs_var,by=c(&#39;FID&#39;,&#39;IID&#39;)) 
  pheno_i_prs&lt;-pheno_i_prs[complete.cases(pheno_i_prs),]
  
  # Calculate the proportion of cases within each quantile
  quant_mean_sd&lt;-NULL
  for(quant_i in 1:n_quant){

    quant_mean_sd&lt;-rbind(quant_mean_sd, data.frame(q_min=quant_mean_sd_est$q_min[quant_i],
                                             q_max=quant_mean_sd_est$q_max[quant_i],
                                             x_mean=mean(pheno_i_prs$pheno[pheno_i_prs[[paste0(pheno[i],&#39;_1&#39;)]] &gt; quant_mean_sd_est$q_min[quant_i] &amp; pheno_i_prs[[paste0(pheno[i],&#39;_1&#39;)]] &lt; quant_mean_sd_est$q_max[quant_i]]),
                                             x_sd=sd(pheno_i_prs$pheno[pheno_i_prs[[paste0(pheno[i],&#39;_1&#39;)]] &gt; quant_mean_sd_est$q_min[quant_i] &amp; pheno_i_prs[[paste0(pheno[i],&#39;_1&#39;)]] &lt; quant_mean_sd_est$q_max[quant_i]])))
  }
  
  quant_mean_sd$q&lt;-1:n_quant
  quant_mean_sd&lt;-quant_mean_sd[c(&#39;q&#39;,&#39;q_min&#39;,&#39;q_max&#39;,&#39;x_mean&#39;,&#39;x_sd&#39;)]

  quant_mean_sd$method&lt;-&#39;Observed&#39;

  quant_comp&lt;-rbind(quant_mean_sd, quant_mean_sd_est_all)
  
  ##
  # Make a plot comparing the p_case
  ##
  
  library(ggplot2)
  library(cowplot)

  bitmap(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/Quantile_mean_predictions_all_&#39;,pheno[i],&#39;.png&#39;), res=300, unit=&#39;px&#39;, width=2500, height=1000)
  print(ggplot(quant_comp, aes(x=q, y=x_mean, colour=method)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(.9)) +
    geom_errorbar(aes(ymin=x_mean-x_sd, ymax=x_mean+x_sd), width=.2, position=position_dodge(.9)) +
    labs(x=&#39;PRS quantile&#39;, y=paste0(pheno[i], &#39; mean and SD&#39;), colour=&#39;Method&#39;) +
    theme_cowplot(12))
  dev.off()
  
  bitmap(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/Quantile_mean_predictions_AVENGEME_&#39;,pheno[i],&#39;.png&#39;), res=300, unit=&#39;px&#39;, width=1500, height=1000)
  print(ggplot(quant_comp[quant_comp$method == &#39;Observed&#39; | quant_comp$method == &#39;Estimated&#39;,], aes(x=q, y=x_mean, colour=method)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(.9)) +
    geom_errorbar(aes(ymin=x_mean-x_sd, ymax=x_mean+x_sd), width=.2, position=position_dodge(.9)) +
    labs(x=&#39;PRS quantile&#39;, y=paste0(pheno[i], &#39; mean and SD&#39;), colour=&#39;Method&#39;) +
    theme_cowplot(12))
  dev.off()
  
  bitmap(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/Quantile_mean_predictions_AVENGEME_90k_&#39;,pheno[i],&#39;.png&#39;), res=300, unit=&#39;px&#39;, width=1500, height=1000)
  print(ggplot(quant_comp[quant_comp$method == &#39;Observed&#39; | quant_comp$method == &quot;Estimated (90k SNP)&quot;,], aes(x=q, y=x_mean, colour=method)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(.9)) +
    geom_errorbar(aes(ymin=x_mean-x_sd, ymax=x_mean+x_sd), width=.2, position=position_dodge(.9)) +
    labs(x=&#39;PRS quantile&#39;, y=paste0(pheno[i], &#39; mean and SD&#39;), colour=&#39;Method&#39;) +
    theme_cowplot(12))
  dev.off()
  
  bitmap(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/Quantile_mean_predictions_AVENGEME_observedR2_&#39;,pheno[i],&#39;.png&#39;), res=300, unit=&#39;px&#39;, width=1500, height=1000)
  print(ggplot(quant_comp[quant_comp$method == &#39;Observed&#39; | quant_comp$method == &quot;Estimated (observed R2)&quot;,], aes(x=q, y=x_mean, colour=method)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(.9)) +
    geom_errorbar(aes(ymin=x_mean-x_sd, ymax=x_mean+x_sd), width=.2, position=position_dodge(.9)) +
    labs(x=&#39;PRS quantile&#39;, y=paste0(pheno[i], &#39; mean and SD&#39;), colour=&#39;Method&#39;) +
    theme_cowplot(12))
  dev.off()

  bitmap(paste0(&#39;/users/k1806347/brc_scratch/Data/UKBB/ValidationArena/PolygenicScores/Histograms_&#39;,pheno[i],&#39;.png&#39;), res=300, unit=&#39;px&#39;, width=1500, height=1500)
  hist(pheno_i_prs$pheno, xlab=pheno[i], main=paste0(&#39;Histogram of &#39;,pheno[i]))
  dev.off()

}

# This works fairly well, although BMI is skewed in UKBiobank, which means the predictions are slightly off.</code></pre>
</details>
<details>
<p><summary>Show predicted and observed mean and sd across quantiles</summary></p>
<center>
<div class="figure">
<img src="Images/Validating_ImputeMe_Ideas/Quantile_mean_predictions_all_Intelligence.png" alt="Predicted and Observed proportion of mean and sd across quantiles" />
<p class="caption">Predicted and Observed proportion of mean and sd across quantiles</p>
</div>
<div class="figure">
<img src="Images/Validating_ImputeMe_Ideas/Quantile_mean_predictions_all_BMI.png" alt="Predicted and Observed proportion of mean and sd across quantiles" />
<p class="caption">Predicted and Observed proportion of mean and sd across quantiles</p>
</div>

</details>
<details>
<p><summary>Show observed distribution of quantitative outcomes</summary></p>
<center>
<div class="figure">
<img src="Images/Validating_ImputeMe_Ideas/Histograms_Intelligence.png" alt="Histogram" />
<p class="caption">Histogram</p>
</div>
<div class="figure">
<img src="Images/Validating_ImputeMe_Ideas/Histograms_BMI.png" alt="Histogram" />
<p class="caption">Histogram</p>
</div>

</details>
<hr />
</div>
<div id="section-plots-for-interpreting-individual-prs" class="section level1">
<h1><span class="header-section-number">6</span> Plots for interpreting individual PRS</h1>
<hr />
<div id="section-binary-outcomes" class="section level2">
<h2><span class="header-section-number">6.1</span> Binary outcomes</h2>
<hr />
<div id="section-example-shiny-app" class="section level3">
<h3><span class="header-section-number">6.1.1</span> Example shiny app</h3>
<pre><code>## 
## Attaching package: &#39;reshape2&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:data.table&#39;:
## 
##     dcast, melt</code></pre>
<pre><code>## 
## Attaching package: &#39;ggimage&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:cowplot&#39;:
## 
##     theme_nothing</code></pre>
<iframe data-deferred-src="appbab1f98e890071e1ff66d4f6541a15c2/?w=&amp;__subapp__=1" width="100%" height="1200" class="shiny-frame shiny-frame-deferred"></iframe>
<hr />
</div>
</div>
<div id="section-quantitative-outcomes" class="section level2">
<h2><span class="header-section-number">6.2</span> Quantitative outcomes</h2>
<hr />
<div id="section-example-shiny-app-1" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Example shiny app</h3>
<iframe data-deferred-src="app84e6013cc2e53cfc08c57e3800104efb/?w=&amp;__subapp__=1" width="100%" height="800" class="shiny-frame shiny-frame-deferred"></iframe>
<hr />
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("section-TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#section-TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
